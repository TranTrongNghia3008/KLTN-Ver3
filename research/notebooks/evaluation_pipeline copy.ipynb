{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9adbf56",
   "metadata": {},
   "source": [
    "# Part 1: Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd2845",
   "metadata": {},
   "source": [
    "## 1.1 Install Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a46a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (1.93.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22027d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\nghia\\appdata\\local\\temp\\pip-req-build-1zvwh2wl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\Nghia\\AppData\\Local\\Temp\\pip-req-build-1zvwh2wl'\n",
      "  fatal: unable to access 'https://github.com/openai/whisper.git/': Could not resolve host: github.com\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  √ó git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\Nghia\\AppData\\Local\\Temp\\pip-req-build-1zvwh2wl' did not run successfully.\n",
      "  ‚îÇ exit code: 128\n",
      "  ‚ï∞‚îÄ> See above for output.\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "√ó git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\Nghia\\AppData\\Local\\Temp\\pip-req-build-1zvwh2wl' did not run successfully.\n",
      "‚îÇ exit code: 128\n",
      "‚ï∞‚îÄ> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyannote.audio in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: asteroid-filterbanks>=0.4 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (0.4.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (0.33.2)\n",
      "Requirement already satisfied: lightning>=2.0.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (2.5.2)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (2.3.0)\n",
      "Requirement already satisfied: pyannote.core>=5.0.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (5.0.0)\n",
      "Requirement already satisfied: pyannote.database>=5.0.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (5.1.3)\n",
      "Requirement already satisfied: pyannote.metrics>=3.2 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (3.2.1)\n",
      "Requirement already satisfied: pyannote.pipeline>=3.0.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (3.0.1)\n",
      "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (2.8.1)\n",
      "Requirement already satisfied: rich>=12.0.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (14.0.0)\n",
      "Requirement already satisfied: semver>=3.0.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (3.0.4)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (0.13.1)\n",
      "Requirement already satisfied: speechbrain>=1.0.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (1.0.3)\n",
      "Requirement already satisfied: tensorboardX>=2.6 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (2.6.4)\n",
      "Requirement already satisfied: torch>=2.0.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (2.7.1)\n",
      "Requirement already satisfied: torch-audiomentations>=0.11.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (0.12.0)\n",
      "Requirement already satisfied: torchaudio>=2.2.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (2.7.1)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.audio) (1.7.3)\n",
      "Requirement already satisfied: numpy in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (2.2.6)\n",
      "Requirement already satisfied: typing-extensions in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (4.14.0)\n",
      "Requirement already satisfied: filelock in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.67.1)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (0.14.3)\n",
      "Requirement already satisfied: pytorch-lightning in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (2.5.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.16.0)\n",
      "Requirement already satisfied: pandas>=0.19 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.3.0)\n",
      "Requirement already satisfied: typer>=0.12.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.16.0)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.7.0)\n",
      "Requirement already satisfied: docopt>=0.6.2 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.6.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.10.3)\n",
      "Requirement already satisfied: sympy>=1.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.14.0)\n",
      "Requirement already satisfied: optuna>=3.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pyannote.pipeline>=3.0.1->pyannote.audio) (4.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from rich>=12.0.0->pyannote.audio) (2.19.2)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from soundfile>=0.12.1->pyannote.audio) (1.17.1)\n",
      "Requirement already satisfied: hyperpyyaml in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from speechbrain>=1.0.0->pyannote.audio) (1.2.2)\n",
      "Requirement already satisfied: joblib in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from speechbrain>=1.0.0->pyannote.audio) (1.5.1)\n",
      "Requirement already satisfied: sentencepiece in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from tensorboardX>=2.6->pyannote.audio) (6.31.1)\n",
      "Requirement already satisfied: networkx in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from torch>=2.0.0->pyannote.audio) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from torch>=2.0.0->pyannote.audio) (3.1.6)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.2.7)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (1.2.5)\n",
      "Requirement already satisfied: pycparser in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (3.12.13)\n",
      "Requirement already satisfied: setuptools in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (65.5.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.9.0.post0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.16.2)\n",
      "Requirement already satisfied: colorlog in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.41)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio) (1.3.0)\n",
      "Requirement already satisfied: primePy>=1.3 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio) (1.3)\n",
      "Requirement already satisfied: colorama in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.13.0->pyannote.audio) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.18.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from jinja2->torch>=2.0.0->pyannote.audio) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2025.6.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.20.1)\n",
      "Requirement already satisfied: Mako in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.3.10)\n",
      "Requirement already satisfied: six>=1.5 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.17.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.2.12)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: opencv-python in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from moviepy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from moviepy) (2.32.4)\n",
      "Requirement already satisfied: proglog<=1.0.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from moviepy) (0.1.12)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from moviepy) (2.2.6)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from moviepy) (2.37.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (11.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2025.6.15)\n",
      "Requirement already satisfied: colorama in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install pyannote.audio\n",
    "!pip install moviepy opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca86f5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yt-dlp in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (2025.6.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a6a458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub[hf_xet] in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (0.33.2)\n",
      "Requirement already satisfied: filelock in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from huggingface_hub[hf_xet]) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from huggingface_hub[hf_xet]) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from huggingface_hub[hf_xet]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from huggingface_hub[hf_xet]) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from huggingface_hub[hf_xet]) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.14.0)\n",
      "Requirement already satisfied: colorama in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub[hf_xet]) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2025.6.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub[hf_xet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33261970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromedriver-autoinstaller in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (0.6.4)\n",
      "Requirement already satisfied: packaging>=23.1 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from chromedriver-autoinstaller) (25.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install chromedriver-autoinstaller\n",
    "!apt-get update\n",
    "!apt-get install -y chromium-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ce3c983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'sudo' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'sudo' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'dpkg' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'dpkg' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'CHROME_DRIVER_VERSION' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'chmod' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'mv' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (4.34.0)\n",
      "Requirement already satisfied: urllib3[socks]~=2.4.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from selenium) (2.4.0)\n",
      "Requirement already satisfied: trio~=0.30.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.12.2 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.4.26 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from selenium) (2025.6.15)\n",
      "Requirement already satisfied: typing_extensions~=4.14.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from selenium) (4.14.0)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from trio~=0.30.0->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from trio~=0.30.0->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from urllib3[socks]~=2.4.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in d:\\lophoc\\thesis\\ver3\\code\\kltn-ver3\\research\\myenv\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!sudo apt -y update\n",
    "!sudo apt install -y wget curl unzip\n",
    "!wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
    "!dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
    "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
    "!dpkg -i google-chrome-stable_current_amd64.deb\n",
    "!CHROME_DRIVER_VERSION=$(curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE)\n",
    "!wget -N https://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip -P /tmp/\n",
    "!unzip -o /tmp/chromedriver_linux64.zip -d /tmp/\n",
    "!chmod +x /tmp/chromedriver\n",
    "!mv /tmp/chromedriver /usr/local/bin/chromedriver\n",
    "!pip install selenium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c97dc1",
   "metadata": {},
   "source": [
    "## 1.2 Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9327cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1411688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "from pyannote.audio import Pipeline\n",
    "from typing import List, Dict\n",
    "import yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5b13240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df685bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ba2ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b6dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For crawling data\n",
    "import chromedriver_autoinstaller\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import concurrent.futures\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException, NoSuchElementException, ElementClickInterceptedException\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27b59196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8569af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c0161",
   "metadata": {},
   "source": [
    "## 1.3 Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5a81aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cf38943",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"http://localhost:8000/deepfake/detect/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99af49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Chromedriver\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')  # Run in headless mode\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--window-size=1920x1080')  # Ensure the window size is large enough\n",
    "\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "chrome_options.add_argument(\"accept-language=en-US,en;q=0.9\")\n",
    "chrome_options.add_argument(\"referer=https://www.google.com/\")\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "chrome_options.add_argument(\n",
    "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.6478.57 Safari/537.36\"\n",
    ")\n",
    "# chrome_options.binary_location = '/usr/bin/chromium-browser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffd41f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIMUM_K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9645c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key = OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0699a806",
   "metadata": {},
   "source": [
    "# Part 2: Extract statements that need fact-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "825bb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 1: Extract audio from video ---\n",
    "def extract_audio(video_path: str, audio_dir: str = \"audios\") -> str:\n",
    "    if not os.path.exists(audio_dir):\n",
    "        os.makedirs(audio_dir)\n",
    "    video = VideoFileClip(video_path)\n",
    "    audio_path = os.path.basename(video_path).replace('.mp4', '.wav')\n",
    "    audio_path = os.path.join(audio_dir, audio_path)\n",
    "    if os.path.exists(audio_path):\n",
    "        os.remove(audio_path)\n",
    "    video.audio.write_audiofile(audio_path)\n",
    "    return audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fc2022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 2: Diarize audio (identify speakers) ---\n",
    "def diarize_audio(audio_path: str) -> List[Dict]:\n",
    "    pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\", use_auth_token=HUGGINGFACE_TOKEN)\n",
    "    diarization = pipeline(audio_path)\n",
    "    speakers = []\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        speakers.append({\n",
    "            \"start\": turn.start,\n",
    "            \"end\": turn.end,\n",
    "            \"speaker\": speaker\n",
    "        })\n",
    "    return speakers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dc41532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 3: Transcribe audio ---\n",
    "def transcribe_audio(audio_path: str) -> List[Dict]:\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"segments\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35273564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 4: Assign speakers to transcript segments ---\n",
    "def assign_speakers(segments: List[Dict], speakers: List[Dict]) -> List[Dict]:\n",
    "    output = []\n",
    "    for seg in segments:\n",
    "        speaker_label = \"unknown\"\n",
    "        for sp in speakers:\n",
    "            if sp[\"start\"] <= seg[\"start\"] <= sp[\"end\"]:\n",
    "                speaker_label = sp[\"speaker\"]\n",
    "                break\n",
    "        output.append({\n",
    "            \"start\": seg[\"start\"],\n",
    "            \"end\": seg[\"end\"],\n",
    "            \"speaker\": speaker_label,\n",
    "            \"text\": seg[\"text\"].strip()\n",
    "        })\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e23243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 5: Identify speaker names via text cues (OpenAI) ---\n",
    "class Speaker(BaseModel):\n",
    "    id: str\n",
    "    name: str\n",
    "\n",
    "class ListSpeakers(BaseModel):\n",
    "    listSpeakers: list[Speaker]\n",
    "\n",
    "\n",
    "def identify_speaker_names_via_text(transcript: List[Dict]) -> Dict:\n",
    "    transcript_text = \"\\n\".join(\n",
    "        [f\"{seg['speaker']}: {seg['text']}\" for seg in transcript]\n",
    "    )\n",
    "    prompt = f\"\"\"\n",
    "    Below is the full transcript of a video, each line contains the speaker (SPEAKER_XX) and the dialogue.\n",
    "\n",
    "    Analyze to determine if there is any part where the speaker introduces himself or is introduced by someone else.\n",
    "\n",
    "    Returns a JSON result with the following structure:\n",
    "    {{\n",
    "      {{\n",
    "        id: \"SPEAKER_00\",\n",
    "        name: \"Name if available\",\n",
    "      }},\n",
    "      ...\n",
    "    }}\n",
    "\n",
    "    If not identified, returns the name field as \"Unnamed\".\n",
    "\n",
    "    Transcript:\n",
    "    {transcript_text}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.responses.parse(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        text_format=ListSpeakers,\n",
    "    )\n",
    "\n",
    "    return response.output_parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9993052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_for_unknown_speakers(\n",
    "    video_path: str,\n",
    "    speaker_segments: List[Dict],\n",
    "    speaker_name_map,  # ki·ªÉu: ListSpeakers (ƒë√£ ch·ª©a list[Speaker(id, name)])\n",
    "    output_dir: str = \"frames\",\n",
    "    max_frames_per_speaker: int = 5\n",
    "):\n",
    "    import os\n",
    "    import cv2\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # T·∫°o dict lookup t√™n t·ª´ speaker_name_map\n",
    "    speaker_id_to_name = {s.id: s.name for s in speaker_name_map.listSpeakers}\n",
    "    speaker_frames = {}\n",
    "\n",
    "    for seg in speaker_segments:\n",
    "        spk = seg['speaker']\n",
    "        name = speaker_id_to_name.get(spk, \"\")\n",
    "        if name.startswith(\"Unnamed\"):\n",
    "            # N·∫øu ƒë√£ ƒë·ªß 5 frame th√¨ b·ªè qua\n",
    "            if spk in speaker_frames and len(speaker_frames[spk]) >= max_frames_per_speaker:\n",
    "                continue\n",
    "\n",
    "            mid_time = (seg['start'] + seg['end']) / 2\n",
    "            frame_num = int(mid_time * fps)\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                frame_path = os.path.join(output_dir, f\"{spk}_{int(seg['start'])}.jpg\")\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "                if spk not in speaker_frames:\n",
    "                    speaker_frames[spk] = []\n",
    "                speaker_frames[spk].append({\n",
    "                    \"time\": mid_time,\n",
    "                    \"frame_path\": frame_path,\n",
    "                    \"text\": seg[\"text\"]\n",
    "                })\n",
    "\n",
    "    cap.release()\n",
    "    return speaker_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5f7b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def identify_unknown_speakers_with_gpt(speaker_frames: dict) -> dict:\n",
    "    \"\"\"\n",
    "    speaker_frames: {\n",
    "        \"SPEAKER_01\": [\n",
    "            {\"time\": ..., \"frame_path\": ..., \"text\": ...},\n",
    "            ...\n",
    "        ],\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    speaker_id_to_name = {}\n",
    "\n",
    "    for speaker_id, frames in speaker_frames.items():\n",
    "        print(f\"\\nüß† ƒêang x·ª≠ l√Ω {speaker_id}...\")\n",
    "\n",
    "        # Chu·∫©n b·ªã prompt ch√≠nh\n",
    "        texts = [f'‚Äú{f[\"text\"]}‚Äù' for f in frames if f.get(\"text\")]\n",
    "        combined_text = \"\\n\".join(texts)  # D√πng t·ªëi ƒëa 3 ƒëo·∫°n transcript\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "This is a collection of frames extracted from a video showing one speaker. Based on their appearance and the following quotes, can you identify who they are or make an educated guess?\n",
    "\n",
    "Quotes:\n",
    "{combined_text}\n",
    "\n",
    "Returns only the speaker's name (no further explanation needed).\n",
    "\n",
    "If you can't tell, reply with \"Unnamed\".\n",
    "\"\"\"\n",
    "\n",
    "        # Chu·∫©n b·ªã ·∫£nh\n",
    "        content_items = [{\"type\": \"input_text\", \"text\": prompt}]\n",
    "        for f in frames:\n",
    "            image_path = f[\"frame_path\"]  # ƒë·∫£m b·∫£o ƒë√∫ng path\n",
    "            try:\n",
    "                base64_image = encode_image(image_path)\n",
    "                content_items.append({\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh {image_path}: {e}\")\n",
    "\n",
    "        # G·ª≠i y√™u c·∫ßu l√™n GPT\n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-4.1-mini\",\n",
    "                input=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": content_items\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            name = response.output_text\n",
    "            speaker_id_to_name[speaker_id] = name\n",
    "            print(f\"‚úÖ {speaker_id} ‚Üí {name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error for {speaker_id}: {e}\")\n",
    "            speaker_id_to_name[speaker_id] = \"Unnamed\"\n",
    "\n",
    "    return speaker_id_to_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11cae5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_named_transcript(transcript, speaker_name_map, new_names):\n",
    "    # B∆∞·ªõc 1: G·ªôp t√™n t·ª´ speaker_name_map v√† new_names\n",
    "    speaker_lookup = {}\n",
    "    for speaker in speaker_name_map.listSpeakers:\n",
    "        speaker_id = speaker.id\n",
    "        name = new_names.get(speaker_id, speaker.name)\n",
    "        speaker_lookup[speaker_id] = name\n",
    "\n",
    "    # B∆∞·ªõc 2: G√°n t√™n r√µ r√†ng v√†o transcript\n",
    "    named_transcript = []\n",
    "    for seg in transcript:\n",
    "        spk = seg['speaker']\n",
    "        if spk == \"unknown\":\n",
    "            display_name = \"Unknown\"\n",
    "        else:\n",
    "            name = speaker_lookup.get(spk, spk)\n",
    "            display_name = name if name != \"Unnamed\" else spk\n",
    "\n",
    "        named_transcript.append({\n",
    "            \"start\": seg[\"start\"],\n",
    "            \"end\": seg[\"end\"],\n",
    "            \"speaker\": display_name,\n",
    "            \"text\": seg[\"text\"]\n",
    "        })\n",
    "\n",
    "    # B∆∞·ªõc 3: G·ªôp c√°c ƒëo·∫°n li√™n ti·∫øp c√πng speaker\n",
    "    if not named_transcript:\n",
    "        return []\n",
    "\n",
    "    merged_transcript = []\n",
    "    current = named_transcript[0]\n",
    "\n",
    "    for seg in named_transcript[1:]:\n",
    "        if seg[\"speaker\"] == current[\"speaker\"]:\n",
    "            # G·ªôp ƒëo·∫°n\n",
    "            current[\"end\"] = seg[\"end\"]\n",
    "            current[\"text\"] += \" \" + seg[\"text\"]\n",
    "        else:\n",
    "            merged_transcript.append(current)\n",
    "            current = seg\n",
    "\n",
    "    merged_transcript.append(current)  # Th√™m ƒëo·∫°n cu·ªëi c√πng\n",
    "    return merged_transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4313bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Statement(BaseModel):\n",
    "    start: float\n",
    "    end: float\n",
    "    speaker: str\n",
    "    text: str\n",
    "    reason: str  # T·∫°i sao c·∫ßn ki·ªÉm ch·ª©ng\n",
    "    context: str\n",
    "\n",
    "class ListStatement(BaseModel):\n",
    "    listStatment: List[Statement]\n",
    "\n",
    "\n",
    "def split_transcript(transcript, chunk_size=100):\n",
    "    \"\"\"Chia transcript th√†nh c√°c ƒëo·∫°n nh·ªè ƒë·ªÉ tr√°nh qu√° d√†i\"\"\"\n",
    "    return [transcript[i:i+chunk_size] for i in range(0, len(transcript), chunk_size)]\n",
    "\n",
    "\n",
    "def find_checkworthy_statements(final_transcript, model=\"gpt-4.1-mini\"):\n",
    "    parts = split_transcript(final_transcript, chunk_size=300)\n",
    "    all_statements = []\n",
    "\n",
    "    for idx, part in enumerate(parts):\n",
    "        print(f\"üîç ƒêang x·ª≠ l√Ω ph·∫ßn {idx+1}/{len(parts)}...\")\n",
    "\n",
    "        # T·∫°o vƒÉn b·∫£n nh·∫≠p\n",
    "        lines = [f\"[{r['start']:.2f}-{r['end']:.2f}] {r['speaker']}: {r['text']}\" for r in part]\n",
    "        input_text = \"\\n\".join(lines)\n",
    "        print(input_text)\n",
    "\n",
    "        prompt = \"\"\"You are a professional fact-checking assistant.\n",
    "            Your job is to extract **checkworthy statements** from transcripts of political events, such as debates, interviews, speeches, or hearings.\n",
    "            Return at **least 2** verifiable statements from 2 different speakers, including unknown speaker (unless there is only 1 speaker, then return 1 statement). If the video is short or has only 1 speaker, extract the entire video.\n",
    "            \n",
    "            A **checkworthy statement** typically:\n",
    "            - Contains a factual claim or statistic.\n",
    "            - Refers to historical events, wars, or political actions.\n",
    "            - Makes a cause-effect claim (e.g., \"if I were president, this would never happen\").\n",
    "            - Assigns blame or credit for an outcome (e.g., war, economy, healthcare).\n",
    "            - Makes bold or controversial public assertions.\n",
    "\n",
    "            Very Important:\n",
    "            - Only extract **entire continuous speaking segments** from a speaker. That is, if a speaker talks for several sentences in one turn (not interrupted by others), you **must return the full segment verbatim**, not just a partial sentence or fragment.\n",
    "            - If a speaker talks multiple times (non-consecutively), treat each turn independently ‚Äî only extract when that turn is checkworthy.\n",
    "\n",
    "            ### Output Format:\n",
    "            Return a list of structured statements in this format:\n",
    "            - `start`: float ‚Üí start time of the speaker‚Äôs turn (in seconds)\n",
    "            - `end`: float ‚Üí end time of the speaker‚Äôs turn (in seconds)\n",
    "            - `speaker`: str ‚Üí name of the speaker\n",
    "            - `text`: str ‚Üí full verbatim text spoken by the speaker in that turn\n",
    "            - `reason`: str ‚Üí short explanation why this is worth fact-checking\n",
    "            - `context`: str ‚Üí provide context including:\n",
    "                + Where the quote was made (e.g., presidential debate, interview, rally) ‚Äî infer if not explicit\n",
    "                + When it happened (date or rough period, e.g., ‚Äúduring the 2024 campaign‚Äù or ‚Äúin June 2025‚Äù)\n",
    "                + The topic under discussion (e.g., foreign policy, war in Ukraine, tax policy)\n",
    "                + Whether the speaker was replying to someone, and what was asked (if known)\n",
    "            \n",
    "            Cannot return null or empty list.\n",
    "          \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.responses.parse(\n",
    "                model=model,\n",
    "                input=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": prompt,\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": input_text,\n",
    "                    },\n",
    "                ],\n",
    "                text_format=ListStatement,\n",
    "            )\n",
    "            statements = response.output_parsed.listStatment\n",
    "            all_statements.extend(statements)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå L·ªói ·ªü ph·∫ßn {idx+1}: {e}\")\n",
    "\n",
    "    return all_statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "535eb539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frame_for_statement(video_path: str, statement, output_dir=\"statement_frames\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    mid_time = (statement.start + statement.end) / 2\n",
    "    frame_num = int(mid_time * fps)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        filename = f\"{statement.speaker}_{int(statement.start*100):06d}.jpg\"\n",
    "        frame_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        return frame_path\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9249f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_statements_from_video(video_path: str):\n",
    "    \"\"\"\n",
    "    Extracts the transcript from a video file.\n",
    "    \"\"\"\n",
    "    print(\"üé¨ Extracting audio...\")\n",
    "    audio_path = extract_audio(video_path)\n",
    "    \n",
    "    print(\"üîä Diarizing speakers...\")\n",
    "    speakers = diarize_audio(audio_path)\n",
    "    \n",
    "    print(\"üìù Transcribing...\")\n",
    "    segments = transcribe_audio(audio_path)\n",
    "    \n",
    "    print(\"üë• Assigning speakers...\")\n",
    "    transcript = assign_speakers(segments, speakers)\n",
    "\n",
    "    print(\"üß† Inferring speaker names from transcript...\")\n",
    "    speaker_name_map = identify_speaker_names_via_text(transcript)\n",
    "    \n",
    "    print(\"üñºÔ∏è Extracting frames for unknown speakers...\")\n",
    "    speaker_frames = extract_frames_for_unknown_speakers(video_path, transcript, speaker_name_map)\n",
    "    \n",
    "    print(\"ü§ñ Identifying unknown speakers with GPT...\")\n",
    "    new_names = identify_unknown_speakers_with_gpt(speaker_frames)\n",
    "\n",
    "    print(\"üìú Generating final transcript...\")\n",
    "    final = generate_named_transcript(transcript, speaker_name_map, new_names)\n",
    "    \n",
    "    print(\"üîç Finding checkworthy statements...\")\n",
    "    final_statements = find_checkworthy_statements(final)\n",
    "    \n",
    "    if not final_statements:\n",
    "        print(\"‚ùå No checkworthy statements found.\")\n",
    "        final_statements = find_checkworthy_statements(final)\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(final_statements)} checkworthy statements.\")\n",
    "    \n",
    "    final_statements_json = []\n",
    "\n",
    "    for s in final_statements:\n",
    "        frame_path = extract_frame_for_statement(video_path, s)\n",
    "\n",
    "        statement_dict = s.dict()\n",
    "        statement_dict[\"frame_path\"] = frame_path or \"N/A\"\n",
    "\n",
    "        final_statements_json.append(statement_dict)\n",
    "    \n",
    "    return final_statements_json\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb3c65",
   "metadata": {},
   "source": [
    "# Part 3: Deepfake prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "391d1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_video_into_clips(final_statements_json, video_path: str):\n",
    "    \"\"\"\n",
    "    Cuts the video into clips based on the provided statements.\n",
    "    Ensures clip end time does not exceed video duration.\n",
    "    \"\"\"\n",
    "    clip_dir = os.path.join(\"statement_clips\", os.path.splitext(os.path.basename(video_path))[0])\n",
    "    \n",
    "    # T·∫°o th∆∞ m·ª•c ho·∫∑c d·ªçn s·∫°ch n·∫øu ƒë√£ t·ªìn t·∫°i\n",
    "    os.makedirs(clip_dir, exist_ok=True)\n",
    "    for f in os.listdir(clip_dir):\n",
    "        file_path = os.path.join(clip_dir, f)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "\n",
    "    # Load video ƒë·ªÉ l·∫•y th·ªùi l∆∞·ª£ng th·ª±c t·∫ø\n",
    "    full_video = VideoFileClip(video_path)\n",
    "    video_duration = full_video.duration\n",
    "    \n",
    "    # Ki·ªÉm tra n·∫øu final_statements_json ch·ªâ c√≥ m·ªôt ph·∫ßn t·ª≠ th√¨ l·∫•y to√†n b·ªô video l∆∞u v√†o clip_dir\n",
    "    if len(final_statements_json) == 1:\n",
    "        clip_path = os.path.join(clip_dir, \"clip_1.mp4\")\n",
    "        print(f\"‚úÇÔ∏è Cutting full video to {clip_path}\")\n",
    "        full_video.write_videofile(clip_path, codec=\"libx264\", audio_codec=\"aac\", verbose=False, logger=None)\n",
    "        full_video.close()\n",
    "        return clip_dir\n",
    "\n",
    "    for i, s in enumerate(final_statements_json):\n",
    "        start, end = float(s['start']), float(s['end'])\n",
    "\n",
    "        # B·ªè qua n·∫øu start v∆∞·ª£t qu√° th·ªùi l∆∞·ª£ng video\n",
    "        if start >= video_duration:\n",
    "            print(f\"‚ö†Ô∏è Skip clip_{i+1}: start time {start:.2f}s >= video duration {video_duration:.2f}s\")\n",
    "            continue\n",
    "\n",
    "        # Gi·ªõi h·∫°n end kh√¥ng v∆∞·ª£t qu√° video\n",
    "        end = min(end, video_duration)\n",
    "\n",
    "        clip_path = os.path.join(clip_dir, f\"clip_{i+1}.mp4\")\n",
    "        print(f\"‚úÇÔ∏è Cutting {clip_path} from {start:.2f}s to {end:.2f}s\")\n",
    "\n",
    "        clip = full_video.subclip(start, end)\n",
    "        clip.write_videofile(clip_path, codec=\"libx264\", audio_codec=\"aac\", verbose=False, logger=None)\n",
    "\n",
    "    full_video.close()\n",
    "    print(f\"‚úÖ Finished cutting video into clips. Saved to {clip_dir}\")\n",
    "    return clip_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2abe0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_api_detect_deepfake(clip_dir: str):\n",
    "    \"\"\"\n",
    "    Detects deepfake in the video clips.\n",
    "    \"\"\"\n",
    "    # T·∫°o danh s√°ch file ƒë·ªÉ g·ª≠i\n",
    "    video_files = []\n",
    "    for filename in os.listdir(clip_dir):\n",
    "        if filename.endswith(\".mp4\"):\n",
    "            file_path = os.path.join(clip_dir, filename)\n",
    "            video_files.append((\"videos\", (filename, open(file_path, \"rb\"), \"video/mp4\")))\n",
    "    \n",
    "    # G·ª≠i y√™u c·∫ßu POST\n",
    "    print(\"üì§ Sending batch videos to deepfake API...\")\n",
    "    response = requests.post(API_URL, files=video_files)\n",
    "\n",
    "    # K·∫øt qu·∫£\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(\"‚úÖ Detection results:\")\n",
    "        for fname, r in result.items():\n",
    "            print(f\"{fname}: {r}\")\n",
    "        return result\n",
    "    else:\n",
    "        print(f\"‚ùå Error {response.status_code}: {response.text}\")\n",
    "        \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1987dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_deepfake(final_statements_json, video_path: str):\n",
    "    \"\"\"\n",
    "    Main function to detect deepfake in the video.\n",
    "    \"\"\"\n",
    "    print(\"üé• Cutting video into clips...\")\n",
    "    \n",
    "    clip_dir = cut_video_into_clips(final_statements_json, video_path)\n",
    "\n",
    "    print(\"üîç Detecting deepfake in clips...\")\n",
    "    results = call_api_detect_deepfake(clip_dir)\n",
    "\n",
    "    for idx, statement in enumerate(final_statements_json):\n",
    "        clip_name = f\"clip_{idx+1}.mp4\"\n",
    "        result = results.get(clip_name, {})\n",
    "        \n",
    "        # L·∫•y nh√£n deepfake n·∫øu c√≥\n",
    "        label = result[\"pred_label\"][0]\n",
    "        pred_score = result[\"pred\"][0]\n",
    "        \n",
    "        # G·∫Øn v√†o statement\n",
    "        statement[\"deepfake_label\"] = label\n",
    "        statement[\"deepfake_score\"] = pred_score\n",
    "    \n",
    "    print(\"‚úÖ Finished detecting deepfake.\")\n",
    "    return final_statements_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58286fb",
   "metadata": {},
   "source": [
    "# Part 4: Crawl related articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb4cd42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_relevant_links(query):\n",
    "  driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "  prompt = f'https://www.bing.com/search?q={query}'\n",
    "  print(prompt)\n",
    "  driver.get(prompt)\n",
    "  time.sleep(random.uniform(1, 10))\n",
    "  # print(driver.page_source)\n",
    "\n",
    "  articles = driver.find_elements(By.CSS_SELECTOR, \"#b_results li.b_algo\")\n",
    "  link_articles = []\n",
    "  link_articles.append({\n",
    "      'title': query[:30],\n",
    "      'link': prompt,\n",
    "      # 'summary': summary\n",
    "  })\n",
    "  print(f\"Found {len(articles)} relevant links:\\n{articles}\")\n",
    "  for article in articles[:MINIMUM_K]:  # Gi·ªõi h·∫°n l·∫•y 5 k·∫øt qu·∫£ ƒë·∫ßu ti√™n\n",
    "    try:\n",
    "      title_element = article.find_element(By.TAG_NAME, \"h2\").find_element(By.TAG_NAME, \"a\")\n",
    "      title = title_element.text\n",
    "      link = title_element.get_attribute('href')\n",
    "      # summary = article.find_element(By.CLASS_NAME, 'css-16nhkrn').text\n",
    "      # local = local_query(link)\n",
    "      link_articles.append({\n",
    "          'title': title,\n",
    "          'link': link,\n",
    "          # 'summary': summary\n",
    "      })\n",
    "      print(title)\n",
    "      print(link)\n",
    "    except Exception as e:\n",
    "        print(\"L·ªói khi tr√≠ch xu·∫•t b√†i vi·∫øt:\", e)\n",
    "  driver.quit()\n",
    "\n",
    "  print(f\"Found {len(link_articles)} relevant links:\\n{link_articles}\")\n",
    "\n",
    "  return link_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "376faf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_dismiss_popups(driver):\n",
    "    try:\n",
    "        # C√°c n√∫t ph·ªï bi·∫øn c·∫ßn nh·∫•n\n",
    "        popup_texts = [\n",
    "            \"Accept Cookies\", \"Accept All Cookies\", \"I Accept\",\n",
    "            \"Agree\", \"Press & Hold\", \"Continue\"\n",
    "        ]\n",
    "        for text in popup_texts:\n",
    "            try:\n",
    "                btn = driver.find_element(\n",
    "                    By.XPATH,\n",
    "                    f\"//button[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{text.lower()}')]\"\n",
    "                )\n",
    "                btn.click()\n",
    "                print(f\"‚úÖ Clicked popup button: '{text}'\")\n",
    "                break\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "            except ElementClickInterceptedException:\n",
    "                continue\n",
    "\n",
    "        # T√¨m c√°c n√∫t c√≥ class name ch·ª©a 'close'\n",
    "        close_candidates = driver.find_elements(By.XPATH, \"//button[contains(@class, 'close') or contains(translate(@aria-label, 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'close')]\")\n",
    "\n",
    "        for btn in close_candidates:\n",
    "            try:\n",
    "                btn.click()\n",
    "                print(\"‚úÖ Clicked a close button\")\n",
    "                break\n",
    "            except (ElementClickInterceptedException, Exception):\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error while dismissing popup: {e}\")\n",
    "\n",
    "def process_article_link(article, max_retries=5):\n",
    "    \"\"\"H√†m x·ª≠ l√Ω m·ªôt li√™n k·∫øt ri√™ng l·∫ª v√† tr·∫£ v·ªÅ n·ªôi dung g·ªôp c√°c th·∫ª <p>\"\"\"\n",
    "    article_crawl = {\n",
    "        \"title\": article['title'],\n",
    "        \"src\": article['link'],\n",
    "        \"contents\": \"\"  # g·ªôp t·∫•t c·∫£ <p> v√†o 1 chu·ªói\n",
    "    }\n",
    "\n",
    "    success = False\n",
    "    wait_time = 10  # th·ªùi gian ch·ªù ban ƒë·∫ßu (gi√¢y)\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        try:\n",
    "            print(f\"‚è≥ Attempt {attempt}: Crawling {article['link']} with wait_time={wait_time}s\")\n",
    "            driver.get(article['link'])\n",
    "            time.sleep(wait_time)\n",
    "            try_dismiss_popups(driver)\n",
    "\n",
    "            all_elements = driver.find_elements(By.XPATH, \".//p\")\n",
    "            contents = []\n",
    "\n",
    "            for element in all_elements:\n",
    "                if element.tag_name == \"p\":\n",
    "                    text_content = element.get_attribute(\"innerText\").strip()\n",
    "                    if text_content:\n",
    "                        contents.append(text_content)\n",
    "\n",
    "            article_crawl[\"contents\"] = \"\\n\".join(contents)\n",
    "            print(f'‚úÖ Crawled content from {article[\"link\"]}:\\n{article_crawl[\"contents\"][:500]}...')  # in 500 k√Ω t·ª± ƒë·∫ßu ti√™n\n",
    "            success = True\n",
    "            break  # th√†nh c√¥ng th√¨ tho√°t\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Attempt {attempt} failed for {article['link']}: {e}\")\n",
    "            wait_time += 300  # tƒÉng th·ªùi gian ch·ªù th√™m 10s cho m·ªói l·∫ßn th·ª≠ l·∫°i\n",
    "\n",
    "        finally:\n",
    "            driver.quit()\n",
    "\n",
    "    if not success:\n",
    "        print(f\"‚ùå Failed to crawl article from {article['link']} after {max_retries} attempts.\")\n",
    "\n",
    "    return article_crawl\n",
    "\n",
    "\n",
    "\n",
    "def crawl_articles(query, crawl_json):\n",
    "    \"\"\"H√†m ch√≠nh ƒë·ªÉ crawl c√°c trang kh√°c\"\"\"\n",
    "    url_articles = search_relevant_links(query)\n",
    "\n",
    "    # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng link c·∫ßn crawl\n",
    "    url_articles = url_articles[:MINIMUM_K]\n",
    "\n",
    "    # S·ª≠ d·ª•ng Multi-threading ƒë·ªÉ ch·∫°y nhi·ªÅu request song song\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        result = list(executor.map(process_article_link, url_articles))\n",
    "\n",
    "    # G·ªôp k·∫øt qu·∫£ v√†o crawl_json\n",
    "    crawl_json.extend(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65af687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_statement(statement):\n",
    "    try:\n",
    "        query = statement[\"text\"].strip('\"')\n",
    "        crawl_json = []\n",
    "\n",
    "        # Crawl theo statement\n",
    "        crawl_articles(query, crawl_json=crawl_json)\n",
    "\n",
    "        # Crawl th√™m theo context\n",
    "        context = statement[\"context\"]\n",
    "        crawl_articles(query=context, crawl_json=crawl_json)\n",
    "\n",
    "        # Lo·∫°i b·ªè c√°c k·∫øt qu·∫£ None\n",
    "        crawl_json = [item for item in crawl_json if item is not None]\n",
    "\n",
    "        # N·ªëi l·∫°i to√†n b·ªô n·ªôi dung: th√™m title v√† content m·ªói b√†i\n",
    "        article_texts = \"\\n\\n\".join(\n",
    "            f\"### {item.get('title', 'No Title')}\\n{item.get('contents', '').strip()}\"\n",
    "            for item in crawl_json\n",
    "            if item.get(\"contents\")\n",
    "        )\n",
    "\n",
    "        # Tr·∫£ l·∫°i enriched statement\n",
    "        enriched_statement = statement.copy()\n",
    "        enriched_statement[\"article_texts\"] = article_texts.strip()\n",
    "\n",
    "        return enriched_statement\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing statement {statement['text']}: {e}\")\n",
    "        enriched_statement = statement.copy()\n",
    "        enriched_statement[\"article_texts\"] = \"\"\n",
    "        return enriched_statement\n",
    "\n",
    "\n",
    "def enrich_statements_with_articles(final_statements_json):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        return list(executor.map(process_single_statement, final_statements_json))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577ea3f",
   "metadata": {},
   "source": [
    "# Part 5: Fact-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7666d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactCheck(BaseModel):\n",
    "    label: bool  # True = SUPPORTED, False = REFUTED\n",
    "\n",
    "def fact_check(statement):\n",
    "    prompt = f\"\"\"\n",
    "You are a professional fact-checking assistant. Your task is to determine whether a specific statement made by a public figure is **factually accurate and verifiably attributed to them**, using only the provided reference documents.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "Follow this strict two-step verification process:\n",
    "\n",
    "1. **Check if the speaker truly made the statement**:\n",
    "   - Search the reference documents to confirm whether the speaker is explicitly or clearly quoted as saying this or something semantically equivalent.\n",
    "   - If you find strong evidence that the speaker made the statement, continue to step 2.\n",
    "   - If **no such quote or attribution** exists in the documents, set:\n",
    "     - **label = false**\n",
    "     - and stop. Do not proceed to step 2.\n",
    "\n",
    "2. **Evaluate the factual accuracy** of the statement using only the reference materials:\n",
    "   - If it is directly supported by the documents, set `label = true`.\n",
    "   - If it is **partially true, misleading, or contradicted**, or if the documents **do not support** it clearly, set `label = false`.\n",
    "\n",
    "**Important Guidelines:**\n",
    "- Use only the reference documents. Do not assume or infer information.\n",
    "- If unsure, default to `label = false`.\n",
    "- Be skeptical: only statements that are clearly made and clearly true should be labeled `true`.\n",
    "\n",
    "### Context:\n",
    "{statement['context']}\n",
    "\n",
    "### Speaker:\n",
    "{statement['speaker']}\n",
    "\n",
    "### Statement:\n",
    "\"{statement['text']}\"\n",
    "\n",
    "### Documents:\n",
    "{statement['article_texts']}\n",
    "\n",
    "### Output format:\n",
    "label: true or false\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.responses.parse(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a medical fact-checking expert.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            text_format=FactCheck\n",
    "        )\n",
    "        result = response.output_parsed\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Problem with API: {e}\")\n",
    "        result = \"Unverified\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9219172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_check_single_statement(statement):\n",
    "    print(statement)\n",
    "    text = statement[\"text\"]\n",
    "\n",
    "    print(f\"üßê Fact-checking: {text[:80]}...\")\n",
    "\n",
    "    result = fact_check(statement)\n",
    "\n",
    "    if result == \"Unverified\":\n",
    "        statement[\"label\"] = None\n",
    "        print(\"‚ùå Unable to verify statement.\")\n",
    "    else:\n",
    "        statement[\"label\"] = result.label\n",
    "\n",
    "    return statement\n",
    "\n",
    "\n",
    "def run_fact_checks_parallel(enriched_statements, max_workers=4):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(fact_check_single_statement, enriched_statements))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7acd2a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_check_video(video_path: str):\n",
    "    \"\"\"\n",
    "    Main function to fact-check the video.\n",
    "    \"\"\"\n",
    "    print(\"üé• Extracting statements from video...\")\n",
    "    final_statements_json = extract_statements_from_video(video_path)\n",
    "    print(final_statements_json)\n",
    "\n",
    "    print(\"üîç Detecting deepfake...\")\n",
    "    final_statements_json = detect_deepfake(final_statements_json, video_path)\n",
    "    \n",
    "    print(\"‚úÖ Finished detecting deepfake.\")\n",
    "    print(final_statements_json)\n",
    "    \n",
    "    for statement in final_statements_json:\n",
    "        if statement[\"deepfake_label\"] == \"FAKE\":\n",
    "            print(f\"‚ö†Ô∏è Statement {statement['text']} is marked as deepfake. Skipping fact-check.\")\n",
    "            return {\n",
    "                \"deepfake_label\": \"FAKE\",\n",
    "                \"label\": False,\n",
    "                \"statements\": final_statements_json\n",
    "            }\n",
    "\n",
    "\n",
    "    print(\"üì∞ Enriching statements with articles...\")\n",
    "    enriched_statements = enrich_statements_with_articles(final_statements_json)\n",
    "\n",
    "    print(\"‚úÖ Finished enriching statements with articles.\")\n",
    "\n",
    "    print(\"üß™ Running fact-checks on statements...\")\n",
    "    fact_checked_results = run_fact_checks_parallel(enriched_statements)\n",
    "    fact_checked_results\n",
    "\n",
    "    for result in fact_checked_results:\n",
    "        if result[\"label\"] == \"False\":\n",
    "            print(f\"‚ùå Statement '{result['text']}' is refuted: {result['explanation']}\")\n",
    "            return {\n",
    "                \"deepfake_label\": \"REAL\",\n",
    "                \"label\": False,\n",
    "                \"statements\": fact_checked_results\n",
    "            }\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"‚úÖ All statements are supported or unverified.\")\n",
    "    return {\n",
    "        \"deepfake_label\": \"REAL\",\n",
    "        \"label\": True,\n",
    "        \"statements\": fact_checked_results\n",
    "    }\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3adb3af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = fact_check_video(\"../data/dfw_youtube_release/1.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c22a2185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e615209e",
   "metadata": {},
   "source": [
    "# Part 6: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30458e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# INPUT_FILE = \"fact_check_results.json\"\n",
    "# OUTPUT_FILE = \"fact_check_results_reverified.json\"\n",
    "\n",
    "# # üëá C·∫•u h√¨nh v√πng c·∫ßn x·ª≠ l√Ω\n",
    "# START_INDEX = 0   # ch·ªânh th√†nh 100, 200... n·∫øu mu·ªën\n",
    "# NUM_ITEMS = 150    # s·ªë l∆∞·ª£ng video b·∫°n mu·ªën x·ª≠ l√Ω l·∫°i\n",
    "\n",
    "# # ƒê·ªçc to√†n b·ªô d·ªØ li·ªáu g·ªëc\n",
    "# with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "#     all_results = json.load(f)\n",
    "\n",
    "# # C·∫Øt ra ph·∫ßn b·∫°n mu·ªën ki·ªÉm tra l·∫°i\n",
    "# target_results = all_results[START_INDEX: START_INDEX + NUM_ITEMS]\n",
    "\n",
    "# # N·∫øu mu·ªën gi·ªØ l·∫°i ph·∫ßn tr∆∞·ªõc v√† sau kh√¥ng thay ƒë·ªïi:\n",
    "# prefix = all_results[:START_INDEX]\n",
    "# suffix = all_results[START_INDEX + NUM_ITEMS:]\n",
    "\n",
    "# reverified_results = []\n",
    "\n",
    "# for item in target_results:\n",
    "#     if item.get(\"label\") != True:\n",
    "#         reverified_results.append(item)\n",
    "#         continue\n",
    "\n",
    "#     print(f\"üîç Re-checking statements for {item['video_path']}\")\n",
    "\n",
    "#     statements = item.get(\"statements\", [])\n",
    "#     if not statements:\n",
    "#         print(\"‚ö†Ô∏è No statements found, skipping...\")\n",
    "#         reverified_results.append(item)\n",
    "#         continue\n",
    "#     rechecked_statements = run_fact_checks_parallel(statements)\n",
    "\n",
    "#     all_true = all(st.get(\"label\") is True for st in rechecked_statements)\n",
    "\n",
    "#     reverified_item = {\n",
    "#         \"video_path\": item[\"video_path\"],\n",
    "#         \"deepfake_label\": item[\"deepfake_label\"],\n",
    "#         \"label\": all_true,\n",
    "#         \"statements\": rechecked_statements\n",
    "#     }\n",
    "\n",
    "#     reverified_results.append(reverified_item)\n",
    "\n",
    "# # G·ªôp l·∫°i to√†n b·ªô k·∫øt qu·∫£\n",
    "# final_output = prefix + reverified_results + suffix\n",
    "\n",
    "# # L∆∞u v√†o file m·ªõi\n",
    "# with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(final_output, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# print(f\"‚úÖ Done. Saved reverified results to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d941d1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìº Processing video 550: ../data/dfw_youtube_release\\549.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\549.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-43.90] Unknown: Mes chers compatriotes, l'ann√©e 2020 d√©marre en fond phare, l'Australie se meurt sous les flammes, et gr√¢ce √† un ing√©nieu d'Honald Trump, nous sommes au bord d'une troisi√®me guerre mondiale avec l'Iran, mais √† part √ßa, tout va bien. Gouvernement annonc√©e un rappel des couches Carlos Gone pour lutter contre les fuites, visiblement, elles √©taient perc√©es. Apr√®s les Golden Globes, Carlos Gone pourrait bien √™tre nomm√© aux Oscars, pour son remake de la Grande Evasion, chez d'≈ìuvre de John Sturgeuse avec Steve McQueen. Rendez-vous compte, il s'√©tait chaper du Japon, et malgr√© un pr√©nom comme le Sien, Carlos n'a rien d'ent√©roriste.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 43.9, 'speaker': 'Unknown', 'text': \"Mes chers compatriotes, l'ann√©e 2020 d√©marre en fond phare, l'Australie se meurt sous les flammes, et gr√¢ce √† un ing√©nieu d'Honald Trump, nous sommes au bord d'une troisi√®me guerre mondiale avec l'Iran, mais √† part √ßa, tout va bien. Gouvernement annonc√©e un rappel des couches Carlos Gone pour lutter contre les fuites, visiblement, elles √©taient perc√©es. Apr√®s les Golden Globes, Carlos Gone pourrait bien √™tre nomm√© aux Oscars, pour son remake de la Grande Evasion, chez d'≈ìuvre de John Sturgeuse avec Steve McQueen. Rendez-vous compte, il s'√©tait chaper du Japon, et malgr√© un pr√©nom comme le Sien, Carlos n'a rien d'ent√©roriste.\", 'reason': 'Contains multiple factual claims about events occurring in 2020 including Australian wildfires, near conflict involving Iran attributed to actions by Donald Trump, government product recall, and entertainment industry references.', 'context': 'Spoken by an unknown speaker in a monologue likely from a news commentary or satire segment early in 2020, discussing major global events including natural disasters, international relations, and entertainment.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\549\\clip_1.mp4\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['a8b7318bec5c4ef88d96213b38e0a73a_clip_1.mp4'], 'pred': [0.7775588035583496], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 43.9, 'speaker': 'Unknown', 'text': \"Mes chers compatriotes, l'ann√©e 2020 d√©marre en fond phare, l'Australie se meurt sous les flammes, et gr√¢ce √† un ing√©nieu d'Honald Trump, nous sommes au bord d'une troisi√®me guerre mondiale avec l'Iran, mais √† part √ßa, tout va bien. Gouvernement annonc√©e un rappel des couches Carlos Gone pour lutter contre les fuites, visiblement, elles √©taient perc√©es. Apr√®s les Golden Globes, Carlos Gone pourrait bien √™tre nomm√© aux Oscars, pour son remake de la Grande Evasion, chez d'≈ìuvre de John Sturgeuse avec Steve McQueen. Rendez-vous compte, il s'√©tait chaper du Japon, et malgr√© un pr√©nom comme le Sien, Carlos n'a rien d'ent√©roriste.\", 'reason': 'Contains multiple factual claims about events occurring in 2020 including Australian wildfires, near conflict involving Iran attributed to actions by Donald Trump, government product recall, and entertainment industry references.', 'context': 'Spoken by an unknown speaker in a monologue likely from a news commentary or satire segment early in 2020, discussing major global events including natural disasters, international relations, and entertainment.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.7775588035583496}]\n",
      "‚ö†Ô∏è Statement Mes chers compatriotes, l'ann√©e 2020 d√©marre en fond phare, l'Australie se meurt sous les flammes, et gr√¢ce √† un ing√©nieu d'Honald Trump, nous sommes au bord d'une troisi√®me guerre mondiale avec l'Iran, mais √† part √ßa, tout va bien. Gouvernement annonc√©e un rappel des couches Carlos Gone pour lutter contre les fuites, visiblement, elles √©taient perc√©es. Apr√®s les Golden Globes, Carlos Gone pourrait bien √™tre nomm√© aux Oscars, pour son remake de la Grande Evasion, chez d'≈ìuvre de John Sturgeuse avec Steve McQueen. Rendez-vous compte, il s'√©tait chaper du Japon, et malgr√© un pr√©nom comme le Sien, Carlos n'a rien d'ent√©roriste. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\549.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 550 videos\n",
      "üìº Processing video 551: ../data/dfw_youtube_release\\550.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\550.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_03...\n",
      "‚úÖ SPEAKER_03 ‚Üí Homelander\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_02...\n",
      "‚úÖ SPEAKER_02 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-19.00] Unknown: ‰ªäÂ§©ÊúÉÊàë been a lovely—Ü–æ –∏–∑inton Richards good boys ok?\n",
      "[19.40-22.00] Homelander: What makes you think I would give a fuck to that guy?\n",
      "[26.00-28.52] SPEAKER_01: If I're gonnager for my brother he costs hell–∏—Ç—å\n",
      "[28.52-32.04] SPEAKER_02: Listen.\n",
      "[32.04-61.86] Unknown: The The The The The The The The The The The These violence will not benefit any indulgence. We have all seen the game of opportunists who have tried to take advantage of\n",
      "[61.86-74.10] SPEAKER_00: the sincere colors to send them. We have all seen the irresponsible political actions in the only project was to boost the public's reputation, looking for the disorder and the energy.\n",
      "‚úÖ Found 2 checkworthy statements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 32.04, 'end': 61.86, 'speaker': 'Unknown', 'text': 'The The The The The The The The The The The These violence will not benefit any indulgence. We have all seen the game of opportunists who have tried to take advantage of', 'reason': 'The speaker claims that violence does not benefit anyone and highlights opportunists exploiting situations, which is a political and social claim worth verifying.', 'context': \"Likely during a political or social commentary segment, roughly in current times, discussing violence and society's opportunists responding to conflict or crisis.\", 'frame_path': 'statement_frames\\\\Unknown_003204.jpg'}, {'start': 61.86, 'end': 74.1, 'speaker': 'SPEAKER_00', 'text': \"the sincere colors to send them. We have all seen the irresponsible political actions in the only project was to boost the public's reputation, looking for the disorder and the energy.\", 'reason': 'This statement alleges irresponsible political actions motivated by reputation-boosting and causing disorder, a claim that implicates political actors and warrants fact-checking.', 'context': 'Likely part of the same political or social commentary as the prior statement, focused on political accountability and public reputation during a social or political event.', 'frame_path': 'statement_frames\\\\SPEAKER_00_006186.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\550\\clip_1.mp4 from 32.04s to 61.86s\n",
      "‚úÇÔ∏è Cutting statement_clips\\550\\clip_2.mp4 from 61.86s to 74.10s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\550\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['c07921988111416d8b900a5fc7b0e856_clip_1.mp4'], 'pred': [0.4412936568260193], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['59feeec12f2a4c7f97dae421cc94a77c_clip_2.mp4'], 'pred': [0.3603633642196655], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 32.04, 'end': 61.86, 'speaker': 'Unknown', 'text': 'The The The The The The The The The The The These violence will not benefit any indulgence. We have all seen the game of opportunists who have tried to take advantage of', 'reason': 'The speaker claims that violence does not benefit anyone and highlights opportunists exploiting situations, which is a political and social claim worth verifying.', 'context': \"Likely during a political or social commentary segment, roughly in current times, discussing violence and society's opportunists responding to conflict or crisis.\", 'frame_path': 'statement_frames\\\\Unknown_003204.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.4412936568260193}, {'start': 61.86, 'end': 74.1, 'speaker': 'SPEAKER_00', 'text': \"the sincere colors to send them. We have all seen the irresponsible political actions in the only project was to boost the public's reputation, looking for the disorder and the energy.\", 'reason': 'This statement alleges irresponsible political actions motivated by reputation-boosting and causing disorder, a claim that implicates political actors and warrants fact-checking.', 'context': 'Likely part of the same political or social commentary as the prior statement, focused on political accountability and public reputation during a social or political event.', 'frame_path': 'statement_frames\\\\SPEAKER_00_006186.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.3603633642196655}]\n",
      "üì∞ Enriching statements with articles...\n",
      "https://www.bing.com/search?q=the sincere colors to send them. We have all seen the irresponsible political actions in the only project was to boost the public's reputation, looking for the disorder and the energy.\n",
      "https://www.bing.com/search?q=The The The The The The The The The The The These violence will not benefit any indulgence. We have all seen the game of opportunists who have tried to take advantage of\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"4321c09127cae2a8f5d1ec6a7f26952f\", element=\"f.535E1A6CF8B0491BA842B36544873FF3.d.CB8BE8DD807842D363C15772F994C1B0.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4321c09127cae2a8f5d1ec6a7f26952f\", element=\"f.535E1A6CF8B0491BA842B36544873FF3.d.CB8BE8DD807842D363C15772F994C1B0.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4321c09127cae2a8f5d1ec6a7f26952f\", element=\"f.535E1A6CF8B0491BA842B36544873FF3.d.CB8BE8DD807842D363C15772F994C1B0.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4321c09127cae2a8f5d1ec6a7f26952f\", element=\"f.535E1A6CF8B0491BA842B36544873FF3.d.CB8BE8DD807842D363C15772F994C1B0.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4321c09127cae2a8f5d1ec6a7f26952f\", element=\"f.535E1A6CF8B0491BA842B36544873FF3.d.CB8BE8DD807842D363C15772F994C1B0.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4321c09127cae2a8f5d1ec6a7f26952f\", element=\"f.535E1A6CF8B0491BA842B36544873FF3.d.CB8BE8DD807842D363C15772F994C1B0.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4321c09127cae2a8f5d1ec6a7f26952f\", element=\"f.535E1A6CF8B0491BA842B36544873FF3.d.CB8BE8DD807842D363C15772F994C1B0.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4321c09127cae2a8f5d1ec6a7f26952f\", element=\"f.535E1A6CF8B0491BA842B36544873FF3.d.CB8BE8DD807842D363C15772F994C1B0.e.27\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4321c09127cae2a8f5d1ec6a7f26952f\", element=\"f.535E1A6CF8B0491BA842B36544873FF3.d.CB8BE8DD807842D363C15772F994C1B0.e.28\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4321c09127cae2a8f5d1ec6a7f26952f\", element=\"f.535E1A6CF8B0491BA842B36544873FF3.d.CB8BE8DD807842D363C15772F994C1B0.e.29\")>]\n",
      "Philosophical Quotes on Violence - ThoughtCo\n",
      "https://www.thoughtco.com/philosophical-quotes-on-violence-2670550\n",
      "Robert A. Heinlein Quotes About Violence | A-Z Quotes\n",
      "https://www.azquotes.com/author/6509-Robert_A_Heinlein/tag/violence\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"7576677caab9508875226fb2cbea880c\", element=\"f.D0D249472F1391B5D4F33EBBF4646B80.d.F3670F312AC54993D9421C055BC1D6FE.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"7576677caab9508875226fb2cbea880c\", element=\"f.D0D249472F1391B5D4F33EBBF4646B80.d.F3670F312AC54993D9421C055BC1D6FE.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"7576677caab9508875226fb2cbea880c\", element=\"f.D0D249472F1391B5D4F33EBBF4646B80.d.F3670F312AC54993D9421C055BC1D6FE.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"7576677caab9508875226fb2cbea880c\", element=\"f.D0D249472F1391B5D4F33EBBF4646B80.d.F3670F312AC54993D9421C055BC1D6FE.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"7576677caab9508875226fb2cbea880c\", element=\"f.D0D249472F1391B5D4F33EBBF4646B80.d.F3670F312AC54993D9421C055BC1D6FE.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"7576677caab9508875226fb2cbea880c\", element=\"f.D0D249472F1391B5D4F33EBBF4646B80.d.F3670F312AC54993D9421C055BC1D6FE.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"7576677caab9508875226fb2cbea880c\", element=\"f.D0D249472F1391B5D4F33EBBF4646B80.d.F3670F312AC54993D9421C055BC1D6FE.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"7576677caab9508875226fb2cbea880c\", element=\"f.D0D249472F1391B5D4F33EBBF4646B80.d.F3670F312AC54993D9421C055BC1D6FE.e.27\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"7576677caab9508875226fb2cbea880c\", element=\"f.D0D249472F1391B5D4F33EBBF4646B80.d.F3670F312AC54993D9421C055BC1D6FE.e.28\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"7576677caab9508875226fb2cbea880c\", element=\"f.D0D249472F1391B5D4F33EBBF4646B80.d.F3670F312AC54993D9421C055BC1D6FE.e.29\")>]\n",
      "30 Examples: How To Apologize for a Mistake Professionally\n",
      "https://status.net/articles/apologize-mistake-professionally-examples/\n",
      "How to write apology emails with 10 samples and a ‚Ä¶\n",
      "https://www.maestrolabs.com/how-to/apology-email\n",
      "Found 3 relevant links:\n",
      "[{'title': 'the sincere colors to send the', 'link': \"https://www.bing.com/search?q=the sincere colors to send them. We have all seen the irresponsible political actions in the only project was to boost the public's reputation, looking for the disorder and the energy.\"}, {'title': '30 Examples: How To Apologize for a Mistake Professionally', 'link': 'https://status.net/articles/apologize-mistake-professionally-examples/'}, {'title': 'How to write apology emails with 10 samples and a ‚Ä¶', 'link': 'https://www.maestrolabs.com/how-to/apology-email'}]Found 3 relevant links:\n",
      "[{'title': 'The The The The The The The Th', 'link': 'https://www.bing.com/search?q=The The The The The The The The The The The These violence will not benefit any indulgence. We have all seen the game of opportunists who have tried to take advantage of'}, {'title': 'Philosophical Quotes on Violence - ThoughtCo', 'link': 'https://www.thoughtco.com/philosophical-quotes-on-violence-2670550'}, {'title': 'Robert A. Heinlein Quotes About Violence | A-Z Quotes', 'link': 'https://www.azquotes.com/author/6509-Robert_A_Heinlein/tag/violence'}]\n",
      "\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=The The The The The The The The The The The These violence will not benefit any indulgence. We have all seen the game of opportunists who have tried to take advantage of with wait_time=10s‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=the sincere colors to send them. We have all seen the irresponsible political actions in the only project was to boost the public's reputation, looking for the disorder and the energy. with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://www.thoughtco.com/philosophical-quotes-on-violence-2670550 with wait_time=10s\n",
      "\n",
      "‚è≥ Attempt 1: Crawling https://status.net/articles/apologize-mistake-professionally-examples/ with wait_time=10s\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=The The The The The The The The The The The These violence will not benefit any indulgence. We have all seen the game of opportunists who have tried to take advantage of:\n",
      "Intolerance is itself a form of violence and an obstacle to the growth of a true democratic spirit. Violent means will give violent freedom. That would be a menace to the world and to India ‚Ä¶\n",
      "Apr 6, 2015¬†¬∑ Here you will learn the surprising truth about violence and how we have stigmatized the study of violence to the point that only the criminal elements have access to it. A former military...\n",
      "Jun 30, 2025¬†¬∑ The moment the slave resolves that he will no longer be a slave, his fetters fall. He fr...\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=the sincere colors to send them. We have all seen the irresponsible political actions in the only project was to boost the public's reputation, looking for the disorder and the energy.:\n",
      "Nov 23, 2011¬†¬∑ Here are some more business email and letter phrases. In this list we look at how to make requests, complain, apologise and give bad news. The examples in the left column are more formal. The right-hand column shows ‚Ä¶\n",
      "Recognizing when you‚Äôve made a mistake and displaying genuine regret is a valuable skill for building relationships and resolving conflicts professionally. Knowing how to apologize ‚Ä¶\n",
      "When American military men approach some serious situation they are wont to write at...\n",
      "‚úÖ Crawled content from https://www.thoughtco.com/philosophical-quotes-on-violence-2670550:\n",
      "Verify you are human by completing the action below....\n",
      "https://www.bing.com/search?q=Likely during a political or social commentary segment, roughly in current times, discussing violence and society's opportunists responding to conflict or crisis.\n",
      "Found 2 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"e375e7f95adcb380f832d4bd48f5d95c\", element=\"f.AA44FF789CBAD3B916882782B071F303.d.5AE0A5C199C819D924037818E681AA70.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e375e7f95adcb380f832d4bd48f5d95c\", element=\"f.AA44FF789CBAD3B916882782B071F303.d.5AE0A5C199C819D924037818E681AA70.e.21\")>]\n",
      "The Role of Political and Social Commentary in Modern Movies ‚Ä¶\n",
      "https://www.panachehq.com/blog/2025/02/01/the-role-of-political-and-social-commentary-in-modern-movies-and-tv-shows/\n",
      "Social commentary - Wikipedia\n",
      "https://en.wikipedia.org/wiki/Social_commentary\n",
      "Found 3 relevant links:\n",
      "[{'title': 'Likely during a political or s', 'link': \"https://www.bing.com/search?q=Likely during a political or social commentary segment, roughly in current times, discussing violence and society's opportunists responding to conflict or crisis.\"}, {'title': 'The Role of Political and Social Commentary in Modern Movies ‚Ä¶', 'link': 'https://www.panachehq.com/blog/2025/02/01/the-role-of-political-and-social-commentary-in-modern-movies-and-tv-shows/'}, {'title': 'Social commentary - Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Social_commentary'}]\n",
      "‚è≥ Attempt 1: Crawling https://www.panachehq.com/blog/2025/02/01/the-role-of-political-and-social-commentary-in-modern-movies-and-tv-shows/ with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=Likely during a political or social commentary segment, roughly in current times, discussing violence and society's opportunists responding to conflict or crisis. with wait_time=10s\n",
      "‚ö†Ô∏è Attempt 1 failed for https://www.panachehq.com/blog/2025/02/01/the-role-of-political-and-social-commentary-in-modern-movies-and-tv-shows/: Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n",
      "  (Session info: chrome=138.0.7204.158)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x1081a33+62339]\n",
      "\tGetHandleVerifier [0x0x1081a74+62404]\n",
      "\t(No symbol) [0x0xec2123]\n",
      "\t(No symbol) [0x0xebf85b]\n",
      "\t(No symbol) [0x0xeb30d2]\n",
      "\t(No symbol) [0x0xeb4b05]\n",
      "\t(No symbol) [0x0xeb3368]\n",
      "\t(No symbol) [0x0xeb2ea3]\n",
      "\t(No symbol) [0x0xeb2bb1]\n",
      "\t(No symbol) [0x0xeb0b54]\n",
      "\t(No symbol) [0x0xeb14fb]\n",
      "\t(No symbol) [0x0xec5b4e]\n",
      "\t(No symbol) [0x0xf51367]\n",
      "\t(No symbol) [0x0xf2f3bc]\n",
      "\t(No symbol) [0x0xf507a3]\n",
      "\t(No symbol) [0x0xf2f1b6]\n",
      "\t(No symbol) [0x0xefe7a2]\n",
      "\t(No symbol) [0x0xeff644]\n",
      "\tGetHandleVerifier [0x0x12f65c3+2637587]\n",
      "\tGetHandleVerifier [0x0x12f19ca+2618138]\n",
      "\tGetHandleVerifier [0x0x10a84aa+220666]\n",
      "\tGetHandleVerifier [0x0x10988d8+156200]\n",
      "\tGetHandleVerifier [0x0x109f06d+182717]\n",
      "\tGetHandleVerifier [0x0x1089978+94920]\n",
      "\tGetHandleVerifier [0x0x1089b02+95314]\n",
      "\tGetHandleVerifier [0x0x1074c4a+9626]\n",
      "\tBaseThreadInitThunk [0x0x758e7ba9+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7733c3ab+107]\n",
      "\tRtlClearBits [0x0x7733c32f+191]\n",
      "\n",
      "‚úÖ Crawled content from https://status.net/articles/apologize-mistake-professionally-examples/:\n",
      "Recognizing when you‚Äôve made a mistake and displaying genuine regret is a valuable skill for building relationships and resolving conflicts professionally. Knowing how to apologize sincerely not only improves your standing in the eyes of others but also helps with your self-improvement.\n",
      "Clearly stating the mistake shows that you understand the issue and can help prevent any miscommunication. This way, the person receiving the apology knows what you‚Äôre apologizing for.\n",
      "Accepting responsibility fo...\n",
      "‚è≥ Attempt 2: Crawling https://www.panachehq.com/blog/2025/02/01/the-role-of-political-and-social-commentary-in-modern-movies-and-tv-shows/ with wait_time=310s\n",
      "‚ö†Ô∏è Attempt 2 failed for https://www.panachehq.com/blog/2025/02/01/the-role-of-political-and-social-commentary-in-modern-movies-and-tv-shows/: Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n",
      "  (Session info: chrome=138.0.7204.158)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x1081a33+62339]\n",
      "\tGetHandleVerifier [0x0x1081a74+62404]\n",
      "\t(No symbol) [0x0xec2123]\n",
      "\t(No symbol) [0x0xebf85b]\n",
      "\t(No symbol) [0x0xeb30d2]\n",
      "\t(No symbol) [0x0xeb4b05]\n",
      "\t(No symbol) [0x0xeb3368]\n",
      "\t(No symbol) [0x0xeb2ea3]\n",
      "\t(No symbol) [0x0xeb2bb1]\n",
      "\t(No symbol) [0x0xeb0b54]\n",
      "\t(No symbol) [0x0xeb14fb]\n",
      "\t(No symbol) [0x0xec5b4e]\n",
      "\t(No symbol) [0x0xf51367]\n",
      "\t(No symbol) [0x0xf2f3bc]\n",
      "\t(No symbol) [0x0xf507a3]\n",
      "\t(No symbol) [0x0xf2f1b6]\n",
      "\t(No symbol) [0x0xefe7a2]\n",
      "\t(No symbol) [0x0xeff644]\n",
      "\tGetHandleVerifier [0x0x12f65c3+2637587]\n",
      "\tGetHandleVerifier [0x0x12f19ca+2618138]\n",
      "\tGetHandleVerifier [0x0x10a84aa+220666]\n",
      "\tGetHandleVerifier [0x0x10988d8+156200]\n",
      "\tGetHandleVerifier [0x0x109f06d+182717]\n",
      "\tGetHandleVerifier [0x0x1089978+94920]\n",
      "\tGetHandleVerifier [0x0x1089b02+95314]\n",
      "\tGetHandleVerifier [0x0x1074c4a+9626]\n",
      "\tBaseThreadInitThunk [0x0x758e7ba9+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7733c3ab+107]\n",
      "\tRtlClearBits [0x0x7733c32f+191]\n",
      "\n",
      "https://www.bing.com/search?q=Likely part of the same political or social commentary as the prior statement, focused on political accountability and public reputation during a social or political event.\n",
      "‚è≥ Attempt 3: Crawling https://www.panachehq.com/blog/2025/02/01/the-role-of-political-and-social-commentary-in-modern-movies-and-tv-shows/ with wait_time=610s\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=Likely during a political or social commentary segment, roughly in current times, discussing violence and society's opportunists responding to conflict or crisis.:\n",
      "Study with Quizlet and memorize flashcards containing terms like Digital media, 1st Amendment (The First Amendment covers such important freedoms as the press, religion, and speech.), -monitor the government and politicians for ‚Ä¶\n",
      "A commentary is a genre of journalism that provides interpretations and opinions on current events, rather than factual reporting. Interpretations may include evaluating the motives behind actors‚Äô behaviors, interpreting the wider scope ‚Ä¶\n",
      "News is a selective account of ...\n",
      "‚ö†Ô∏è Attempt 3 failed for https://www.panachehq.com/blog/2025/02/01/the-role-of-political-and-social-commentary-in-modern-movies-and-tv-shows/: Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n",
      "  (Session info: chrome=138.0.7204.158)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x1081a33+62339]\n",
      "\tGetHandleVerifier [0x0x1081a74+62404]\n",
      "\t(No symbol) [0x0xec2123]\n",
      "\t(No symbol) [0x0xebf85b]\n",
      "\t(No symbol) [0x0xeb30d2]\n",
      "\t(No symbol) [0x0xeb4b05]\n",
      "\t(No symbol) [0x0xeb3368]\n",
      "\t(No symbol) [0x0xeb2ea3]\n",
      "\t(No symbol) [0x0xeb2bb1]\n",
      "\t(No symbol) [0x0xeb0b54]\n",
      "\t(No symbol) [0x0xeb14fb]\n",
      "\t(No symbol) [0x0xec5b4e]\n",
      "\t(No symbol) [0x0xf51367]\n",
      "\t(No symbol) [0x0xf2f3bc]\n",
      "\t(No symbol) [0x0xf507a3]\n",
      "\t(No symbol) [0x0xf2f1b6]\n",
      "\t(No symbol) [0x0xefe7a2]\n",
      "\t(No symbol) [0x0xeff644]\n",
      "\tGetHandleVerifier [0x0x12f65c3+2637587]\n",
      "\tGetHandleVerifier [0x0x12f19ca+2618138]\n",
      "\tGetHandleVerifier [0x0x10a84aa+220666]\n",
      "\tGetHandleVerifier [0x0x10988d8+156200]\n",
      "\tGetHandleVerifier [0x0x109f06d+182717]\n",
      "\tGetHandleVerifier [0x0x1089978+94920]\n",
      "\tGetHandleVerifier [0x0x1089b02+95314]\n",
      "\tGetHandleVerifier [0x0x1074c4a+9626]\n",
      "\tBaseThreadInitThunk [0x0x758e7ba9+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7733c3ab+107]\n",
      "\tRtlClearBits [0x0x7733c32f+191]\n",
      "\n",
      "‚è≥ Attempt 4: Crawling https://www.panachehq.com/blog/2025/02/01/the-role-of-political-and-social-commentary-in-modern-movies-and-tv-shows/ with wait_time=910s\n",
      "‚ö†Ô∏è Attempt 4 failed for https://www.panachehq.com/blog/2025/02/01/the-role-of-political-and-social-commentary-in-modern-movies-and-tv-shows/: Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n",
      "  (Session info: chrome=138.0.7204.158)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x1081a33+62339]\n",
      "\tGetHandleVerifier [0x0x1081a74+62404]\n",
      "\t(No symbol) [0x0xec2123]\n",
      "\t(No symbol) [0x0xebf85b]\n",
      "\t(No symbol) [0x0xeb30d2]\n",
      "\t(No symbol) [0x0xeb4b05]\n",
      "\t(No symbol) [0x0xeb3368]\n",
      "\t(No symbol) [0x0xeb2ea3]\n",
      "\t(No symbol) [0x0xeb2bb1]\n",
      "\t(No symbol) [0x0xeb0b54]\n",
      "\t(No symbol) [0x0xeb14fb]\n",
      "\t(No symbol) [0x0xec5b4e]\n",
      "\t(No symbol) [0x0xf51367]\n",
      "\t(No symbol) [0x0xf2f3bc]\n",
      "\t(No symbol) [0x0xf507a3]\n",
      "\t(No symbol) [0x0xf2f1b6]\n",
      "\t(No symbol) [0x0xefe7a2]\n",
      "\t(No symbol) [0x0xeff644]\n",
      "\tGetHandleVerifier [0x0x12f65c3+2637587]\n",
      "\tGetHandleVerifier [0x0x12f19ca+2618138]\n",
      "\tGetHandleVerifier [0x0x10a84aa+220666]\n",
      "\tGetHandleVerifier [0x0x10988d8+156200]\n",
      "\tGetHandleVerifier [0x0x109f06d+182717]\n",
      "\tGetHandleVerifier [0x0x1089978+94920]\n",
      "\tGetHandleVerifier [0x0x1089b02+95314]\n",
      "\tGetHandleVerifier [0x0x1074c4a+9626]\n",
      "\tBaseThreadInitThunk [0x0x758e7ba9+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7733c3ab+107]\n",
      "\tRtlClearBits [0x0x7733c32f+191]\n",
      "\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"19f59c37505884befe916a32c8e0a20f\", element=\"f.36728B1A7D5376017A7CE5A3FBB97507.d.FB9FD170DD427EB7D6636F7664ECB104.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"19f59c37505884befe916a32c8e0a20f\", element=\"f.36728B1A7D5376017A7CE5A3FBB97507.d.FB9FD170DD427EB7D6636F7664ECB104.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"19f59c37505884befe916a32c8e0a20f\", element=\"f.36728B1A7D5376017A7CE5A3FBB97507.d.FB9FD170DD427EB7D6636F7664ECB104.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"19f59c37505884befe916a32c8e0a20f\", element=\"f.36728B1A7D5376017A7CE5A3FBB97507.d.FB9FD170DD427EB7D6636F7664ECB104.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"19f59c37505884befe916a32c8e0a20f\", element=\"f.36728B1A7D5376017A7CE5A3FBB97507.d.FB9FD170DD427EB7D6636F7664ECB104.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"19f59c37505884befe916a32c8e0a20f\", element=\"f.36728B1A7D5376017A7CE5A3FBB97507.d.FB9FD170DD427EB7D6636F7664ECB104.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"19f59c37505884befe916a32c8e0a20f\", element=\"f.36728B1A7D5376017A7CE5A3FBB97507.d.FB9FD170DD427EB7D6636F7664ECB104.e.27\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"19f59c37505884befe916a32c8e0a20f\", element=\"f.36728B1A7D5376017A7CE5A3FBB97507.d.FB9FD170DD427EB7D6636F7664ECB104.e.28\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"19f59c37505884befe916a32c8e0a20f\", element=\"f.36728B1A7D5376017A7CE5A3FBB97507.d.FB9FD170DD427EB7D6636F7664ECB104.e.29\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"19f59c37505884befe916a32c8e0a20f\", element=\"f.36728B1A7D5376017A7CE5A3FBB97507.d.FB9FD170DD427EB7D6636F7664ECB104.e.30\")>]\n",
      "Political and social commentary - (World Literature II) - Vocab ...\n",
      "https://library.fiveable.me/key-terms/world-literature-ii/political-and-social-commentary\n",
      "Social commentary - Wikipedia\n",
      "https://en.wikipedia.org/wiki/Social_commentary\n",
      "Found 3 relevant links:\n",
      "[{'title': 'Likely part of the same politi', 'link': 'https://www.bing.com/search?q=Likely part of the same political or social commentary as the prior statement, focused on political accountability and public reputation during a social or political event.'}, {'title': 'Political and social commentary - (World Literature II) - Vocab ...', 'link': 'https://library.fiveable.me/key-terms/world-literature-ii/political-and-social-commentary'}, {'title': 'Social commentary - Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Social_commentary'}]\n",
      "‚è≥ Attempt 1: Crawling https://library.fiveable.me/key-terms/world-literature-ii/political-and-social-commentary with wait_time=10s‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=Likely part of the same political or social commentary as the prior statement, focused on political accountability and public reputation during a social or political event. with wait_time=10s\n",
      "\n",
      "‚è≥ Attempt 5: Crawling https://www.panachehq.com/blog/2025/02/01/the-role-of-political-and-social-commentary-in-modern-movies-and-tv-shows/ with wait_time=1210s\n",
      "‚ö†Ô∏è Attempt 5 failed for https://www.panachehq.com/blog/2025/02/01/the-role-of-political-and-social-commentary-in-modern-movies-and-tv-shows/: Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n",
      "  (Session info: chrome=138.0.7204.158)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x1081a33+62339]\n",
      "\tGetHandleVerifier [0x0x1081a74+62404]\n",
      "\t(No symbol) [0x0xec2123]\n",
      "\t(No symbol) [0x0xebf85b]\n",
      "\t(No symbol) [0x0xeb30d2]\n",
      "\t(No symbol) [0x0xeb4b05]\n",
      "\t(No symbol) [0x0xeb3368]\n",
      "\t(No symbol) [0x0xeb2ea3]\n",
      "\t(No symbol) [0x0xeb2bb1]\n",
      "\t(No symbol) [0x0xeb0b54]\n",
      "\t(No symbol) [0x0xeb14fb]\n",
      "\t(No symbol) [0x0xec5b4e]\n",
      "\t(No symbol) [0x0xf51367]\n",
      "\t(No symbol) [0x0xf2f3bc]\n",
      "\t(No symbol) [0x0xf507a3]\n",
      "\t(No symbol) [0x0xf2f1b6]\n",
      "\t(No symbol) [0x0xefe7a2]\n",
      "\t(No symbol) [0x0xeff644]\n",
      "\tGetHandleVerifier [0x0x12f65c3+2637587]\n",
      "\tGetHandleVerifier [0x0x12f19ca+2618138]\n",
      "\tGetHandleVerifier [0x0x10a84aa+220666]\n",
      "\tGetHandleVerifier [0x0x10988d8+156200]\n",
      "\tGetHandleVerifier [0x0x109f06d+182717]\n",
      "\tGetHandleVerifier [0x0x1089978+94920]\n",
      "\tGetHandleVerifier [0x0x1089b02+95314]\n",
      "\tGetHandleVerifier [0x0x1074c4a+9626]\n",
      "\tBaseThreadInitThunk [0x0x758e7ba9+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7733c3ab+107]\n",
      "\tRtlClearBits [0x0x7733c32f+191]\n",
      "\n",
      "‚ùå Failed to crawl article from https://www.panachehq.com/blog/2025/02/01/the-role-of-political-and-social-commentary-in-modern-movies-and-tv-shows/ after 5 attempts.\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=Likely part of the same political or social commentary as the prior statement, focused on political accountability and public reputation during a social or political event.:\n",
      "This paper is a result of the analysis of strategies of The Rambler's satire in 40 of his articles that were published in The Namibian newspaper in 2015. We extracted 51 articles from The ‚Ä¶\n",
      "The boy was playing alone on a dusty road, not far from the big door of the courtyard ‚Ä¶\n",
      "This paper is a result of the analysis of strategies of The Rambler's satire in 40 ‚Ä¶\n",
      "¬© 2008-2024 ResearchGate GmbH. All rights reserved. Terms; Privacy; IP ‚Ä¶\n",
      "Social commentary is the act of using rhetorical means to provid...\n",
      "‚úÖ Crawled content from https://library.fiveable.me/key-terms/world-literature-ii/political-and-social-commentary:\n",
      "Citation:\n",
      "Political and social commentary refers to the expression of opinions or critiques about societal issues, governmental policies, and cultural phenomena, often aimed at raising awareness or prompting change. This type of commentary can be found in various forms of literature, including magical realist short stories, where authors blend fantastical elements with real-world issues to highlight the absurdities and injustices in society.\n",
      "Magical Realism: A literary genre that incorporates fa...\n",
      "‚úÖ Finished enriching statements with articles.\n",
      "üß™ Running fact-checks on statements...\n",
      "{'start': 32.04, 'end': 61.86, 'speaker': 'Unknown', 'text': 'The The The The The The The The The The The These violence will not benefit any indulgence. We have all seen the game of opportunists who have tried to take advantage of', 'reason': 'The speaker claims that violence does not benefit anyone and highlights opportunists exploiting situations, which is a political and social claim worth verifying.', 'context': \"Likely during a political or social commentary segment, roughly in current times, discussing violence and society's opportunists responding to conflict or crisis.\", 'frame_path': 'statement_frames\\\\Unknown_003204.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.4412936568260193, 'article_texts': '### The The The The The The The Th\\nIntolerance is itself a form of violence and an obstacle to the growth of a true democratic spirit. Violent means will give violent freedom. That would be a menace to the world and to India ‚Ä¶\\nApr 6, 2015\\xa0¬∑ Here you will learn the surprising truth about violence and how we have stigmatized the study of violence to the point that only the criminal elements have access to it. A former military...\\nJun 30, 2025\\xa0¬∑ The moment the slave resolves that he will no longer be a slave, his fetters fall. He frees himself and shows the way to others. Freedom and slavery are mental states. Victory ‚Ä¶\\nJun 4, 2024\\xa0¬∑ The impact of violence extends far beyond its immediate victims, shaping community norms, perpetuating intergenerational cycles of abuse, ‚Ä¶\\nApr 1, 2019\\xa0¬∑ Here is a selection of quotes, sorted out into topics. Frantz Fanon: \"Violence is man re-creating himself.\" George Orwell: \"We sleep safe in our ‚Ä¶\\nWe all can agree that \"violence\" is generally undesirable and unpleasant. I believe it is critical to distinguish between the INITIATION of violence, and the ‚Ä¶\\nThese inspiring quotes remind us that violence is not the answer and that we have the power to create a world where peace prevails. Let us reflect on these ‚Ä¶\\nViolence\\nUse of physical force\\nViolence is characterized as the use of physical force by humans to cause harm to other living beings, such as pain, injury, disablement, death, damage and destruction. The World Health Organization d‚Ä¶\\n\\n### Philosophical Quotes on Violence - ThoughtCo\\nVerify you are human by completing the action below.\\n\\n### Likely during a political or s\\nStudy with Quizlet and memorize flashcards containing terms like Digital media, 1st Amendment (The First Amendment covers such important freedoms as the press, religion, and speech.), -monitor the government and politicians for ‚Ä¶\\nA commentary is a genre of journalism that provides interpretations and opinions on current events, rather than factual reporting. Interpretations may include evaluating the motives behind actors‚Äô behaviors, interpreting the wider scope ‚Ä¶\\nNews is a selective account of what happens in the world. Common subjects are violence (wars), crime (school shootings), natural disasters (earthquakes, hurricanes), and scandals (sexual, financial). The statements and actions of ‚Ä¶\\nNov 21, 2023\\xa0¬∑ Social commentary is a way of providing one\\'s perspective on society and its problems. Social commentary can critique many aspects of society including culture, politics, and religion.\\nStudy with Quizlet and memorize flashcards containing terms like the news provides a refracted version of reality because it: - emphasizing dramatic and compelling news stories - is biased in favor of a Republican viewpoint - is ‚Ä¶\\nSocial commentary is a form of writing that offers insight into society, its values, and its customs. It is the act of using rhetorical means to provide commentary on issues in a society. Social commentary can be found in a variety of literary ‚Ä¶'}\n",
      "üßê Fact-checking: The The The The The The The The The The The These violence will not benefit any ...\n",
      "{'start': 61.86, 'end': 74.1, 'speaker': 'SPEAKER_00', 'text': \"the sincere colors to send them. We have all seen the irresponsible political actions in the only project was to boost the public's reputation, looking for the disorder and the energy.\", 'reason': 'This statement alleges irresponsible political actions motivated by reputation-boosting and causing disorder, a claim that implicates political actors and warrants fact-checking.', 'context': 'Likely part of the same political or social commentary as the prior statement, focused on political accountability and public reputation during a social or political event.', 'frame_path': 'statement_frames\\\\SPEAKER_00_006186.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.3603633642196655, 'article_texts': '### the sincere colors to send the\\nNov 23, 2011\\xa0¬∑ Here are some more business email and letter phrases. In this list we look at how to make requests, complain, apologise and give bad news. The examples in the left column are more formal. The right-hand column shows ‚Ä¶\\nRecognizing when you‚Äôve made a mistake and displaying genuine regret is a valuable skill for building relationships and resolving conflicts professionally. Knowing how to apologize ‚Ä¶\\nWhen American military men approach some serious situation they are wont to write at the head of their directive the words \"over-all strategic concept.\" There is wisdom in this, as it leads to ‚Ä¶\\nWe follow up with a breakdown of the apology email structure and provide 10 samples. Finally, we use our techniques to build a foolproof apology email template. Want to apologize in an email? Let\\'s get started! OK, we\\'ve ‚Ä¶\\nExplore the vibrant world of color idioms in English with our list of 40 expressions. From \"green with envy\" to \"red herring\", learn the meanings and origins of these idioms, as well as how to use them in everyday conversation. Improve your ‚Ä¶\\nJun 20, 2025\\xa0¬∑ Apologies can be as delicate as they are necessary, a tightrope walk of sincerity that commands authenticity. When you‚Äôve messed up and need to make amends, a bland ‚Äúsorry‚Äù often just won‚Äôt cut it. An apology should ‚Ä¶\\n\\n### 30 Examples: How To Apologize for a Mistake Professionally\\nRecognizing when you‚Äôve made a mistake and displaying genuine regret is a valuable skill for building relationships and resolving conflicts professionally. Knowing how to apologize sincerely not only improves your standing in the eyes of others but also helps with your self-improvement.\\nClearly stating the mistake shows that you understand the issue and can help prevent any miscommunication. This way, the person receiving the apology knows what you‚Äôre apologizing for.\\nAccepting responsibility for your mistake demonstrates accountability and conveys your sincerity:\\nWhen deciding on the method of communication, consider the severity and impact of the mistake. For minor slip-ups or misunderstandings, a simple email or direct message may suffice. However, if your mistake caused significant harm or confusion, a face-to-face conversation or even a well-drafted formal letter might be more appropriate.\\nAvoid using vague phrases or shifting blame, and instead, openly admit your fault. Describe the mistake and its consequences without over-exaggerating or downplaying its significance.\\nFor instance, if you missed a crucial deadline, do not make excuses for your actions. Instead, your apology should be straightforward: ‚ÄúI apologize for failing to meet the deadline for (‚Ä¶) project, and I understand how this has negatively impacted our team. To rectify the situation, I will work diligently to complete the project as soon as possible.‚Äù\\nExpressing genuine regret and empathy for the consequences of your mistake strengthens the sincerity of your apology. Channel your feelings of remorse and describe how the mistake has affected the people involved or the organization as a whole.\\nIf, for example, you made a thoughtless comment to a coworker, express your regret by saying, ‚ÄúI am truly sorry for my careless remark earlier. I understand how it may have hurt your feelings and caused unnecessary tension. I want to assure you that it was not my intention, and I will be more mindful of my words in the future.‚Äù\\nJust as important as the content of the apology is when you express it. Waiting too long can make the apology seem insincere, but apologizing too soon might not give you enough time to fully understand the situation and the impact of your mistake. Take the time you need to gather all the necessary information, consider the consequences, and develop a genuine, well-thought-out apology.\\nWhen considering the timing of your apology, keep in mind the following:\\nFor example, if you accidentally send a confidential email to the wrong recipient, you should immediately apologize for the mistake and inform them that you will follow up with more information. Afterward, you can investigate the situation further and compose a more detailed and sincere apology for the harm your mistake caused.\\nWhen apologizing for a professional mistake, it‚Äôs important to include a clear plan of action that demonstrates your understanding of the issue and commitment to rectifying it. This adds credibility to your apology and reassures the affected parties that you‚Äôre taking the matter seriously.\\nDear [Client], I realize that the error in the financial report has led to budget miscalculations. To address this, I will revise the report and implement a new review process for future financial documentation. I will have the corrected report to you by the end of the day, and the new review process will be in place by next week. As a token of our apology, we‚Äôd like to offer a 10% discount on your next order with us. I will keep you updated on our progress, and please feel free to contact me with any concerns.\\nKeep in mind these communication tips for a successful apology:\\nAn effective way to apologize for an error in the workplace is to be sincere and direct. Accept responsibility for your mistake and address how you plan to correct it. Offer solutions and show your commitment to making things right. For example:\\n‚ÄúI realize I made a mistake with the project deadline, and I take full responsibility for it. I will work extra hours this week to make sure we are back on track, and I‚Äôll double-check all deadlines in the future.‚Äù\\nHere are two examples of sincere apologies in professional emails:\\nWhen writing an apology in a business letter, be clear and concise. Start by acknowledging your mistake, and then explain the steps you‚Äôre taking to rectify the problem:\\n‚ÄúI would like to formally apologize for the errors found in our recent invoice. We have reviewed our records and found the discrepancies. To resolve this issue, we have credited your account with the appropriate amount. Please find the updated invoice enclosed.‚Äù\\nInstead of using the word ‚Äòsorry‚Äô, try acknowledging the error and focusing on how you plan to fix it. For example:\\nTo offer a heartfelt apology in a work setting, show empathy by acknowledging the impact your mistake had on others and express your regret. Then, indicate your plan to prevent similar problems in the future:\\n‚ÄúI understand that my mistake created extra work for you, and I deeply regret any inconvenience. Please know that I‚Äôm taking steps to ensure that this won‚Äôt happen again, and I‚Äôll be more diligent in the future.‚Äù\\nAn appropriate structure for a professional apology includes three main points:\\nFor example:\\n‚ÄúI recently became aware that I made a mistake in our client presentation. I take full responsibility for the oversight and have corrected the error. Moving forward, I will double-check all materials before submitting them. Thank you for your understanding and support.‚Äù\\n\\n### Likely part of the same politi\\nThis paper is a result of the analysis of strategies of The Rambler\\'s satire in 40 of his articles that were published in The Namibian newspaper in 2015. We extracted 51 articles from The ‚Ä¶\\nThe boy was playing alone on a dusty road, not far from the big door of the courtyard ‚Ä¶\\nThis paper is a result of the analysis of strategies of The Rambler\\'s satire in 40 ‚Ä¶\\n¬© 2008-2024 ResearchGate GmbH. All rights reserved. Terms; Privacy; IP ‚Ä¶\\nSocial commentary is the act of using rhetorical means to provide commentary on social, cultural, political, or economic issues in a society. This is often done with the idea of implementing or promoting change by informing the general populace about a given problem and appealing to people\\'s sense of justice. Social commentary can be practiced through all forms of communication, from printed form, to conversations to computerized communicationÔºåincluding ‚Ä¶\\nPolitical and social commentary refers to the expression of opinions or critiques about societal issues, governmental policies, and cultural phenomena, often aimed at raising awareness or ‚Ä¶\\nArt has long been a forum for expressing opinions about the state of politics and society. Through caricature, satire, symbolism, and allegory, artists have commented both explicitly and subversively on everything from vanity and ‚Ä¶\\nIn the 19th century, art became an important medium for social and political commentary. The Romantic movement, for example, focused on the individual ‚Ä¶\\nJun 14, 2021\\xa0¬∑ We carefully look at how political ideologies lie in the assumptions about society and social relations subtly articulated in social media posts, whether these relate to a foreign country, gender inequalities, or fitness programmes.\\nSocial commentary\\nSocial commentary is the act of using rhetorical means to provide commentary on social, cultural, political, or economic issues in a society. This is often done with the idea of implementing or promot‚Ä¶\\nThe presentation of social commentary can range from obvious and on-the-nose to subtle and layered within subtext. This type of commentary can be found in literature, music, television, and cinema.\\n\\n### Political and social commentary - (World Literature II) - Vocab ...\\nCitation:\\nPolitical and social commentary refers to the expression of opinions or critiques about societal issues, governmental policies, and cultural phenomena, often aimed at raising awareness or prompting change. This type of commentary can be found in various forms of literature, including magical realist short stories, where authors blend fantastical elements with real-world issues to highlight the absurdities and injustices in society.\\nMagical Realism: A literary genre that incorporates fantastical elements into a realistic setting, blurring the lines between reality and fantasy.\\nSatire: A genre that uses humor, irony, or exaggeration to criticize or mock societal norms, institutions, or individuals.\\nA narrative technique in which characters or events symbolize deeper moral or political meanings, allowing authors to address complex themes indirectly.'}\n",
      "üßê Fact-checking: the sincere colors to send them. We have all seen the irresponsible political ac...\n",
      "‚úÖ All statements are supported or unverified.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\550.mp4\n",
      "Deepfake label: REAL, Fact-check label: True\n",
      "üíæ Saved checkpoint after 551 videos\n",
      "üìº Processing video 552: ../data/dfw_youtube_release\\551.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\551.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-6.02] Unknown: Vous croyez que j'ai peur des arabes en s'en r√©el ? Fais BIM BAM BOO LA SATAMAK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 6.02, 'speaker': 'Unknown', 'text': \"Vous croyez que j'ai peur des arabes en s'en r√©el ? Fais BIM BAM BOO LA SATAMAK\", 'reason': 'Contains a provocative statement about fear towards a specific ethnic group which may reflect social or political tensions; can be analyzed for context and implications.', 'context': 'Unknown setting, possibly a political rally or social commentary, with the speaker addressing fears or perceptions towards Arabs, likely during a discussion about social or ethnic relations.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\551\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\551.mp4, 2688000 bytes wanted but 0 bytes read,at frame 313/314, at time 10.43/10.45 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['4182d8fb56044c83b65a8e1b49a9add1_clip_1.mp4'], 'pred': [0.7207056879997253], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 6.02, 'speaker': 'Unknown', 'text': \"Vous croyez que j'ai peur des arabes en s'en r√©el ? Fais BIM BAM BOO LA SATAMAK\", 'reason': 'Contains a provocative statement about fear towards a specific ethnic group which may reflect social or political tensions; can be analyzed for context and implications.', 'context': 'Unknown setting, possibly a political rally or social commentary, with the speaker addressing fears or perceptions towards Arabs, likely during a discussion about social or ethnic relations.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.7207056879997253}]\n",
      "‚ö†Ô∏è Statement Vous croyez que j'ai peur des arabes en s'en r√©el ? Fais BIM BAM BOO LA SATAMAK is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\551.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 552 videos\n",
      "üìº Processing video 553: ../data/dfw_youtube_release\\552.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\552.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-3.32] Unknown: Je n'y peux sans que d'une chose\n",
      "[3.32-27.16] SPEAKER_00: Je me fiche de tous les cas t√¥t Que le sapin me propose Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi\n",
      "[30.00-36.60] Unknown: Je te demande pas beaucoup pour nos belles\n",
      "[36.60-116.56] SPEAKER_00: Je n'y peux sans que d'une chose Je me fiche de tous les cas t√¥t Que le sapin me propose Mais peut-√™tre sans d'accrocher mes chaussettes Au tessie de la chemin√©e Le p√®re no√´l ne me conjurent pas Avec un jouet cette ann√©e Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi Je ne te demande pas beaucoup pour nos belles Je n'y esp√®re m√™me pas de flocons Je vais juste attendre de plus belles Sous le qui tombe le salon Je n'en dirai pas mes souhaits Au point d'heure pour le p√®re no√´l Je ne resterai m√™me pas √©vier Pour entendre un t√©lique lochette Je te demande pas beaucoup pour nos belles c'est toi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 checkworthy statements.\n",
      "[{'start': 3.32, 'end': 27.16, 'speaker': 'SPEAKER_00', 'text': \"Je me fiche de tous les cas t√¥t Que le sapin me propose Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi\", 'reason': \"The speaker makes an emotional claim about personal priorities and the meaning behind efforts made for 'our beauties', implying personal dedication and emotional value.\", 'context': 'Likely from a recorded speech or poetic excerpt during a cultural or artistic presentation in 2024, discussing personal values and emotional priorities, without clear external prompt.', 'frame_path': 'statement_frames\\\\SPEAKER_00_000332.jpg'}, {'start': 36.6, 'end': 116.56, 'speaker': 'SPEAKER_00', 'text': \"Je n'y peux sans que d'une chose Je me fiche de tous les cas t√¥t Que le sapin me propose Mais peut-√™tre sans d'accrocher mes chaussettes Au tessie de la chemin√©e Le p√®re no√´l ne me conjurent pas Avec un jouet cette ann√©e Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi Je ne te demande pas beaucoup pour nos belles Je n'y esp√®re m√™me pas de flocons Je vais juste attendre de plus belles Sous le qui tombe le salon Je n'en dirai pas mes souhaits Au point d'heure pour le p√®re no√´l Je ne resterai m√™me pas √©vier Pour entendre un t√©lique lochette Je te demande pas beaucoup pour nos belles c'est toi\", 'reason': 'The speaker makes a series of personal and emotional claims about preferences and hopes related to Christmas, explicitly stating a lack of interest in traditional gifts and highlighting emotional focus on a specific person.', 'context': 'Likely from a poetic or musical performance recorded in 2024, this extended statement reflects on personal values related to holiday traditions and emotional desires, possibly in response to general societal customs.', 'frame_path': 'statement_frames\\\\SPEAKER_00_003660.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\552\\clip_1.mp4 from 3.32s to 27.16s\n",
      "‚úÇÔ∏è Cutting statement_clips\\552\\clip_2.mp4 from 36.60s to 116.56s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\552\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['48903e8ef1be4a2faba662cedc8ad14c_clip_1.mp4'], 'pred': [0.30663758516311646], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['d88be9d4ad6741f89758a6ee83325570_clip_2.mp4'], 'pred': [0.363993763923645], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 3.32, 'end': 27.16, 'speaker': 'SPEAKER_00', 'text': \"Je me fiche de tous les cas t√¥t Que le sapin me propose Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi\", 'reason': \"The speaker makes an emotional claim about personal priorities and the meaning behind efforts made for 'our beauties', implying personal dedication and emotional value.\", 'context': 'Likely from a recorded speech or poetic excerpt during a cultural or artistic presentation in 2024, discussing personal values and emotional priorities, without clear external prompt.', 'frame_path': 'statement_frames\\\\SPEAKER_00_000332.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.30663758516311646}, {'start': 36.6, 'end': 116.56, 'speaker': 'SPEAKER_00', 'text': \"Je n'y peux sans que d'une chose Je me fiche de tous les cas t√¥t Que le sapin me propose Mais peut-√™tre sans d'accrocher mes chaussettes Au tessie de la chemin√©e Le p√®re no√´l ne me conjurent pas Avec un jouet cette ann√©e Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi Je ne te demande pas beaucoup pour nos belles Je n'y esp√®re m√™me pas de flocons Je vais juste attendre de plus belles Sous le qui tombe le salon Je n'en dirai pas mes souhaits Au point d'heure pour le p√®re no√´l Je ne resterai m√™me pas √©vier Pour entendre un t√©lique lochette Je te demande pas beaucoup pour nos belles c'est toi\", 'reason': 'The speaker makes a series of personal and emotional claims about preferences and hopes related to Christmas, explicitly stating a lack of interest in traditional gifts and highlighting emotional focus on a specific person.', 'context': 'Likely from a poetic or musical performance recorded in 2024, this extended statement reflects on personal values related to holiday traditions and emotional desires, possibly in response to general societal customs.', 'frame_path': 'statement_frames\\\\SPEAKER_00_003660.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.363993763923645}]\n",
      "üì∞ Enriching statements with articles...\n",
      "https://www.bing.com/search?q=Je n'y peux sans que d'une chose Je me fiche de tous les cas t√¥t Que le sapin me propose Mais peut-√™tre sans d'accrocher mes chaussettes Au tessie de la chemin√©e Le p√®re no√´l ne me conjurent pas Avec un jouet cette ann√©e Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi Je ne te demande pas beaucoup pour nos belles Je n'y esp√®re m√™me pas de flocons Je vais juste attendre de plus belles Sous le qui tombe le salon Je n'en dirai pas mes souhaits Au point d'heure pour le p√®re no√´l Je ne resterai m√™me pas √©vier Pour entendre un t√©lique lochette Je te demande pas beaucoup pour nos belles c'est toihttps://www.bing.com/search?q=Je me fiche de tous les cas t√¥t Que le sapin me propose Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi\n",
      "\n",
      "Found 4 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"181f75c5f4bf7ea506d32f3c7e69935c\", element=\"f.BFB9DCC68406260EE3977823D5A7337D.d.C8D909578D9DA51C855C54E8D97CC87C.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"181f75c5f4bf7ea506d32f3c7e69935c\", element=\"f.BFB9DCC68406260EE3977823D5A7337D.d.C8D909578D9DA51C855C54E8D97CC87C.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"181f75c5f4bf7ea506d32f3c7e69935c\", element=\"f.BFB9DCC68406260EE3977823D5A7337D.d.C8D909578D9DA51C855C54E8D97CC87C.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"181f75c5f4bf7ea506d32f3c7e69935c\", element=\"f.BFB9DCC68406260EE3977823D5A7337D.d.C8D909578D9DA51C855C54E8D97CC87C.e.27\")>]\n",
      "Sara‚Äôh (FRA) ‚Äì All I want for Christmas is you (french ‚Ä¶\n",
      "https://genius.com/Sarah-fra-all-i-want-for-christmas-is-you-french-version-lyrics\n",
      "All I Want For Christmas is You : voici la traduction\n",
      "https://www.cnews.fr/divertissement/2023-11-02/all-i-want-christmas-you-voici-la-traduction-francaise-des-paroles-du-tube\n",
      "Found 3 relevant links:\n",
      "[{'title': 'Je me fiche de tous les cas t√¥', 'link': \"https://www.bing.com/search?q=Je me fiche de tous les cas t√¥t Que le sapin me propose Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi\"}, {'title': 'Sara‚Äôh (FRA) ‚Äì All I want for Christmas is you (french ‚Ä¶', 'link': 'https://genius.com/Sarah-fra-all-i-want-for-christmas-is-you-french-version-lyrics'}, {'title': 'All I Want For Christmas is You : voici la traduction', 'link': 'https://www.cnews.fr/divertissement/2023-11-02/all-i-want-christmas-you-voici-la-traduction-francaise-des-paroles-du-tube'}]\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=Je me fiche de tous les cas t√¥t Que le sapin me propose Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://genius.com/Sarah-fra-all-i-want-for-christmas-is-you-french-version-lyrics with wait_time=10s\n",
      "Found 2 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"5931d5d1aee53b6331158022fb47493b\", element=\"f.82AB29006EFAE3F3A889AF6FE6486691.d.F643D9B0CFC811FB1644A75669B705F8.e.16\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"5931d5d1aee53b6331158022fb47493b\", element=\"f.82AB29006EFAE3F3A889AF6FE6486691.d.F643D9B0CFC811FB1644A75669B705F8.e.17\")>]\n",
      "Citation apocryphe ‚Äî Wikip√©dia\n",
      "https://fr.wikipedia.org/wiki/Citation_apocryphe\n",
      "Cause toujours ! 7 expressions expliqu√©es sans complexe\n",
      "https://www.philomag.com/articles/cause-toujours-7-expressions-expliquees-sans-complexe\n",
      "Found 3 relevant links:\n",
      "[{'title': \"Je n'y peux sans que d'une cho\", 'link': \"https://www.bing.com/search?q=Je n'y peux sans que d'une chose Je me fiche de tous les cas t√¥t Que le sapin me propose Mais peut-√™tre sans d'accrocher mes chaussettes Au tessie de la chemin√©e Le p√®re no√´l ne me conjurent pas Avec un jouet cette ann√©e Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi Je ne te demande pas beaucoup pour nos belles Je n'y esp√®re m√™me pas de flocons Je vais juste attendre de plus belles Sous le qui tombe le salon Je n'en dirai pas mes souhaits Au point d'heure pour le p√®re no√´l Je ne resterai m√™me pas √©vier Pour entendre un t√©lique lochette Je te demande pas beaucoup pour nos belles c'est toi\"}, {'title': 'Citation apocryphe ‚Äî Wikip√©dia', 'link': 'https://fr.wikipedia.org/wiki/Citation_apocryphe'}, {'title': 'Cause toujours ! 7 expressions expliqu√©es sans complexe', 'link': 'https://www.philomag.com/articles/cause-toujours-7-expressions-expliquees-sans-complexe'}]\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=Je n'y peux sans que d'une chose Je me fiche de tous les cas t√¥t Que le sapin me propose Mais peut-√™tre sans d'accrocher mes chaussettes Au tessie de la chemin√©e Le p√®re no√´l ne me conjurent pas Avec un jouet cette ann√©e Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi Je ne te demande pas beaucoup pour nos belles Je n'y esp√®re m√™me pas de flocons Je vais juste attendre de plus belles Sous le qui tombe le salon Je n'en dirai pas mes souhaits Au point d'heure pour le p√®re no√´l Je ne resterai m√™me pas √©vier Pour entendre un t√©lique lochette Je te demande pas beaucoup pour nos belles c'est toi with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://fr.wikipedia.org/wiki/Citation_apocryphe with wait_time=10s\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=Je me fiche de tous les cas t√¥t Que le sapin me propose Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi:\n",
      "Il semble que vous essayez de citer ou recr√©er une version des paroles de la chanson \"All I Want For Christmas Is You\" en fran√ßais, mais avec quelques ajustements ou erreurs dans le texte. Voici une version corrig√©e et adapt√©e pour mieux refl√©ter l'esprit de la chanson :\n",
      "Je me fiche de tous les cadeaux\n",
      "Que le sapin peut proposer\n",
      "Je te veux juste pour moi\n",
      "Bien plus que tu ne le crois\n",
      "R√©alise mon souhait\n",
      "Tout ce que je veux pour No√´l, c'est toi.\n",
      "Si vous souhaitez une traduction ou une adaptation p...\n",
      "‚úÖ Crawled content from https://genius.com/Sarah-fra-all-i-want-for-christmas-is-you-french-version-lyrics:\n",
      "Follow @genius...\n",
      "https://www.bing.com/search?q=Likely from a recorded speech or poetic excerpt during a cultural or artistic presentation in 2024, discussing personal values and emotional priorities, without clear external prompt.\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=Je n'y peux sans que d'une chose Je me fiche de tous les cas t√¥t Que le sapin me propose Mais peut-√™tre sans d'accrocher mes chaussettes Au tessie de la chemin√©e Le p√®re no√´l ne me conjurent pas Avec un jouet cette ann√©e Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi Je ne te demande pas beaucoup pour nos belles Je n'y esp√®re m√™me pas de flocons Je vais juste attendre de plus belles Sous le qui tombe le salon Je n'en dirai pas mes souhaits Au point d'heure pour le p√®re no√´l Je ne resterai m√™me pas √©vier Pour entendre un t√©lique lochette Je te demande pas beaucoup pour nos belles c'est toi:\n",
      "Le sociologue Robert Merton remarqua que certaines situations s'expliquent par ce qu'il appela l'¬´ effet Matthieu ¬ª, en r√©f√©rence √† la phrase de l'√âvangile selon saint Matthieu : ¬´ √Ä celui qui a, il sera beaucoup donn√© et il vivra dans l‚Äôabondance, mais √† celui qui n‚Äôa rien, il sera tout pris, m√™me ce qu‚Äôil poss√©dait. ¬ª ‚Ä¶ See more\n",
      "Une citation apocryphe est une citation attribu√©e √† une personne qui n‚Äôa pourtant jamais tenu les propos rapport√©s, ou alors les a exprim√©s sous une forme diff√©rente. ...\n",
      "‚úÖ Crawled content from https://fr.wikipedia.org/wiki/Citation_apocryphe:\n",
      "Cet article ne cite pas suffisamment ses sources (f√©vrier 2017).\n",
      "Si vous disposez d'ouvrages ou d'articles de r√©f√©rence ou si vous connaissez des sites web de qualit√© traitant du th√®me abord√© ici, merci de compl√©ter l'article en donnant les r√©f√©rences utiles √† sa v√©rifiabilit√© et en les liant √† la section ¬´¬†Notes et r√©f√©rences¬†¬ª.\n",
      "Certaines informations figurant dans cet article ou cette section devraient √™tre mieux reli√©es aux sources mentionn√©es dans les sections ¬´¬†Bibliographie¬†¬ª, ¬´¬†Sources¬†¬ª ...\n",
      "https://www.bing.com/search?q=Likely from a poetic or musical performance recorded in 2024, this extended statement reflects on personal values related to holiday traditions and emotional desires, possibly in response to general societal customs.\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"9fcf01487d39fdedf3b4b9f41618aa22\", element=\"f.367AC188FDD28734D9DBC3485FDDA281.d.3DD1477E6A3B48746170C282567A1C18.e.17\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"9fcf01487d39fdedf3b4b9f41618aa22\", element=\"f.367AC188FDD28734D9DBC3485FDDA281.d.3DD1477E6A3B48746170C282567A1C18.e.18\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"9fcf01487d39fdedf3b4b9f41618aa22\", element=\"f.367AC188FDD28734D9DBC3485FDDA281.d.3DD1477E6A3B48746170C282567A1C18.e.19\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"9fcf01487d39fdedf3b4b9f41618aa22\", element=\"f.367AC188FDD28734D9DBC3485FDDA281.d.3DD1477E6A3B48746170C282567A1C18.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"9fcf01487d39fdedf3b4b9f41618aa22\", element=\"f.367AC188FDD28734D9DBC3485FDDA281.d.3DD1477E6A3B48746170C282567A1C18.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"9fcf01487d39fdedf3b4b9f41618aa22\", element=\"f.367AC188FDD28734D9DBC3485FDDA281.d.3DD1477E6A3B48746170C282567A1C18.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"9fcf01487d39fdedf3b4b9f41618aa22\", element=\"f.367AC188FDD28734D9DBC3485FDDA281.d.3DD1477E6A3B48746170C282567A1C18.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"9fcf01487d39fdedf3b4b9f41618aa22\", element=\"f.367AC188FDD28734D9DBC3485FDDA281.d.3DD1477E6A3B48746170C282567A1C18.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"9fcf01487d39fdedf3b4b9f41618aa22\", element=\"f.367AC188FDD28734D9DBC3485FDDA281.d.3DD1477E6A3B48746170C282567A1C18.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"9fcf01487d39fdedf3b4b9f41618aa22\", element=\"f.367AC188FDD28734D9DBC3485FDDA281.d.3DD1477E6A3B48746170C282567A1C18.e.26\")>]\n",
      "META COMM CHAP 13 Flashcards | Quizlet\n",
      "https://quizlet.com/543144694/meta-comm-chap-13-flash-cards/\n",
      "Cultural Poetics in Literary Theory - English Studies\n",
      "https://english-studies.net/cultural-poetics-in-literary-theory/\n",
      "Found 3 relevant links:\n",
      "[{'title': 'Likely from a recorded speech ', 'link': 'https://www.bing.com/search?q=Likely from a recorded speech or poetic excerpt during a cultural or artistic presentation in 2024, discussing personal values and emotional priorities, without clear external prompt.'}, {'title': 'META COMM CHAP 13 Flashcards | Quizlet', 'link': 'https://quizlet.com/543144694/meta-comm-chap-13-flash-cards/'}, {'title': 'Cultural Poetics in Literary Theory - English Studies', 'link': 'https://english-studies.net/cultural-poetics-in-literary-theory/'}]\n",
      "‚è≥ Attempt 1: Crawling https://quizlet.com/543144694/meta-comm-chap-13-flash-cards/ with wait_time=10s‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=Likely from a recorded speech or poetic excerpt during a cultural or artistic presentation in 2024, discussing personal values and emotional priorities, without clear external prompt. with wait_time=10s\n",
      "\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"440397feccc3c4b47812d1530993b34d\", element=\"f.CF79A98F675D0167945CE765C0B0CB3B.d.6537E6D2215A1D998A6A2252FC65E08E.e.18\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"440397feccc3c4b47812d1530993b34d\", element=\"f.CF79A98F675D0167945CE765C0B0CB3B.d.6537E6D2215A1D998A6A2252FC65E08E.e.19\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"440397feccc3c4b47812d1530993b34d\", element=\"f.CF79A98F675D0167945CE765C0B0CB3B.d.6537E6D2215A1D998A6A2252FC65E08E.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"440397feccc3c4b47812d1530993b34d\", element=\"f.CF79A98F675D0167945CE765C0B0CB3B.d.6537E6D2215A1D998A6A2252FC65E08E.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"440397feccc3c4b47812d1530993b34d\", element=\"f.CF79A98F675D0167945CE765C0B0CB3B.d.6537E6D2215A1D998A6A2252FC65E08E.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"440397feccc3c4b47812d1530993b34d\", element=\"f.CF79A98F675D0167945CE765C0B0CB3B.d.6537E6D2215A1D998A6A2252FC65E08E.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"440397feccc3c4b47812d1530993b34d\", element=\"f.CF79A98F675D0167945CE765C0B0CB3B.d.6537E6D2215A1D998A6A2252FC65E08E.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"440397feccc3c4b47812d1530993b34d\", element=\"f.CF79A98F675D0167945CE765C0B0CB3B.d.6537E6D2215A1D998A6A2252FC65E08E.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"440397feccc3c4b47812d1530993b34d\", element=\"f.CF79A98F675D0167945CE765C0B0CB3B.d.6537E6D2215A1D998A6A2252FC65E08E.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"440397feccc3c4b47812d1530993b34d\", element=\"f.CF79A98F675D0167945CE765C0B0CB3B.d.6537E6D2215A1D998A6A2252FC65E08E.e.27\")>]\n",
      "2024: A year in concert reviews, astonishing youth, late-romantic ...\n",
      "https://www.planethugill.com/2024/12/2024-year-in-concert-reviews.html\n",
      "The Year in Poetry: How Poets Captured the Spirit of ‚Ä¶\n",
      "https://www.thepoetrycove.com/post/the-year-in-poetry-how-poets-captured-the-spirit-of-2024\n",
      "Found 3 relevant links:\n",
      "[{'title': 'Likely from a poetic or musica', 'link': 'https://www.bing.com/search?q=Likely from a poetic or musical performance recorded in 2024, this extended statement reflects on personal values related to holiday traditions and emotional desires, possibly in response to general societal customs.'}, {'title': '2024: A year in concert reviews, astonishing youth, late-romantic ...', 'link': 'https://www.planethugill.com/2024/12/2024-year-in-concert-reviews.html'}, {'title': 'The Year in Poetry: How Poets Captured the Spirit of ‚Ä¶', 'link': 'https://www.thepoetrycove.com/post/the-year-in-poetry-how-poets-captured-the-spirit-of-2024'}]\n",
      "‚è≥ Attempt 1: Crawling https://www.planethugill.com/2024/12/2024-year-in-concert-reviews.html with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=Likely from a poetic or musical performance recorded in 2024, this extended statement reflects on personal values related to holiday traditions and emotional desires, possibly in response to general societal customs. with wait_time=10s\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=Likely from a recorded speech or poetic excerpt during a cultural or artistic presentation in 2024, discussing personal values and emotional priorities, without clear external prompt.:\n",
      "Musical clips from CDs and iTunes, recorded clips from conversations, and interviews are most likely examples of _____. In the context of presentational aids, which of the following is true of ‚Ä¶\n",
      "Aug 22, 2023¬†¬∑ Understanding cultural differences in public speaking is essential for effective communication and audience engagement. Cultural communication styles, nonverbal cues, values, and beliefs can greatly impact how a message ‚Ä¶\n",
      "Sep 11, 2023¬†¬∑ Cultural Poetics, as a theoretical term, encompasses ...\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=Likely from a poetic or musical performance recorded in 2024, this extended statement reflects on personal values related to holiday traditions and emotional desires, possibly in response to general societal customs.:\n",
      "Dec 30, 2024¬†¬∑ From poetic Liszt and Grieg concertos to a little bit of magic from Martha Argerich and friends at Le Piano Symphonique in Lucerne From the poetry of the young Yoav Levanon ‚Ä¶\n",
      "Dec 29, 2024¬†¬∑ From addressing climate change and social justice to exploring personal resilience, poets have captured the essence of 2024‚Äôs triumphs, ‚Ä¶\n",
      "Dec 20, 2024¬†¬∑ Below, our first-rate writers, thinkers, and contributors share the musical moments from 2024 that impacted them most. From Beyonc√© galloping ...\n",
      "‚úÖ Clicked a close button\n",
      "‚úÖ Crawled content from https://www.planethugill.com/2024/12/2024-year-in-concert-reviews.html:\n",
      "Baroque music featured highly this year, Lawrence Cummings and the AAM used just eight singers for their moving version of Bach's St Matthew Passion and equally life-enhancing was Bach's Brandenburg Concertos from the OAE. We heard Handel's original version of Esther from Solomon's Knot, who also popped up in Monteverdi's Vespers of 1610, one of a pair of contrasting performances of this work, the other by from the ever admirable Sixteen. There was more Handel at the Wimbledon Festival with Benj...\n",
      "‚úÖ Crawled content from https://quizlet.com/543144694/meta-comm-chap-13-flash-cards/:\n",
      "¬© 2025 Quizlet, Inc....\n",
      "‚úÖ Finished enriching statements with articles.\n",
      "üß™ Running fact-checks on statements...\n",
      "{'start': 3.32, 'end': 27.16, 'speaker': 'SPEAKER_00', 'text': \"Je me fiche de tous les cas t√¥t Que le sapin me propose Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi\", 'reason': \"The speaker makes an emotional claim about personal priorities and the meaning behind efforts made for 'our beauties', implying personal dedication and emotional value.\", 'context': 'Likely from a recorded speech or poetic excerpt during a cultural or artistic presentation in 2024, discussing personal values and emotional priorities, without clear external prompt.', 'frame_path': 'statement_frames\\\\SPEAKER_00_000332.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.30663758516311646, 'article_texts': '### Je me fiche de tous les cas t√¥\\nIl semble que vous essayez de citer ou recr√©er une version des paroles de la chanson \"All I Want For Christmas Is You\" en fran√ßais, mais avec quelques ajustements ou erreurs dans le texte. Voici une version corrig√©e et adapt√©e pour mieux refl√©ter l\\'esprit de la chanson :\\nJe me fiche de tous les cadeaux\\nQue le sapin peut proposer\\nJe te veux juste pour moi\\nBien plus que tu ne le crois\\nR√©alise mon souhait\\nTout ce que je veux pour No√´l, c\\'est toi.\\nSi vous souhaitez une traduction ou une adaptation plus pr√©cise, n\\'h√©sitez pas √† demander ! üòä\\nDec 7, 2018\\xa0¬∑ All I want for Christmas is you (french version) Lyrics: Je n‚Äôdemande pas / Beaucoup pour No√´l / Une seule chose dont j‚Äôai besoin / Je me fiche de tous vos cadeaux / Que je vois...\\nNov 2, 2023\\xa0¬∑ Depuis 1994, le tube ¬´All I want For Christmas Is You¬ª, interpr√©t√© par Mariah Carey, accompagne le monde entier lors de la p√©riode des f√™tes de fin d\\'ann√©es. Mais connaissez-vous le sens des paroles ? ¬´It‚Äôs tiiiiime !¬ª.\\nDec 21, 2021\\xa0¬∑ Santa, won‚Äôt you bring me the one I really need? (Yeah, oh) Won‚Äôt you please bring my baby to me? La c√©l√®bre chanson de No√´l de Mariah Carey est une v√©ritable ‚Ä¶\\n\\n### Sara‚Äôh (FRA) ‚Äì All I want for Christmas is you (french ‚Ä¶\\nFollow @genius\\n\\n### Likely from a recorded speech \\nMusical clips from CDs and iTunes, recorded clips from conversations, and interviews are most likely examples of _____. In the context of presentational aids, which of the following is true of ‚Ä¶\\nAug 22, 2023\\xa0¬∑ Understanding cultural differences in public speaking is essential for effective communication and audience engagement. Cultural communication styles, nonverbal cues, values, and beliefs can greatly impact how a message ‚Ä¶\\nSep 11, 2023\\xa0¬∑ Cultural Poetics, as a theoretical term, encompasses the interdisciplinary examination of cultural expressions, prioritizing the nuanced interplay between language, ‚Ä¶\\nThe LC English course broken down into topics from essays to Yeats. For each topic find study notes, sample essays as well as past exam questions with marking schemes.\\nAug 27, 2024\\xa0¬∑ When addressing a culturally diverse group, it\\'s crucial to craft your speech in a way that resonates with various cultural backgrounds and perspectives. Here are some strategies to help...\\nYour cultural artifact speech should teach us about (1) the artifact that is the focus of the speech, (2) the culture from which the artifact comes by sharing how the artifact represents important values and traditions in that culture, and (3) who ‚Ä¶\\nAligned to the Australian Curriculum: English for Year 7, this resource uses collection material from the National Library of Australia to examine how creators like Judith Wright, Judy Horacek and Joan Lindsay express cultural ‚Ä¶\\n\\n### META COMM CHAP 13 Flashcards | Quizlet\\n¬© 2025 Quizlet, Inc.'}\n",
      "üßê Fact-checking: Je me fiche de tous les cas t√¥t Que le sapin me propose Je te veux juste pour mo...\n",
      "{'start': 36.6, 'end': 116.56, 'speaker': 'SPEAKER_00', 'text': \"Je n'y peux sans que d'une chose Je me fiche de tous les cas t√¥t Que le sapin me propose Mais peut-√™tre sans d'accrocher mes chaussettes Au tessie de la chemin√©e Le p√®re no√´l ne me conjurent pas Avec un jouet cette ann√©e Je te veux juste pour moi Oui, bien plus que t'y le crois L'an aurait possible Tout ce que je fais pour nos belles c'est toi Je ne te demande pas beaucoup pour nos belles Je n'y esp√®re m√™me pas de flocons Je vais juste attendre de plus belles Sous le qui tombe le salon Je n'en dirai pas mes souhaits Au point d'heure pour le p√®re no√´l Je ne resterai m√™me pas √©vier Pour entendre un t√©lique lochette Je te demande pas beaucoup pour nos belles c'est toi\", 'reason': 'The speaker makes a series of personal and emotional claims about preferences and hopes related to Christmas, explicitly stating a lack of interest in traditional gifts and highlighting emotional focus on a specific person.', 'context': 'Likely from a poetic or musical performance recorded in 2024, this extended statement reflects on personal values related to holiday traditions and emotional desires, possibly in response to general societal customs.', 'frame_path': 'statement_frames\\\\SPEAKER_00_003660.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.363993763923645, 'article_texts': \"### Je n'y peux sans que d'une cho\\nLe sociologue Robert Merton remarqua que certaines situations s'expliquent par ce qu'il appela l'¬´ effet Matthieu ¬ª, en r√©f√©rence √† la phrase de l'√âvangile selon saint Matthieu : ¬´ √Ä celui qui a, il sera beaucoup donn√© et il vivra dans l‚Äôabondance, mais √† celui qui n‚Äôa rien, il sera tout pris, m√™me ce qu‚Äôil poss√©dait. ¬ª ‚Ä¶ See more\\nUne citation apocryphe est une citation attribu√©e √† une personne qui n‚Äôa pourtant jamais tenu les propos rapport√©s, ou alors les a exprim√©s sous une forme diff√©rente. See more\\n‚Ä¢ Marie-Antoinette : ¬´ Qu'ils mangent de la brioche ! ¬ª En fait, les pamphl√©taires lui ont attribu√© une citation des Confessions de Jean-Jacques Rousseau, publi√©es en 1778 : ¬´ Je me rappelai le pis-aller d‚Äôune grande princesse √† qui l‚Äôon disait que les paysans n‚Äôavaient ‚Ä¶ See more\\n‚Ä¢ Attribu√© √† l'Acad√©mie de Platon : ¬´ Que nul n'entre ici s'il n'est g√©om√®tre ¬ª : Cette formule n'appara√Æt au plus t√¥t qu'au II si√®cle de notre √†re, alors que l'Acad√©mie de Platon a disparu ‚Ä¶ See more\\n‚Ä¢ Madame de S√©vign√© : ¬´ Racine passera comme le caf√©. ¬ª M de S√©vign√© n'appr√©ciait ni le th√©√¢tre de Jean Racine ni le See more\\nUne citation apocryphe est une citation  attribu√©e √† une personne qui n‚Äôa pourtant jamais tenu les propos rapport√©s, ou alors les a exprim√©s sous une forme diff√©rente.  See more\\nUne citation apocryphe est une citation  attribu√©e √† une personne qui n‚Äôa pourtant jamais tenu les propos rapport√©s, ou alors les a exprim√©s sous une forme diff√©rente.  See more\\n‚Ä¢ Attribu√© √† l'Acad√©mie de Platon  : ¬´ Que nul n'entre ici s'il n'est g√©om√®tre ¬ª : Cette formule n'appara√Æt au plus t√¥t qu'au II  si√®cle de notre √†re, alors que l'Acad√©mie de Platon a disparu en 86 av. J.-C. ‚Ä¢ Evelyn Hall  : ¬´ Je ne suis pas d‚Äôaccord avec ce que vous dites, mais je me battrai pour que vous ayez le droit de le dire. ¬ªEvelyn Beatrice Hall qui, dans un livre, The Friends of Voltaire, publi√© en ‚Ä¶ See more\\n‚Ä¢ Attribu√© √† l'Acad√©mie de Platon  : ¬´ Que nul n'entre ici s'il n'est g√©om√®tre ¬ª : Cette formule n'appara√Æt au plus t√¥t qu'au II  si√®cle de notre √†re, alors que l'Acad√©mie de Platon a disparu en 86 av. J.-C. ‚Ä¢ Evelyn Hall  : ¬´ Je ne suis pas d‚Äôaccord avec ce que vous dites, mais je me battrai pour que vous ayez le droit de le dire. ¬ªEvelyn Beatrice Hall qui, dans un livre, The Friends of Voltaire, publi√© en 1906 sous le pseudonyme de S. G. Tallentyre, utilisa la c√©l√®bre formule pour r√©sumer la pens√©e voltairienne. ¬´ ¬´ I disapprove of what you say, but I will defend to the death your right to say it ¬ª, was his attitude now ¬ª, √©crit-elle. Elle confirmera par la suite que c‚Äô√©tait sa propre expression et qu‚Äôelle n‚Äôaurait pas d√ª √™tre mise entre guillemets. Qu‚Äôelle soit due √† la maladresse de l‚Äôauteur ou de l‚Äô√©diteur, la citation a √©t√© rapidement traduite en fran√ßais avant de conna√Ætre le succ√®s que l‚Äôon sait.Elle a √©t√© employ√©e pour la premi√®re fois en 1906 dans The Friends of Voltaire, livre en anglais d‚ÄôEvelyn Beatrice Hall √©crivant sous le pseudonyme de S. G. Tallentyre, pour r√©sumer la position de Voltaire : ¬´ ‚ÄòI disapprove of what you say, but I will defend to the death your right to say it‚Äô, was his attitude now ¬ª .  Le Fran√ßais se dit volontiers ¬´ voltairien ¬ª, comme il se dit ¬´ cart√©sien ¬ª ou ¬´ rabelaisien ¬ª. C'est un bon vivant √† l'esprit logique, √† qui ¬´ on ne la fait pas ¬ª. ¬´ √ätre voltairien ¬ª est synonyme d'ind√©pendance d'esprit, de libert√© de parole, de libert√© de presse, de scepticisme mordant, surtout contre la religion √©tablie .Une autre citation apocryphe de Voltaire a √©t√© souvent cit√©e en janvier 2014 lors de d√©bats en marge de l'affaire Dieudonn√© : ¬´ Pour savoir qui vous dirige vraiment il suffit de regarder ceux que vous ne pouvez pas critiquer. ¬ª Selon le site HoaxBuster , il s'agirait d'une citation en anglais d'un certain Kevin Alfred Strom en 1993, traduite en fran√ßais et attribu√©e √† Voltaire sans que la r√©f√©rence du pr√©tendu texte de Voltaire ne soit jamais pr√©cis√©e.‚Ä¢ Galileo Galilei : ¬´ Et pourtant elle tourne ! ¬ª (E pur si muove!) Galil√©e n‚Äôa pas d√©fi√© ainsi le Saint-Office  (ce qui, dans les circonstances extr√™mement tendues qui venaient de l'opposer √† l'√âglise, aurait √©t√© du suicide), et accepta de se renier. Cette l√©gende a √©t√© publi√©e en 1761 dans Querelles Litt√©raires , un si√®cle apr√®s sa mort.‚Ä¢ Albert Einstein : ¬´ L‚Äôastrologie est une science en soi, illuminatrice. J‚Äôai beaucoup appris gr√¢ce √† elle et je lui dois beaucoup. Les connaissances g√©ophysiques mettent en relief le pouvoir des √©toiles et des plan√®tes sur le destin terrestre. √Ä son tour, en un certain sens, l‚Äôastrologie le renforce. C‚Äôest pourquoi c‚Äôest une esp√®ce d‚Äô√©lixir de vie pour l‚Äôhumanit√©. ¬ª Apparue dans les ann√©es 1980, la citation va envahir les sites astrologiques. Elle connait son heure de gloire quand elle est reprise en exergue par l'astrologue √âlizabeth Teissier dans sa th√®se de sociologie . C'est un bien mauvais argument d'autorit√© puisque, en r√©alit√©, Einstein avait tr√®s mauvaise opinion de l‚Äôastrologie  .‚Ä¢ La citation ¬´ si les abeilles venaient √† dispara√Ætre, l'humanit√© n'aurait plus que quatre ann√©es devant elle ¬ª attribu√©e √† Albert Einstein est une rumeur propag√©e dans les m√©dias. Elle a √©t√© √©nonc√©e pour la premi√®re fois en 1994 (39 ans apr√®s la mort d'Einstein) dans une brochure distribu√©e par l‚ÄôUnion Nationale de l‚ÄôApiculture Fran√ßaise √† l‚Äôoccasion d‚Äôune manifestation √† Bruxelles contre la politique agricole europ√©enne   . Einstein √©tait physicien et non biologiste. Sans abeilles, la pollinisation d‚Äôun grand nombre de plantes ne se ferait plus, entra√Ænant la disparition de nombreux animaux et des effets d√©vastateurs sur l'agriculture et la biosph√®re  de mani√®re g√©n√©rale .‚Ä¢ G√©n√©ral Pierre Cambronne sur le champ de bataille de Waterloo : ¬´ La garde meurt, mais ne se rend pas ¬ª, phrase d√©mentie d'ailleurs par l'int√©ress√© lui-m√™me ¬´ puisque je ne suis pas mort c'est que je me suis rendu ¬ª . Victor Hugo affirmera dans Les Mis√©rables qu'il aurait r√©pondu ¬´ merde ¬ª (¬´ le mot de Cambronne  ¬ª).‚Ä¢ Henri IV de France lorsqu'il accepte de renoncer √† la foi r√©form√©e pour entrer dans Paris : ¬´ Paris vaut bien une messe ! ¬ª. La phrase tire vraisemblablement son origine des propos pr√™t√©s au ¬´ duc de Rosny ¬ª (Sully) dans Les Caquets de l'accouch√©e  (r√©cit anonyme de 1622) : ¬´ Comme disoit un jour le duc de Rosny au feu roy Henry le Grand, que Dieu absolve, lors qu'il luy demandoit pourquoy il n'alloit pas √† la messe aussi bien que lui : Sire, sire, la couronne vaut bien une messe ; aussi une esp√©e de connestable donn√©e √† un vieil routier de guerre merite bien de desguiser pour un temps sa conscience et de feindre d'estre grand catholique  ¬ª.‚Ä¢ ¬´ Lafayette nous voici ! ¬ª par le g√©n√©ral en chef des arm√©es am√©ricaines √† l'arriv√©e de ses troupes en France, durant la Premi√®re Guerre mondiale. Cette citation aurait √©t√© invent√©e pour son article par Gaston Riou, qui n'avait pu assister au discours. On suppose aussi qu‚Äôelle aurait √©t√© prononc√©e le jour anniversaire de l‚ÄôInd√©pendance des √âtats-Unis d'Am√©rique, le 4 juillet 1917 par le colonel Stanton, sur la tombe de La Fayette au cimeti√®re de Picpus √† Paris  .‚Ä¢ Andr√© Malraux  : ¬´ Le XXI  si√®cle sera spirituel ou ne sera pas ¬ª. (On trouve aussi ¬´ religieux ¬ª au lieu de ¬´ spirituel ¬ª.) Cette phrase semble une citation non litt√©rale de deux propos authentiques : ¬´ Je pense que la t√¢che du prochain si√®cle, en face de la plus terrible menace qu'ait connue l'humanit√©, va √™tre d'y r√©int√©grer les dieux. ¬ª et ¬´ Le probl√®me capital de la fin du si√®cle sera le probl√®me religieux ‚Äì sous une forme aussi diff√©rente de celle que nous connaissons, que le christianisme le fut des religions antiques . ¬ª‚Ä¢ Elvis Presley : ¬´ Je n'ai besoin des Noirs que pour acheter mes disques et cirer mes pompes  ¬ª. Il n'y a aucune preuve qu'il ait affirm√© cela, et rien ne laisse √† penser que ce grand admirateur de la culture afro-am√©ricaine ait pu avoir des opinions racistes. Par ailleurs, le succ√®s commercial d'Elvis fut d√ª principalement au public blanc, pr√©cis√©ment parce qu'il contribuait, √† travers le rock 'n' roll naissant, √† offrir une interpr√©tation ¬´ pr√©sentable ¬ª du rhythm 'n' blues consid√©r√© comme une ¬´ musique de Noirs pour des Noirs ¬ª, les deux styles pourtant tr√®s proches faisant alors l'objet de classements s√©par√©s, en vertu de la s√©gr√©gation raciale  qui √©tait alors √† l'≈ìuvre.‚Ä¢ Charles X n'a pas d√©clar√©, √† la Restauration ¬´ Rien n'y est chang√© [√† la France] si ce n'est qu'il s'y trouve un Fran√ßais de plus ! ¬ª. C'est Jacques Claude Beugnot qui l'√©crit, pilot√© par Talleyrand  qui fait publier cette d√©claration dans le Moniteur. Celui qui est alors comte d'Artois la rejette dans un premier temps, mais, devant le succ√®s de la formule, se dira convaincu de l'avoir prononc√©e  !‚Ä¢ ¬´ La grandeur d‚Äôune nation et son progr√®s moral peuvent √™tre jug√©s √† la ‚Ä¶ See more\\n‚Ä¢ Marie-Antoinette : ¬´ Qu'ils mangent de la brioche ! ¬ª En fait, les pamphl√©taires lui ont attribu√© une citation des Confessions de Jean-Jacques Rousseau, publi√©es en 1778 : ¬´ Je me rappelai le pis-aller d‚Äôune grande princesse √† qui l‚Äôon disait que les paysans n‚Äôavaient pas de pain, et qui r√©pondit : ‚ÄúQu‚Äôils mangent de la brioche‚Äù. J‚Äôachetai de la brioche. ¬ª (Livre sixi√®me : 1736).‚Ä¢ Hermann G√∂ring ou Joseph Goebbels : ¬´ Quand j'entends le mot ‚Äúculture‚Äù, je sors mon revolver. ¬ª (en allemand : ¬´ Wenn ich ‚ÄúKultur‚Äù h√∂re... entsichere ich meinen Browning ¬ª litt. quand j'entends le mot ‚Äúculture‚Äù, j'√¥te le cran de s√ªret√© de mon Browning.). Cette phrase vient d'une pi√®ce de th√©√¢tre allemande jou√©e en 1933, Schlageter, de Hanns Johst , ‚Ä¶ See more\\n‚Ä¢ Marie-Antoinette : ¬´ Qu'ils mangent de la brioche ! ¬ª En fait, les pamphl√©taires lui ont attribu√© une citation des Confessions de Jean-Jacques Rousseau, publi√©es en 1778 : ¬´ Je me rappelai le pis-aller d‚Äôune grande princesse √† qui l‚Äôon disait que les paysans n‚Äôavaient pas de pain, et qui r√©pondit : ‚ÄúQu‚Äôils mangent de la brioche‚Äù. J‚Äôachetai de la brioche. ¬ª (Livre sixi√®me : 1736).‚Ä¢ Hermann G√∂ring ou Joseph Goebbels : ¬´ Quand j'entends le mot ‚Äúculture‚Äù, je sors mon revolver. ¬ª (en allemand : ¬´ Wenn ich ‚ÄúKultur‚Äù h√∂re... entsichere ich meinen Browning ¬ª litt. quand j'entends le mot ‚Äúculture‚Äù, j'√¥te le cran de s√ªret√© de mon Browning.). Cette phrase vient d'une pi√®ce de th√©√¢tre allemande jou√©e en 1933, Schlageter, de Hanns Johst   , et √©tait devenue une plaisanterie r√©currente en Allemagne. Elle a par la suite √©t√© prononc√©e par Baldur von Schirach, chef des Jeunesses hitl√©riennes, lors d'un discours en 1938 .‚Ä¢ Simon IV de Montfort ou Arnaud Amaury : ¬´ Tuez-les tous, Dieu reconnaitra les siens ¬ª, durant le sac de B√©ziers, en 1209. Cette phrase pr√©sente en fait les trois types des citations apocryphes, puisqu'elle est :   See more\\n‚Ä¢ Madame de S√©vign√© : ¬´ Racine passera comme le caf√©. ¬ª M  de S√©vign√© n'appr√©ciait ni le th√©√¢tre de Jean Racine ni le caf√© mais le rapprochement entre ces deux termes vient de Voltaire et de Jean-Fran√ßois de La Harpe.‚Ä¢ Benjamin Franklin : ¬´ Un peuple pr√™t √† sacrifier un peu de libert√© pour un peu de s√©curit√© ne m√©rite ni l'une ni l'autre, et finit par perdre les deux. ¬ª La phrase exacte est : ¬´ Ceux qui peuvent renoncer √† la libert√© essentielle pour acheter un peu de ‚Ä¶ See more\\n‚Ä¢ Madame de S√©vign√© : ¬´ Racine passera comme le caf√©. ¬ª M  de S√©vign√© n'appr√©ciait ni le th√©√¢tre de Jean Racine ni le caf√© mais le rapprochement entre ces deux termes vient de Voltaire et de Jean-Fran√ßois de La Harpe.‚Ä¢ Benjamin Franklin : ¬´ Un peuple pr√™t √† sacrifier un peu de libert√© pour un peu de s√©curit√© ne m√©rite ni l'une ni l'autre, et finit par perdre les deux. ¬ª La phrase exacte est : ¬´ Ceux qui peuvent renoncer √† la libert√© essentielle pour acheter un peu de s√©curit√© temporaire, ne m√©ritent ni la libert√© ni la s√©curit√©. ¬ª, et rien n'atteste que Benjamin Franklin en soit l'auteur puisqu'elle appara√Æt dans une lettre qu'il a seulement contribu√© √† r√©diger . Par ailleurs, son utilisation fr√©quente pour d√©noncer des lois jug√©es liberticides au service d'objectifs s√©curitaires contraste fortement avec son sens d'origine, destin√© √† convaincre la famille Penn de payer une taxe pour financer la d√©fense de la Pennsylvanie  contre les Fran√ßais et les Indiens .‚Ä¢ Mirabeau : ¬´ Allez dire √† ceux qui vous envoient que nous sommes ici par la volont√© du peuple et que nous ne quitterons nos places que par la force des ba√Øonnettes ! ¬ª La phrase exacte est plus probablement : ¬´ Cependant, pour √©viter tout √©quivoque  et tout d√©lai, je d√©clare que si l‚Äôon vous a charg√©s de nous faire sortir d‚Äôici, vous devez demander des ordres pour employer la force ; car nous ne quitterons nos places que par la puissance des ba√Øonnettes. ¬ª Mais la version emphatique est la plus connue .‚Ä¢ Michel Rocard : ¬´ La France ne peut pas accueillir toute la mis√®re du monde... ¬ª La formule a bel et bien √©t√© prononc√©e par le premier ministre en 1989, cependant elle se serait poursuivie dans son √©nonc√© initial par un compl√©ment qui en change nettement le sens : ¬´ ...mais elle doit en prendre fid√®lement sa part. ¬ª Dans un article publi√© dans Le Monde en 1996, puis au 70  anniversaire de la Cimade  en 2009, Michel Rocard se plaignit de la citation r√©currente et syst√©matiquement tronqu√©e d'une phrase de lui sous la forme : ¬´ La France ne peut accueillir toute la mis√®re du monde ¬ª, alors que selon lui, la forme compl√®te √©tait : ¬´ La France ne peut accueillir toute la mis√®re du monde, mais elle doit en prendre fid√®lement sa part. ¬ª Toutefois, d'apr√®s un article de Thomas Deltombe    retra√ßant l'historique de la pol√©mique, Michel Rocard a bel et bien prononc√© la version courte de la phrase, dans un √©nonc√© visant clairement √† justifier une politique anti-immigration (dans un contexte de mont√©e du Front national), et ce √† au moins deux reprises : le 3 d√©cembre 1989 √† l'√©mission 7 sur 7, et le 7 janvier 1990 devant des √©lus socialistes originaires du Maghreb. Lors de l'allocution du 7 janvier 1990, Michel Rocard aurait ainsi d√©clar√© : ¬´ [...] la France n‚Äôest plus, ne peut plus √™tre une terre d‚Äôimmigration nouvelle. Je l‚Äôai d√©j√† dit et je le r√©affirme : quelque g√©n√©reux qu‚Äôon soit, nous ne pouvons accueillir toute la mis√®re du monde. ¬ª ‚Ä¢ Antoine Lavoisier : ¬´ Rien ne se perd, rien ne se cr√©e, tout se transforme  ¬ª.‚Ä¢ Charles Darwin : ¬´ Les esp√®ces qui survivent ne sont pas les esp√®ces les plus fortes, ni les plus intelligentes, mais celles qui s'adaptent le mieux aux changements ¬ª la phrase est tr√®s couramment attribu√©e √† Darwin n'est pas de lui. Elle est cependant dans le marbre du hall de l'Acad√©mie des sciences de Californie et a √©t√© aper√ßue encore dans une exposition consacr√©e √† la pal√©ontologie √† la Cit√© des Sciences √† Paris. Une citation tronqu√©e √† √©galement √©t√© mise en √©vidence par le British National History Museum de Londres, plus exactement sur le site internet de l'exposition c√©l√©brant le bicentenaire de Darwin: ¬´Dans la lutte pour la survie, les plus aptes gagnent aux d√©pens de leurs rivaux, parce qu'ils r√©ussissent √† s'adapter le mieux √† leur environnement¬ª. ¬´Ces phrases n'apparaissent nulle part dans l'oeuvre de Darwin¬ª, affirme Patrick Tort, auteur de nombreux ouvrages sur Darwin et le darwinisme qui travaille au Mus√©um national d'histoire naturelle √† Paris. Mais le plus pr√©judiciable est que les citations sont non seulement attribu√©es √† tort √† Darwin, mais ne sont pas non plus fid√®les √† sa pens√©e. En effet d'apr√®s son ≈ìuvre L'Origine des Esp√®ces, publi√©e en 1859, il y d√©voile la th√©orie de la s√©lection naturelle. Or les esp√®ces qui survivent davantage ne sont pas les esp√®ces qui s'adaptent le mieux au changement. ¬´Ce sont les plus chanceuses, ou celles qui ont d√©j√† les bonnes caract√©ristiques physiques pour les transmettre √† la g√©n√©ration suivante¬ª, explique ce professeur . See more\\nJul 3, 2025\\xa0¬∑ Mais la lettre de l‚Äôexpression nous dit, elle, autre chose : au lieu de profiter du pr√©sent, nous allons au-devant de nous-m√™mes, vers un ailleurs plus palpitant que l‚Äô√©vidence ‚Ä¶\\n\\n### Citation apocryphe ‚Äî Wikip√©dia\\nCet article ne cite pas suffisamment ses sources (f√©vrier 2017).\\nSi vous disposez d'ouvrages ou d'articles de r√©f√©rence ou si vous connaissez des sites web de qualit√© traitant du th√®me abord√© ici, merci de compl√©ter l'article en donnant les r√©f√©rences utiles √† sa v√©rifiabilit√© et en les liant √† la section ¬´\\xa0Notes et r√©f√©rences\\xa0¬ª.\\nCertaines informations figurant dans cet article ou cette section devraient √™tre mieux reli√©es aux sources mentionn√©es dans les sections ¬´\\xa0Bibliographie\\xa0¬ª, ¬´\\xa0Sources\\xa0¬ª ou ¬´\\xa0Liens externes\\xa0¬ª (f√©vrier 2017).\\nUne citation apocryphe est une citation attribu√©e √† une personne qui n‚Äôa pourtant jamais tenu les propos rapport√©s, ou alors les a exprim√©s sous une forme diff√©rente.\\nLe sociologue Robert Merton remarqua que certaines situations s'expliquent par ce qu'il appela l'¬´\\xa0effet Matthieu\\xa0¬ª, en r√©f√©rence √† la phrase de l'√âvangile selon saint Matthieu\\xa0: ¬´\\xa0√Ä celui qui a, il sera beaucoup donn√© et il vivra dans l‚Äôabondance, mais √† celui qui n‚Äôa rien, il sera tout pris, m√™me ce qu‚Äôil poss√©dait.\\xa0¬ª Quand la phrase est suffisamment percutante pour rester c√©l√®bre, mais que l'auteur ne l'est pas assez pour √™tre retenu, on attribue la phrase √† une personne plus c√©l√®bre, mais dont les propres id√©es et le ton correspondent suffisamment pour que cela semble plausible. N. David Mermin explique ainsi que l'effet Matthieu a conduit √† attribuer √† Richard Feynman sa boutade √† propos de la physique quantique\\xa0: ¬´\\xa0Shut up and calculate\\xa0¬ª[1].\\nLe Premier ministre britannique Winston Churchill √©tant c√©l√®bre pour sa r√©partie, il existe de fausses citations de toutes origines qui lui sont attribu√©es. Propos d√©form√©s, contexte modifi√©, ou attribution abusive ‚Äî ceci √©tant favoris√© par la tendance qu'avait Churchill lui-m√™me √† faire des citations sans le pr√©ciser[2].\\n¬´\\xa0J‚Äôaimais l‚Äôauteur du livre De l‚ÄôEsprit [Helv√©tius]. Cet homme valait mieux que tous ses ennemis ensemble\\xa0; mais je n‚Äôai jamais approuv√© ni les erreurs de son livre, ni les v√©rit√©s triviales qu‚Äôil d√©bite avec emphase. J‚Äôai pris son parti hautement, quand des hommes absurdes l‚Äôont condamn√© pour ces v√©rit√©s m√™mes.\\xa0¬ª\\n‚Äî\\xa0Questions sur l‚ÄôEncyclop√©die, article ¬´\\xa0Homme\\xa0¬ª[4]\\n\\n### Likely from a poetic or musica\\nDec 30, 2024\\xa0¬∑ From poetic Liszt and Grieg concertos to a little bit of magic from Martha Argerich and friends at Le Piano Symphonique in Lucerne From the poetry of the young Yoav Levanon ‚Ä¶\\nDec 29, 2024\\xa0¬∑ From addressing climate change and social justice to exploring personal resilience, poets have captured the essence of 2024‚Äôs triumphs, ‚Ä¶\\nDec 20, 2024\\xa0¬∑ Below, our first-rate writers, thinkers, and contributors share the musical moments from 2024 that impacted them most. From Beyonc√© galloping through our hearts with Cowboy ‚Ä¶\\nJan 7, 2025\\xa0¬∑ My focus this year spanned from seductive R&B vocals, to fresh takes on classic country, to some of the most refreshing pop and hip-hop projects in recent history. This article ‚Ä¶\\nJan 15, 2025\\xa0¬∑ These are some of the most-read and best-loved poetic gems we‚Äôve shared this year. If you want even more poetry, Mischa Willet has more than enough poetry recommendations to fill your reading list for 2025, too. (Or ‚Ä¶\\nDec 15, 2024\\xa0¬∑ A reading list of our 2024 features. Art by Erin Maala. Over the last 12 months, the Poetry Foundation has been hard at work, publishing nearly three dozen longform features‚Äîeverything from critical essays to profiles, from ‚Ä¶\\n\\n### 2024: A year in concert reviews, astonishing youth, late-romantic ...\\nBaroque music featured highly this year, Lawrence Cummings and the AAM used just eight singers for their moving version of Bach's St Matthew Passion and equally life-enhancing was Bach's Brandenburg Concertos from the OAE. We heard Handel's original version of Esther from Solomon's Knot, who also popped up in Monteverdi's Vespers of 1610, one of a pair of contrasting performances of this work, the other by from the ever admirable Sixteen. There was more Handel at the Wimbledon Festival with Benjamin Hulett and Helen Charlston in Jephtha.\\xa0 I Fagiolini took us to 17th century Venice for glorious multi-choir music by Benevoli.\\nThanks to baritone Florian St√∂rtz and pianist Aleksandra Myslek I finally got to hear a goodly selection of songs by Robert Kahn, whose music was forbidden by the Nazis and who was forced to flee to England in his 70s, whilst tenor Laurence Kilsby and pianist Ella O'Neill took us on a journey of remarkable emotional depth.\\nAt Le Piano Symphonique in Lucerne, Martha Argerich and two friends created a little bit of magic in an evening that moved through from large-scale Liszt and Grieg to poetic intimacy.\\nThere were rarities. At the Proms, Benjamin Grosvenor, Edward Gardner and the LPO turned Busoni's Piano Concerto into riveting symphonic theatre whilst Andras Schiff and the OAE brought their Mendelssohn festival to a close with his rarely performed symphony-cantata Lobesgesang. And a real rarity, impressively tackled by the North London Chorus was Ethel Smyth's late work, The Prison. And on a different scale, pianist Simon Callaghan tackled Cyril Scott's unjustly neglected Piano Sonata.\\nIn contemporary music, the National Youth Orchestra and National Youth Brass Band combined forces for Gavin Higgins's epic Concerto Grosso for Brass Band and Orchestra, whilst horn player Ben Goldscheider joined forces with Britten Sinfonia for the premiere of Huw Watkins' Horn Concerto.\"}\n",
      "üßê Fact-checking: Je n'y peux sans que d'une chose Je me fiche de tous les cas t√¥t Que le sapin me...\n",
      "‚úÖ All statements are supported or unverified.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\552.mp4\n",
      "Deepfake label: REAL, Fact-check label: True\n",
      "üíæ Saved checkpoint after 553 videos\n",
      "üìº Processing video 554: ../data/dfw_youtube_release\\553.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\553.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_02...\n",
      "‚úÖ SPEAKER_02 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-2.84] Unknown: C'est qui √† la t√™te, lui explique comment on a clair\n",
      "[2.84-14.48] SPEAKER_01: Le corps du Christ, oh comme je l'aime Foudrez avoir le m√™me Oh dis J√©sus, ah tu fais de la Miscue Comme je ferais avoir le corps du Christ Le corps du Christ\n",
      "[14.48-16.12] Unknown: Le corps du Christ\n",
      "[16.12-18.12] SPEAKER_01: Le corps du Christ\n",
      "[18.12-22.32] Unknown: Oh dis J√©sus, ah tu fais de la Miscue\n",
      "[22.32-25.12] SPEAKER_01: Comme je ferais avoir le corps du Christ\n",
      "[25.12-35.18] Unknown: Une fois... p'tain Papis\n",
      "[35.54-38.50] SPEAKER_00: M√®che\n",
      "[38.76-46.24] Unknown: cm\n",
      "[48.40-54.80] SPEAKER_02: d'oeil Í∑∏Îûò\n",
      "[54.80-57.72] Unknown: carte\n",
      "[58.04-59.88] SPEAKER_02: 87\n",
      "[59.88-64.88] Unknown: Tell me why beauty pie Told me to do\n",
      "[64.88-70.88] SPEAKER_02: Jack's but I see too\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 2.84, 'speaker': 'Unknown', 'text': \"C'est qui √† la t√™te, lui explique comment on a clair\", 'reason': 'This statement makes a claim or seeks explanation about leadership or clarity, which might be relevant for fact-checking political or organizational context.', 'context': 'Unknown context, possibly an informal discussion or interview, early in the transcript, unclear topic but could relate to leadership or organizational clarity.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\553\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\553.mp4, 691200 bytes wanted but 0 bytes read,at frame 1779/1781, at time 74.20/74.26 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n",
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\553.mp4, 691200 bytes wanted but 0 bytes read,at frame 1780/1781, at time 74.24/74.26 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['00cbf7ab159e4087976cf723a0d2083a_clip_1.mp4'], 'pred': [0.24656760692596436], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 2.84, 'speaker': 'Unknown', 'text': \"C'est qui √† la t√™te, lui explique comment on a clair\", 'reason': 'This statement makes a claim or seeks explanation about leadership or clarity, which might be relevant for fact-checking political or organizational context.', 'context': 'Unknown context, possibly an informal discussion or interview, early in the transcript, unclear topic but could relate to leadership or organizational clarity.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.24656760692596436}]\n",
      "üì∞ Enriching statements with articles...\n",
      "https://www.bing.com/search?q=C'est qui √† la t√™te, lui explique comment on a clair\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"59b64acf9165490dc3930ef060be0bad\", element=\"f.698038E6A0A07C2EB40E9BD07AA3DCB9.d.8419BE263E2FAC37CACA3D85006E0A03.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"59b64acf9165490dc3930ef060be0bad\", element=\"f.698038E6A0A07C2EB40E9BD07AA3DCB9.d.8419BE263E2FAC37CACA3D85006E0A03.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"59b64acf9165490dc3930ef060be0bad\", element=\"f.698038E6A0A07C2EB40E9BD07AA3DCB9.d.8419BE263E2FAC37CACA3D85006E0A03.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"59b64acf9165490dc3930ef060be0bad\", element=\"f.698038E6A0A07C2EB40E9BD07AA3DCB9.d.8419BE263E2FAC37CACA3D85006E0A03.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"59b64acf9165490dc3930ef060be0bad\", element=\"f.698038E6A0A07C2EB40E9BD07AA3DCB9.d.8419BE263E2FAC37CACA3D85006E0A03.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"59b64acf9165490dc3930ef060be0bad\", element=\"f.698038E6A0A07C2EB40E9BD07AA3DCB9.d.8419BE263E2FAC37CACA3D85006E0A03.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"59b64acf9165490dc3930ef060be0bad\", element=\"f.698038E6A0A07C2EB40E9BD07AA3DCB9.d.8419BE263E2FAC37CACA3D85006E0A03.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"59b64acf9165490dc3930ef060be0bad\", element=\"f.698038E6A0A07C2EB40E9BD07AA3DCB9.d.8419BE263E2FAC37CACA3D85006E0A03.e.27\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"59b64acf9165490dc3930ef060be0bad\", element=\"f.698038E6A0A07C2EB40E9BD07AA3DCB9.d.8419BE263E2FAC37CACA3D85006E0A03.e.28\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"59b64acf9165490dc3930ef060be0bad\", element=\"f.698038E6A0A07C2EB40E9BD07AA3DCB9.d.8419BE263E2FAC37CACA3D85006E0A03.e.29\")>]\n",
      "4 expressions utiles pour expliquer quelque chose en ‚Ä¶\n",
      "https://www.francaisauthentique.com/4-expressions-utiles-pour-expliquer-quelque-chose-en-francais/\n",
      "La mise en relief : c‚Äôest ‚Ä¶ qui/c‚Äôest‚Ä¶ que - ALLOFLE\n",
      "https://allofle.com/la-mise-en-relief-cest-qui-cest-que-grammaire-du-niveau-intermediaire/\n",
      "Found 3 relevant links:\n",
      "[{'title': \"C'est qui √† la t√™te, lui expli\", 'link': \"https://www.bing.com/search?q=C'est qui √† la t√™te, lui explique comment on a clair\"}, {'title': '4 expressions utiles pour expliquer quelque chose en ‚Ä¶', 'link': 'https://www.francaisauthentique.com/4-expressions-utiles-pour-expliquer-quelque-chose-en-francais/'}, {'title': 'La mise en relief : c‚Äôest ‚Ä¶ qui/c‚Äôest‚Ä¶ que - ALLOFLE', 'link': 'https://allofle.com/la-mise-en-relief-cest-qui-cest-que-grammaire-du-niveau-intermediaire/'}]\n",
      "‚è≥ Attempt 1: Crawling https://www.francaisauthentique.com/4-expressions-utiles-pour-expliquer-quelque-chose-en-francais/ with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=C'est qui √† la t√™te, lui explique comment on a clair with wait_time=10s\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=C'est qui √† la t√™te, lui explique comment on a clair:\n",
      "Jul 30, 2018¬†¬∑ La premi√®re petite phrase, c‚Äôest ¬´ c‚Äôest la raison pour laquelle ¬ª. Quand on utilise √ßa, eh bien, on dit que ce qu‚Äôon vient de dire explique ce qui va suivre. On va prendre un petit exemple pour que vous compreniez bien. On ‚Ä¶\n",
      "Mar 28, 2022¬†¬∑ Pour mettre en relief un nom ou un groupe nominal dans la phrase, il est courant de d√©tacher l‚Äô√©l√©ment en t√™te de phrase et de l‚Äôencadrer par ¬´ c‚Äôest ‚Ä¶ qui ¬ª, s‚Äôil s‚Äôagit d‚Äôun ‚Ä¶\n",
      "Le service sans frais de Google traduit instantan√©ment des mots, d...\n",
      "‚úÖ Crawled content from https://www.francaisauthentique.com/4-expressions-utiles-pour-expliquer-quelque-chose-en-francais/:\n",
      "Abonnez-vous √† la chaine You Tube pour ne manquer aucune vid√©o : cliquez ici.\n",
      "T√©l√©chargez le fichier MP3 ici.\n",
      "T√©l√©chargez le fichier PDF ici.\n",
      "Transcription de la vid√©o :\n",
      "Salut √† tous, merci de nous rejoindre pour cette nouvelle vid√©o. Avant de commencer, je voulais juste vous dire que je vous ai mis en bas un lien, je vous ai pr√©par√© une petite surprise li√©e au pack 4 de Fran√ßais Authentique, le pack 4 qui est la rediffusion de toutes les conf√©rences du s√©minaire que j‚Äôai donn√© √† Paris. Ce cours...\n",
      "https://www.bing.com/search?q=Unknown context, possibly an informal discussion or interview, early in the transcript, unclear topic but could relate to leadership or organizational clarity.\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"71b8e14340b722d3625f1b3f7b57c0c0\", element=\"f.F2773777464500C55055656F9A4C50C0.d.86FEA0503CFC0CCBBC2F227F5EEADB82.e.14\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"71b8e14340b722d3625f1b3f7b57c0c0\", element=\"f.F2773777464500C55055656F9A4C50C0.d.86FEA0503CFC0CCBBC2F227F5EEADB82.e.15\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"71b8e14340b722d3625f1b3f7b57c0c0\", element=\"f.F2773777464500C55055656F9A4C50C0.d.86FEA0503CFC0CCBBC2F227F5EEADB82.e.16\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"71b8e14340b722d3625f1b3f7b57c0c0\", element=\"f.F2773777464500C55055656F9A4C50C0.d.86FEA0503CFC0CCBBC2F227F5EEADB82.e.17\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"71b8e14340b722d3625f1b3f7b57c0c0\", element=\"f.F2773777464500C55055656F9A4C50C0.d.86FEA0503CFC0CCBBC2F227F5EEADB82.e.18\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"71b8e14340b722d3625f1b3f7b57c0c0\", element=\"f.F2773777464500C55055656F9A4C50C0.d.86FEA0503CFC0CCBBC2F227F5EEADB82.e.19\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"71b8e14340b722d3625f1b3f7b57c0c0\", element=\"f.F2773777464500C55055656F9A4C50C0.d.86FEA0503CFC0CCBBC2F227F5EEADB82.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"71b8e14340b722d3625f1b3f7b57c0c0\", element=\"f.F2773777464500C55055656F9A4C50C0.d.86FEA0503CFC0CCBBC2F227F5EEADB82.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"71b8e14340b722d3625f1b3f7b57c0c0\", element=\"f.F2773777464500C55055656F9A4C50C0.d.86FEA0503CFC0CCBBC2F227F5EEADB82.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"71b8e14340b722d3625f1b3f7b57c0c0\", element=\"f.F2773777464500C55055656F9A4C50C0.d.86FEA0503CFC0CCBBC2F227F5EEADB82.e.23\")>]\n",
      "3344-14313-1-PB.pdf\n",
      "https://discovery.ucl.ac.uk/id/eprint/10091304/1/FQS%20informal%20conversations.pdf\n",
      "Informal Interviews: A Gateway to Rich Qualitative ‚Ä¶\n",
      "https://journalism.university/communication-research-methods/informal-interviews-qualitative-insights-gateway/\n",
      "Found 3 relevant links:\n",
      "[{'title': 'Unknown context, possibly an i', 'link': 'https://www.bing.com/search?q=Unknown context, possibly an informal discussion or interview, early in the transcript, unclear topic but could relate to leadership or organizational clarity.'}, {'title': '3344-14313-1-PB.pdf', 'link': 'https://discovery.ucl.ac.uk/id/eprint/10091304/1/FQS%20informal%20conversations.pdf'}, {'title': 'Informal Interviews: A Gateway to Rich Qualitative ‚Ä¶', 'link': 'https://journalism.university/communication-research-methods/informal-interviews-qualitative-insights-gateway/'}]\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=Unknown context, possibly an informal discussion or interview, early in the transcript, unclear topic but could relate to leadership or organizational clarity. with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://discovery.ucl.ac.uk/id/eprint/10091304/1/FQS%20informal%20conversations.pdf with wait_time=10s\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=Unknown context, possibly an informal discussion or interview, early in the transcript, unclear topic but could relate to leadership or organizational clarity.:\n",
      "Abstract: Arguing that the role of informal conversations in qualitative social and educational research methodologies is contested but also relatively neglected, in this article we set out ‚Ä¶\n",
      "Mar 24, 2022¬†¬∑ We use examples to show how we have used informal conversations in our research, which we interrogate and use to raise a number of, mainly ethical and ‚Ä¶\n",
      "Dec 24, 2023¬†¬∑ In this blog, we‚Äôll explore the concept of informal interviews, their strengths and limitations, and how they can provide res...\n",
      "‚úÖ Crawled content from https://discovery.ucl.ac.uk/id/eprint/10091304/1/FQS%20informal%20conversations.pdf:\n",
      "...\n",
      "‚úÖ Finished enriching statements with articles.\n",
      "üß™ Running fact-checks on statements...\n",
      "{'start': 0.0, 'end': 2.84, 'speaker': 'Unknown', 'text': \"C'est qui √† la t√™te, lui explique comment on a clair\", 'reason': 'This statement makes a claim or seeks explanation about leadership or clarity, which might be relevant for fact-checking political or organizational context.', 'context': 'Unknown context, possibly an informal discussion or interview, early in the transcript, unclear topic but could relate to leadership or organizational clarity.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.24656760692596436, 'article_texts': \"### C'est qui √† la t√™te, lui expli\\nJul 30, 2018\\xa0¬∑ La premi√®re petite phrase, c‚Äôest ¬´ c‚Äôest la raison pour laquelle ¬ª. Quand on utilise √ßa, eh bien, on dit que ce qu‚Äôon vient de dire explique ce qui va suivre. On va prendre un petit exemple pour que vous compreniez bien. On ‚Ä¶\\nMar 28, 2022\\xa0¬∑ Pour mettre en relief un nom ou un groupe nominal dans la phrase, il est courant de d√©tacher l‚Äô√©l√©ment en t√™te de phrase et de l‚Äôencadrer par ¬´ c‚Äôest ‚Ä¶ qui ¬ª, s‚Äôil s‚Äôagit d‚Äôun ‚Ä¶\\nLe service sans frais de Google traduit instantan√©ment des mots, des expressions et des pages Web entre le fran√ßais et plus de 100 autres langues.\\nJan 14, 2025\\xa0¬∑ Lorsqu‚Äôon commente ¬´c‚Äôest clair¬ª, on donne l‚Äôimpression que tout a √©t√© dit, qu‚Äôil n‚Äôy a plus rien √† ajouter. L‚Äôexpression a le pouvoir de clore une discussion tout en signifiant √† son...\\nNos experts vous expliquent la r√®gle : ¬´ C‚Äôest l√† o√π ¬ª ou ¬´ C‚Äôest l√† que ¬ª ? Comment √©viter les pl√©onasmes grammaticaux - Astuces et exercices corrig√©s pour √©crire sans fautes !\\nNov 16, 2018\\xa0¬∑ Pour ajouter un peu d‚Äôoriginalit√© √† votre production √©crite, nous vous proposons, ci-dessous, des expressions, des locutions et des syntagmes construits autour du mot t√™te. Vous trouverez √©galement une liste pour ‚Ä¶\\n\\n### 4 expressions utiles pour expliquer quelque chose en ‚Ä¶\\nAbonnez-vous √† la chaine You Tube pour ne manquer aucune vid√©o : cliquez ici.\\nT√©l√©chargez le fichier MP3 ici.\\nT√©l√©chargez le fichier PDF ici.\\nTranscription de la vid√©o :\\nSalut √† tous, merci de nous rejoindre pour cette nouvelle vid√©o. Avant de commencer, je voulais juste vous dire que je vous ai mis en bas un lien, je vous ai pr√©par√© une petite surprise li√©e au pack 4 de Fran√ßais Authentique, le pack 4 qui est la rediffusion de toutes les conf√©rences du s√©minaire que j‚Äôai donn√© √† Paris. Ce cours, il a √©t√© en vente une semaine et ensuite, de temps en temps pour certains √©v√©nements, mais il n‚Äôest plus en vente, plus accessible et l√†, je l‚Äôai rouvert, je l‚Äôai remis √† disposition jusqu‚Äô√† dimanche 5 ao√ªt et non seulement il est √† disposition, mais en plus, il est en promotion √† 50 %. Vous avez un lien en bas, vous pouvez en profiter jusqu‚Äô√† cette date, ensuite, il sera trop tard. Pour ceux qui ne connaissent pas le contenu, il vous suffit de cliquer sur le lien ; c‚Äôest tout simplement la rediffusion de ma conf√©rence sur les diff√©rents monuments de Paris, celle de mon fr√®re sur la gastronomie fran√ßaise, film√©e par des professionnels, les interviews de diff√©rents membres qui ont appris √† parler le fran√ßais et qui nous disent comment ils ont fait, un forum de questions o√π tous les membres me posaient √† moi et √† ma famille (C√©line ma femme et ma belle-s≈ìur Charl√®ne et mon fr√®re Jimmy) diff√©rentes questions li√©es √† l‚Äôapprentissage du fran√ßais et un petit peu au d√©veloppement personnel et √† Fran√ßais Authentique. Plein d‚Äôinformations de qualit√© dans un pack qui est disponible √† 50 % de son prix jusqu‚Äôau 5 ao√ªt et il ne sera plus en vente au moins jusqu‚Äô√† la fin de l‚Äôann√©e ‚Äì peut-√™tre que je le ressortirai pour No√´l, ce n‚Äôest pas s√ªr, et si je le ressors pour No√´l, il ne sera pas √† 50 %. Donc, c‚Äôest maintenant ou jamais, il y a un lien en bas. Mais, ce n‚Äôest pas √ßa le sujet de la vid√©o d‚Äôaujourd‚Äôhui : le sujet d‚Äôaujourd‚Äôhui, c‚Äôest de parler de quatre expressions qui vous permettent d‚Äôexpliquer quelque chose en fran√ßais.\\nCes quatre expressions, elles sont interchangeables, c‚Äôest-√†-dire que vous pouvez, dans chaque exemple que je vais vous donner, remplacer l‚Äôune par l‚Äôautre. On peut dire que ces quatre expressions veulent dire la m√™me chose, mais vous verrez qu‚Äôelles sont tr√®s tr√®s utiles dans le langage courant pour expliquer des choses et elles vous permettront souvent de vous d√©bloquer un peu. Parfois, on est en train de parler, on a un souci, on n‚Äôarrive pas √† dire quelque chose et ce genre de petites phrases vous aide √† vous d√©bloquer.\\nLa premi√®re petite phrase, c‚Äôest\\xa0¬´ c‚Äôest la raison pour laquelle\\xa0¬ª. Quand on utilise √ßa, eh bien, on dit que ce qu‚Äôon vient de dire explique ce qui va suivre. On va prendre un petit exemple pour que vous compreniez bien. On peut dire :\\xa0¬´ J‚Äôaime passer mes vacances en France, c‚Äôest la raison pour laquelle j‚Äôapprends le fran√ßais.\\xa0¬ª Vous voyez, ici, on veut expliquer la raison, on veut expliquer pourquoi on apprend le fran√ßais. Donc, on dit que c‚Äôest la raison pour laquelle j‚Äôapprends le fran√ßais, on a donn√© l‚Äôexplication avant : c‚Äôest parce qu‚Äôon aime passer ses vacances en France. Donc, ce qui vient avant explique ce qui vient apr√®s, cette petite expression passe-partout,\\xa0¬´ c‚Äôest la raison pour laquelle\\xa0¬ª. Vous pouvez entendre :\\xa0¬´ Ah, j‚Äôai mal dormi, c‚Äôest la raison pour laquelle je suis tr√®s fatigu√© aujourd‚Äôhui.\\xa0¬ª Encore une fois, ce qui vient apr√®s\\xa0¬´ c‚Äôest la raison pour laquelle\\xa0¬ª est expliqu√© par ce qu‚Äôil y avait avant. Ici, on comprend que je suis fatigu√© parce que j‚Äôai mal dormi cette nuit. Donc, ce qui vient avant nous explique ce qui vient apr√®s ; on comprend pourquoi on apprend le fran√ßais dans le premier exemple (on apprend le fran√ßais parce qu‚Äôon aime passer les vacances en France) et dans le deuxi√®me exemple, on apprend pourquoi je suis fatigu√© aujourd‚Äôhui : c‚Äôest parce que j‚Äôai mal dormi.\\nDeuxi√®me expression synonyme, elle marche exactement de la m√™me fa√ßon, c‚Äôest\\xa0¬´ c‚Äôest pourquoi\\xa0¬ª. Par exemple, vous pouvez dire :\\xa0¬´ J‚Äôadore cet auteur, c‚Äôest pourquoi j‚Äôai lu tous ses livres.\\xa0¬ª La raison pour laquelle vous avez lu tous ses livres ‚Äì on explique la deuxi√®me partie, ce qui vient apr√®s le\\xa0¬´ c‚Äôest pourquoi\\xa0¬ª ‚Äì on l‚Äôexplique avant. C‚Äôest parce qu‚Äôon adore cet auteur qu‚Äôon a lu tous ses livres.\\nVous pouvez dire :\\xa0¬´ Cette maison est tr√®s ch√®re, c‚Äôest pourquoi je ne l‚Äôai pas achet√©e.\\xa0¬ª Je n‚Äôai pas achet√© cette maison et on l‚Äôexplique en disant qu‚Äôelle est trop ch√®re et on utilise le\\xa0¬´ c‚Äôest pourquoi\\xa0¬ª pour faire la transition entre les deux. Encore une fois, ce qui vient apr√®s\\xa0¬´ c‚Äôest pourquoi\\xa0¬ª est expliqu√© par ce qui vient avant.\\nUne autre fa√ßon d‚Äôexpliquer quelque chose, c‚Äôest d‚Äôutiliser la petite expression\\xa0¬´ c‚Äôest pour cela\\xa0¬ª et vous entendrez souvent √† l‚Äôoral\\xa0¬´ c‚Äôest pour √ßa\\xa0¬ª.\\xa0¬´ C‚Äôest pour √ßa\\xa0¬ª, c‚Äôest plus familier, c‚Äôest moins joli que\\xa0¬´ c‚Äôest pour cela\\xa0¬ª, mais ces deux expressions sont les m√™mes : c‚Äôest pour √ßa, c‚Äôest pour cela. C‚Äôest pareil : ce qui vient apr√®s est expliqu√© par ce qui vient avant. Vous pouvez, par exemple, entendre quelqu‚Äôun dire :\\xa0¬´ Il a trois petites s≈ìurs, c‚Äôest pour cela qu‚Äôil aime s‚Äôoccuper des enfants.\\xa0¬ª Donc, on sait qu‚Äôil aime s‚Äôoccuper des enfants et l‚Äôexplication nous est donn√©e avant la petite phrase\\xa0¬´ c‚Äôest pour cela\\xa0¬ª. On dit quelque chose, on dit\\xa0¬´ c‚Äôest pour cela\\xa0¬ª, on donne ensuite la cons√©quence.\\nVous pouvez entendre √©galement :\\xa0¬´ Il fait 40¬∞C, c‚Äôest pour cela que j‚Äôai allum√© la climatisation.\\xa0¬ª Encore une fois,\\xa0¬´ c‚Äôest pour √ßa\\xa0¬ª, c‚Äôest comme\\xa0¬´ c‚Äôest pour cela\\xa0¬ª sauf que c‚Äôest un peu plus familier. On explique :\\xa0¬´ J‚Äôai allum√© la climatisation et j‚Äôexplique √ßa en disant [que] c‚Äôest parce qu‚Äôil fait chaud.\\xa0¬ª C‚Äôest pour √ßa, c‚Äôest pour cela.\\nEt enfin, quatri√®me expression, exactement sur le m√™me principe : voil√† pourquoi. Ce qui vient apr√®s\\xa0¬´ voil√† pourquoi\\xa0¬ª est expliqu√© par ce qu‚Äôil y avait avant. Je vais vous donner un petit exemple. Il est tr√®s comp√©tent, voil√† pourquoi son chef lui a accord√© une augmentation. Son chef lui a accord√© une augmentation ; on l‚Äôexplique avant : c‚Äôest parce qu‚Äôil est tr√®s comp√©tent, et entre les deux, on met\\xa0¬´ voil√† pourquoi ¬ª L√†, vous commencez, je pense, √† bien comprendre le principe.\\nUn dernier exemple. J‚Äôadorais mon oncle, voil√† pourquoi son d√©c√®s me touche beaucoup. Ce qui vient apr√®s est expliqu√© par ce qui vient avant.\\nJ‚Äôesp√®re que tout √ßa est un peu plus clair pour vous maintenant. Ces quatre expressions, comme je vous l‚Äôai dit, elles sont interchangeables, c‚Äôest-√†-dire que vous pouvez les √©changer l‚Äôune et l‚Äôautre. Ne stressez pas l√†-dessus, mais soyez attentifs quand vous les entendez ou quand vous les lisez, √ßa vous permettra de bien mieux les comprendre, les assimiler et r√©ussir √† les utiliser √† l‚Äôoral. Moi, j‚Äôaime bien l‚Äôexpression\\xa0¬´ c‚Äôest la raison pour laquelle\\xa0¬ª et je sais que j‚Äôai essay√© de trouver l‚Äô√©quivalent en allemand et en anglais quand je parlais ces langues pour justement me sortir de certaines situations de blocage.\\nMerci d‚Äôavoir regard√© cette vid√©o, n‚Äôoubliez pas la promotion sur le pack 4 qui se termine dimanche 5 ao√ªt 2018, il y a un lien en bas pour en savoir plus. J‚Äôesp√®re vous retrouver de l‚Äôautre c√¥t√©. Salut !\\nApprenez √† parler fran√ßais en prenant du plaisir avec Fran√ßais Authentique\\nNotifications\\n\\n### Unknown context, possibly an i\\nAbstract: Arguing that the role of informal conversations in qualitative social and educational research methodologies is contested but also relatively neglected, in this article we set out ‚Ä¶\\nMar 24, 2022\\xa0¬∑ We use examples to show how we have used informal conversations in our research, which we interrogate and use to raise a number of, mainly ethical and ‚Ä¶\\nDec 24, 2023\\xa0¬∑ In this blog, we‚Äôll explore the concept of informal interviews, their strengths and limitations, and how they can provide researchers with rich, qualitative insights that other methods might miss. What are informal ‚Ä¶\\nAnother aspect of interview context to contemplate is whether you are bringing artefacts (such as documents and photographs) or data (such as video or transcriptions) into the interview as ‚Ä¶\\nInformal discussions can be the first phase towards the definition of more structured interviews. During the process of community engagement: allows a great variety of information, and often unexpected information. People can ‚Ä¶\\nMar 14, 2025\\xa0¬∑ An informal interview is the art of obtaining important information through casual conversation, without a rigid structure of questions. Unlike a classic structured interview with prepared questions, an informal conversation ‚Ä¶\\nMar 24, 2022\\xa0¬∑ Sometimes informal conversations are not only the best way, they are the only way to generate data. We use examples to show how we have used informal conversations in our research, which we...\"}\n",
      "üßê Fact-checking: C'est qui √† la t√™te, lui explique comment on a clair...\n",
      "‚úÖ All statements are supported or unverified.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\553.mp4\n",
      "Deepfake label: REAL, Fact-check label: True\n",
      "üíæ Saved checkpoint after 554 videos\n",
      "üìº Processing video 555: ../data/dfw_youtube_release\\554.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\554.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-11.00] Unknown: ... Alors aujourd'hui, comment est-ce que l'on devient un praticien en massage bien-√™tre ?\n",
      "[11.00-52.00] SPEAKER_01: On va l'appeler comme √ßa si, puisqu'effectivement, on n'a pas l'ode d'employer le mot Massage directement et seul puisqu'il est r√©serv√© justement √† la profession de massures qui n'est, donc un dipl√¥me d'√©tarque, on passe en trois ans. Il y a qu'une forme et l'aujourd'hui, c'est passer une certification ou simplement de forme de stage, alors plus ou moins long g√©n√©ralement des stages de deux, trois √† quatre jours, puis il y a un des stages de 15 jours, mais voil√†, il n'y a pas de formule alors aujourd'hui, il n'y a pas de reconnaissance au niveau de l'Etat, de fa√ßon √† dissocier le travail du masseur et du quiner, du masseur quiner avec le praticien massage bien-√™tre, une polypique, effectivement, Tang, c'est des dissoci√©s un peu, c'est de profession, parce que je pense qu'il y a la place pour faire.\n",
      "[58.00-63.00] Unknown: C'est tr√®s curieux, c'est... √† ma fois sans le vouloir, j'ai l'impression que j'ai fait de l'humour, je lui ai...\n",
      "[63.00-64.00] SPEAKER_00: Pas le revoir.\n",
      "[64.00-65.00] Unknown: Et qu'est-ce d'un ?\n",
      "[65.00-66.00] SPEAKER_00: √Ä ma fois, je sais.\n",
      "[66.00-70.00] Unknown: Je crois que c'est cancel√© par rigolo et que √ßa ne parle pas de saucisse.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 11.0, 'end': 52.0, 'speaker': 'SPEAKER_01', 'text': \"On va l'appeler comme √ßa si, puisqu'effectivement, on n'a pas l'ode d'employer le mot Massage directement et seul puisqu'il est r√©serv√© justement √† la profession de massures qui n'est, donc un dipl√¥me d'√©tarque, on passe en trois ans. Il y a qu'une forme et l'aujourd'hui, c'est passer une certification ou simplement de forme de stage, alors plus ou moins long g√©n√©ralement des stages de deux, trois √† quatre jours, puis il y a un des stages de 15 jours, mais voil√†, il n'y a pas de formule alors aujourd'hui, il n'y a pas de reconnaissance au niveau de l'Etat, de fa√ßon √† dissocier le travail du masseur et du quiner, du masseur quiner avec le praticien massage bien-√™tre, une polypique, effectivement, Tang, c'est des dissoci√©s un peu, c'est de profession, parce que je pense qu'il y a la place pour faire.\", 'reason': 'This statement makes factual claims about the legal recognition and certification process of massage practitioners in France, including training duration and professional distinctions, which are important for understanding regulatory frameworks.', 'context': 'This was said during an interview or discussion around June 2024, likely concerning the topic of massage therapy professions and certification standards in France, explaining the legal status and training requirements of massage practitioners.', 'frame_path': 'statement_frames\\\\SPEAKER_01_001100.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\554\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\554.mp4, 2764800 bytes wanted but 0 bytes read,at frame 1753/1754, at time 73.11/73.12 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['86cd9aded4264778bb2cb16359faa6cd_clip_1.mp4'], 'pred': [0.64211505651474], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 11.0, 'end': 52.0, 'speaker': 'SPEAKER_01', 'text': \"On va l'appeler comme √ßa si, puisqu'effectivement, on n'a pas l'ode d'employer le mot Massage directement et seul puisqu'il est r√©serv√© justement √† la profession de massures qui n'est, donc un dipl√¥me d'√©tarque, on passe en trois ans. Il y a qu'une forme et l'aujourd'hui, c'est passer une certification ou simplement de forme de stage, alors plus ou moins long g√©n√©ralement des stages de deux, trois √† quatre jours, puis il y a un des stages de 15 jours, mais voil√†, il n'y a pas de formule alors aujourd'hui, il n'y a pas de reconnaissance au niveau de l'Etat, de fa√ßon √† dissocier le travail du masseur et du quiner, du masseur quiner avec le praticien massage bien-√™tre, une polypique, effectivement, Tang, c'est des dissoci√©s un peu, c'est de profession, parce que je pense qu'il y a la place pour faire.\", 'reason': 'This statement makes factual claims about the legal recognition and certification process of massage practitioners in France, including training duration and professional distinctions, which are important for understanding regulatory frameworks.', 'context': 'This was said during an interview or discussion around June 2024, likely concerning the topic of massage therapy professions and certification standards in France, explaining the legal status and training requirements of massage practitioners.', 'frame_path': 'statement_frames\\\\SPEAKER_01_001100.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.64211505651474}]\n",
      "‚ö†Ô∏è Statement On va l'appeler comme √ßa si, puisqu'effectivement, on n'a pas l'ode d'employer le mot Massage directement et seul puisqu'il est r√©serv√© justement √† la profession de massures qui n'est, donc un dipl√¥me d'√©tarque, on passe en trois ans. Il y a qu'une forme et l'aujourd'hui, c'est passer une certification ou simplement de forme de stage, alors plus ou moins long g√©n√©ralement des stages de deux, trois √† quatre jours, puis il y a un des stages de 15 jours, mais voil√†, il n'y a pas de formule alors aujourd'hui, il n'y a pas de reconnaissance au niveau de l'Etat, de fa√ßon √† dissocier le travail du masseur et du quiner, du masseur quiner avec le praticien massage bien-√™tre, une polypique, effectivement, Tang, c'est des dissoci√©s un peu, c'est de profession, parce que je pense qu'il y a la place pour faire. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\554.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 555 videos\n",
      "üìº Processing video 556: ../data/dfw_youtube_release\\555.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\555.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_02...\n",
      "‚úÖ SPEAKER_02 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-18.00] Unknown: Ah, elle est bonne ! Non, non, non, tout va bien, pistache. Papa ne laissera personne venir ta brocher. T'as nouvene d√©cour. Super la machine √† caf√©. C'est qui la sont n√¥tre ?\n",
      "[18.00-22.00] SPEAKER_02: Ah, c'est mon colocat√®re. Un colocat√®re ?\n",
      "[22.00-28.00] Unknown: Ah oui, il fallait bien payer le loyer pendant que tu te pr√©lasses √† l'h√¥pital. Comment √ßa marche, l'air ?\n",
      "[28.00-36.00] SPEAKER_02: Mais gars, super journ√©e. La meilleure va ma vie, en fait. On cocte des sucreuris qui rendent tout bizarre. Les gens viennent de l'autre c√¥t√© de la ville pour en acheter.\n",
      "[43.00-52.00] Unknown: Sus-moi sur le champ. Bonne t'abruti. √áa, c'est le retour √† l'envoyeur.\n",
      "[52.00-57.00] SPEAKER_00: Son adresse, c'est celle qui est du c√¥t√© o√π il y a le timbre.\n",
      "[59.00-63.00] Unknown: L'h√¥pital, c'est le sac. Il est bien.\n",
      "[64.00-69.00] SPEAKER_01: Il est bien. Non, non, non, non. Tout va bien, pistache.\n",
      "[69.00-76.00] SPEAKER_02: Papa ne laissera personne venir ta brocher. Comment √ßa marche, l'air ? Et ce mec concope de sucreuris qui rendent tout bizarre.\n",
      "[76.00-78.00] Unknown: Les gens viennent de l'autre.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 checkworthy statements.\n",
      "[{'start': 28.0, 'end': 36.0, 'speaker': 'SPEAKER_02', 'text': \"Mais gars, super journ√©e. La meilleure va ma vie, en fait. On cocte des sucreuris qui rendent tout bizarre. Les gens viennent de l'autre c√¥t√© de la ville pour en acheter.\", 'reason': \"Claim about a popular product ('sucreuris') that affects people and draws customers from far away; can be fact-checked for accuracy and implications.\", 'context': \"Informal conversation or private discussion, sometime during the video dated unknown, discussing a day and some product ('sucreuris'), possibly related to informal or illicit trade.\", 'frame_path': 'statement_frames\\\\SPEAKER_02_002800.jpg'}, {'start': 69.0, 'end': 76.0, 'speaker': 'SPEAKER_02', 'text': \"Papa ne laissera personne venir ta brocher. Comment √ßa marche, l'air ? Et ce mec concope de sucreuris qui rendent tout bizarre.\", 'reason': \"Claims about protection ('Papa ne laissera personne venir ta brocher') and about 'sucreuris' causing strange effects, which can be examined for meaning and truthfulness.\", 'context': \"Continuation of informal discussion, same session as previous, possibly responding to someone about a protection issue and effects of 'sucreuris', a kind of substance or product.\", 'frame_path': 'statement_frames\\\\SPEAKER_02_006900.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\555\\clip_1.mp4 from 28.00s to 36.00s\n",
      "‚úÇÔ∏è Cutting statement_clips\\555\\clip_2.mp4 from 69.00s to 76.00s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\555\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['75a0419c5411419eb0b67c75018fde29_clip_1.mp4'], 'pred': [0.6676973700523376], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['67877d8166e341dbbd5af535e5569c75_clip_2.mp4'], 'pred': [0.5161087512969971], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 28.0, 'end': 36.0, 'speaker': 'SPEAKER_02', 'text': \"Mais gars, super journ√©e. La meilleure va ma vie, en fait. On cocte des sucreuris qui rendent tout bizarre. Les gens viennent de l'autre c√¥t√© de la ville pour en acheter.\", 'reason': \"Claim about a popular product ('sucreuris') that affects people and draws customers from far away; can be fact-checked for accuracy and implications.\", 'context': \"Informal conversation or private discussion, sometime during the video dated unknown, discussing a day and some product ('sucreuris'), possibly related to informal or illicit trade.\", 'frame_path': 'statement_frames\\\\SPEAKER_02_002800.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.6676973700523376}, {'start': 69.0, 'end': 76.0, 'speaker': 'SPEAKER_02', 'text': \"Papa ne laissera personne venir ta brocher. Comment √ßa marche, l'air ? Et ce mec concope de sucreuris qui rendent tout bizarre.\", 'reason': \"Claims about protection ('Papa ne laissera personne venir ta brocher') and about 'sucreuris' causing strange effects, which can be examined for meaning and truthfulness.\", 'context': \"Continuation of informal discussion, same session as previous, possibly responding to someone about a protection issue and effects of 'sucreuris', a kind of substance or product.\", 'frame_path': 'statement_frames\\\\SPEAKER_02_006900.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5161087512969971}]\n",
      "‚ö†Ô∏è Statement Mais gars, super journ√©e. La meilleure va ma vie, en fait. On cocte des sucreuris qui rendent tout bizarre. Les gens viennent de l'autre c√¥t√© de la ville pour en acheter. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\555.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 556 videos\n",
      "üìº Processing video 557: ../data/dfw_youtube_release\\556.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\556.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí French Faker\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-27.68] Unknown: VR, en jour nous en vernis que √ßa ne m'est... La famille afin de pas te te raconter ma life r√™ve de pas l'y faire Je veux pas de calin, je suis qu'un de la son sous le string fissait Ah non mais haut, elle m'a pris pour qu'il pourrouille mais haut Non mais √† l'eau, non mais √† l'eau Je laisse traces pour transovercer En elle fait totalement p√©ter\n",
      "[28.04-33.36] French Faker: Je rentre contre dans les poches Quand petit fr√®re, pas l'√©cole Je t'en m'a plus\n",
      "[33.36-35.72] Unknown: Je t'en m'a plus Pulse\n",
      "[35.72-37.60] French Faker: Oh shiiiit, le shiiiit\n",
      "[37.60-38.60] Unknown: Le shiiiit\n",
      "[38.60-39.60] French Faker: Le shiiit\n",
      "[39.60-41.60] Unknown: Pulse Pulse\n",
      "[41.60-42.60] French Faker: Sans...\n",
      "‚ùå No checkworthy statements found.\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-27.68] Unknown: VR, en jour nous en vernis que √ßa ne m'est... La famille afin de pas te te raconter ma life r√™ve de pas l'y faire Je veux pas de calin, je suis qu'un de la son sous le string fissait Ah non mais haut, elle m'a pris pour qu'il pourrouille mais haut Non mais √† l'eau, non mais √† l'eau Je laisse traces pour transovercer En elle fait totalement p√©ter\n",
      "[28.04-33.36] French Faker: Je rentre contre dans les poches Quand petit fr√®re, pas l'√©cole Je t'en m'a plus\n",
      "[33.36-35.72] Unknown: Je t'en m'a plus Pulse\n",
      "[35.72-37.60] French Faker: Oh shiiiit, le shiiiit\n",
      "[37.60-38.60] Unknown: Le shiiiit\n",
      "[38.60-39.60] French Faker: Le shiiit\n",
      "[39.60-41.60] Unknown: Pulse Pulse\n",
      "[41.60-42.60] French Faker: Sans...\n",
      "‚úÖ Found 0 checkworthy statements.\n",
      "[]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\556\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚ùå Error 422: {\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"videos\"],\"msg\":\"Field required\",\"input\":null}]}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[]\n",
      "üì∞ Enriching statements with articles...\n",
      "‚úÖ Finished enriching statements with articles.\n",
      "üß™ Running fact-checks on statements...\n",
      "‚úÖ All statements are supported or unverified.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\556.mp4\n",
      "Deepfake label: REAL, Fact-check label: True\n",
      "üíæ Saved checkpoint after 557 videos\n",
      "üìº Processing video 558: ../data/dfw_youtube_release\\557.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\557.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-10.00] Unknown: J'aime bien ta voix, j'aime bien quand mon tu parles J'aime bien ta voix, j'aime bien quand tu m'appelles\n",
      "[10.00-14.00] SPEAKER_00: J'aime bien te voir, j'aime bien quand tu me fays time\n",
      "[14.00-24.00] Unknown: J'aime bien te voir on met J'aime bien quand tu me regardes en l'√©dien J'aime bien te contient\n",
      "‚ùå No checkworthy statements found.\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-10.00] Unknown: J'aime bien ta voix, j'aime bien quand mon tu parles J'aime bien ta voix, j'aime bien quand tu m'appelles\n",
      "[10.00-14.00] SPEAKER_00: J'aime bien te voir, j'aime bien quand tu me fays time\n",
      "[14.00-24.00] Unknown: J'aime bien te voir on met J'aime bien quand tu me regardes en l'√©dien J'aime bien te contient\n",
      "‚úÖ Found 0 checkworthy statements.\n",
      "[]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\557\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚ùå Error 422: {\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"videos\"],\"msg\":\"Field required\",\"input\":null}]}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[]\n",
      "üì∞ Enriching statements with articles...\n",
      "‚úÖ Finished enriching statements with articles.\n",
      "üß™ Running fact-checks on statements...\n",
      "‚úÖ All statements are supported or unverified.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\557.mp4\n",
      "Deepfake label: REAL, Fact-check label: True\n",
      "üíæ Saved checkpoint after 558 videos\n",
      "üìº Processing video 559: ../data/dfw_youtube_release\\558.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\558.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_02...\n",
      "‚úÖ SPEAKER_02 ‚Üí Gargamel\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-7.00] Unknown: La Wanda! Ha ha! You get it because it's a wand. So I call it La Wanda. It's very funny.\n",
      "[7.00-11.00] Gargamel: If you weren't an excruciating pain, you'd be laughing. Oh, that's right.\n",
      "[11.00-20.00] Unknown: I'm going to rule the entire world! Ha ha ha! Oh, and Papa, I want to know that as my first official\n",
      "[20.00-29.00] Gargamel: all the way from Swerve Village right here to my Swerve Lator. So you get to be with all of you on Nittles, Smurf and Fizz.\n",
      "‚úÖ Found 1 checkworthy statements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 11.0, 'end': 20.0, 'speaker': 'Unknown', 'text': \"I'm going to rule the entire world! Ha ha ha! Oh, and Papa, I want to know that as my first official\", 'reason': 'Claims the intention to rule the entire world, a bold and verifiable statement about ambition or intent.', 'context': 'This was said during a casual conversation or fictional scenario, unclear exact setting, around the beginning of the dialogue (0-29 seconds), topic related to ambition or control, not in response to a specific question.', 'frame_path': 'statement_frames\\\\Unknown_001100.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\558\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\558.mp4, 2688000 bytes wanted but 0 bytes read,at frame 1001/1002, at time 33.37/33.37 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['7cf0a2b6c33342af98be89b3e0fec281_clip_1.mp4'], 'pred': [0.5065723061561584], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 11.0, 'end': 20.0, 'speaker': 'Unknown', 'text': \"I'm going to rule the entire world! Ha ha ha! Oh, and Papa, I want to know that as my first official\", 'reason': 'Claims the intention to rule the entire world, a bold and verifiable statement about ambition or intent.', 'context': 'This was said during a casual conversation or fictional scenario, unclear exact setting, around the beginning of the dialogue (0-29 seconds), topic related to ambition or control, not in response to a specific question.', 'frame_path': 'statement_frames\\\\Unknown_001100.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5065723061561584}]\n",
      "‚ö†Ô∏è Statement I'm going to rule the entire world! Ha ha ha! Oh, and Papa, I want to know that as my first official is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\558.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 559 videos\n",
      "üìº Processing video 560: ../data/dfw_youtube_release\\559.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\559.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-3.90] Unknown: ŸáŸÜÿØÿßŸÖ ÿßŸäÿ¨ÿ™\n",
      "[3.90-10.76] SPEAKER_00: ÿßÿ≠ÿØ ŸÉplace ÿ®ÿßŸÑŸÉŸÑ Ÿäÿπÿ∑Ÿä ŸÅŸä ÿπ Philippe\n",
      "[19.36-22.56] Unknown: ÿßÿ¨ÿ±ŸàŸÖ ÿßŸÑÿ∫Ÿëÿ∫ÿ©\n",
      "[22.56-31.56] SPEAKER_00: ÿßŸáŸÑÿß ÿ®ŸÉŸÖ. ÿßŸÜÿß ÿßŸÑŸÖÿ™ÿ≠ÿØÿ´ ÿ®ÿßÿ≥ŸÖ ÿßŸÑÿ¨Ÿäÿ¥ ÿßŸÑŸÖÿ≥ÿ±Ÿä ŸÖŸÇÿ™ŸÑ ÿπÿ¥ÿ±ÿ© ŸÖŸÜ\n",
      "[31.56-61.28] SPEAKER_01: ŸÖŸÜ ÿ≥ŸÖŸáŸÖ ÿßÿ±Ÿáÿßÿ®ŸäŸÜ ŸÅŸä ÿ¥ŸÖÿßŸÑ ÿ≥ŸäŸÜÿßÿ°. ÿßÿ∂ÿßŸÅÿ© ÿßŸÑÿßÿ∑ŸÇÿßŸÑ ÿßÿ±ÿ®ÿπÿ© ŸàÿÆŸÖÿ≥ŸäŸÜ ÿßÿÆÿ±ŸäŸÜ ŸÅŸä ÿ≥ŸäŸÜÿßÿ° ŸàÿßŸÑÿßÿ≥ŸÖÿπŸÑŸä ŸàÿßŸÑÿØŸÇŸáŸÑŸä. ŸÉŸÖÿß ÿ®ÿ≥ÿ™ Ÿàÿ≤ÿßÿ±ÿ© ÿßŸÑÿØŸÅÿßÿπ ÿ™ÿ¨ŸäŸÑ ŸÖÿµŸàÿ±ÿß Ÿäÿ™ŸÅÿ± ÿπŸÖŸÑŸäÿ© ÿßŸÑÿ¨Ÿäÿ¥ ŸÅŸä ÿ≥ŸäŸÜÿßÿ°. Ÿàÿ™ÿ£ÿ™ÿÆÿ∑Ÿàÿ© ÿßŸÑÿ¨Ÿäÿ¥ ÿßŸÑŸÖÿ≥ÿ±Ÿäÿ® ÿπÿØŸâ ÿßŸÑÿ≥ÿπÿßÿ™ŸÑ ŸÖŸÜ ÿ®ÿ´Ÿä ÿ¨ŸÖÿπÿ™Ÿä ÿßŸÜÿµÿßÿ± ÿ®Ÿäÿ™ ÿßŸÑŸÖŸÇÿØÿ≥ ÿ™ÿ¨ŸäŸÑ ŸàÿµŸàÿ±ÿß ÿ™ÿ®ŸÜŸâ ŸÅŸäŸá ÿßŸÑŸáÿ¨ŸàŸÖ ÿπŸÑŸâ ŸÉŸÖŸäŸÜ ÿßŸÑŸÉÿ±ÿßŸÖ ÿßŸÑŸÇŸàÿØŸä ÿ≥ŸÑÿØŸä ÿßÿØŸâ ŸÑŸÖŸÇÿ™ŸÑŸä ÿ´ŸÑÿßÿ´ŸäŸÜ ÿ¨ŸÜÿØŸäŸäŸÜ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 checkworthy statements.\n",
      "[{'start': 22.56, 'end': 31.56, 'speaker': 'SPEAKER_00', 'text': 'ÿßŸáŸÑÿß ÿ®ŸÉŸÖ. ÿßŸÜÿß ÿßŸÑŸÖÿ™ÿ≠ÿØÿ´ ÿ®ÿßÿ≥ŸÖ ÿßŸÑÿ¨Ÿäÿ¥ ÿßŸÑŸÖÿ≥ÿ±Ÿä ŸÖŸÇÿ™ŸÑ ÿπÿ¥ÿ±ÿ© ŸÖŸÜ', 'reason': 'Claims about military casualties by the Egyptian army spokesman.', 'context': 'Statement made by an Egyptian army spokesman during a military briefing or press statement related to conflict in Sinai, likely around the period of increased insurgent activity in the 2020s.', 'frame_path': 'statement_frames\\\\SPEAKER_00_002256.jpg'}, {'start': 31.56, 'end': 61.28, 'speaker': 'SPEAKER_01', 'text': 'ŸÖŸÜ ÿ≥ŸÖŸáŸÖ ÿßÿ±Ÿáÿßÿ®ŸäŸÜ ŸÅŸä ÿ¥ŸÖÿßŸÑ ÿ≥ŸäŸÜÿßÿ°. ÿßÿ∂ÿßŸÅÿ© ÿßŸÑÿßÿ∑ŸÇÿßŸÑ ÿßÿ±ÿ®ÿπÿ© ŸàÿÆŸÖÿ≥ŸäŸÜ ÿßÿÆÿ±ŸäŸÜ ŸÅŸä ÿ≥ŸäŸÜÿßÿ° ŸàÿßŸÑÿßÿ≥ŸÖÿπŸÑŸä ŸàÿßŸÑÿØŸÇŸáŸÑŸä. ŸÉŸÖÿß ÿ®ÿ≥ÿ™ Ÿàÿ≤ÿßÿ±ÿ© ÿßŸÑÿØŸÅÿßÿπ ÿ™ÿ¨ŸäŸÑ ŸÖÿµŸàÿ±ÿß Ÿäÿ™ŸÅÿ± ÿπŸÖŸÑŸäÿ© ÿßŸÑÿ¨Ÿäÿ¥ ŸÅŸä ÿ≥ŸäŸÜÿßÿ°. Ÿàÿ™ÿ£ÿ™ÿÆÿ∑Ÿàÿ© ÿßŸÑÿ¨Ÿäÿ¥ ÿßŸÑŸÖÿ≥ÿ±Ÿäÿ® ÿπÿØŸâ ÿßŸÑÿ≥ÿπÿßÿ™ŸÑ ŸÖŸÜ ÿ®ÿ´Ÿä ÿ¨ŸÖÿπÿ™Ÿä ÿßŸÜÿµÿßÿ± ÿ®Ÿäÿ™ ÿßŸÑŸÖŸÇÿØÿ≥ ÿ™ÿ¨ŸäŸÑ ŸàÿµŸàÿ±ÿß ÿ™ÿ®ŸÜŸâ ŸÅŸäŸá ÿßŸÑŸáÿ¨ŸàŸÖ ÿπŸÑŸâ ŸÉŸÖŸäŸÜ ÿßŸÑŸÉÿ±ÿßŸÖ ÿßŸÑŸÇŸàÿØŸä ÿ≥ŸÑÿØŸä ÿßÿØŸâ ŸÑŸÖŸÇÿ™ŸÑŸä ÿ´ŸÑÿßÿ´ŸäŸÜ ÿ¨ŸÜÿØŸäŸäŸÜ.', 'reason': 'Reports casualties of insurgents and soldiers, military operations in Sinai involving Ansar Beit al-Maqdis group, and media releases by the Ministry of Defense.', 'context': \"Continuation of the Egyptian military spokesman's briefing on counter-terrorism operations in northern Sinai, discussing casualties and claims of militant attacks, presumably during mid to late 2010s or later.\", 'frame_path': 'statement_frames\\\\SPEAKER_01_003156.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\559\\clip_1.mp4 from 22.56s to 31.56s\n",
      "‚úÇÔ∏è Cutting statement_clips\\559\\clip_2.mp4 from 31.56s to 61.28s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\559\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['6153f5f74b6a4377891f702edf9fd4d6_clip_1.mp4'], 'pred': [0.5226649045944214], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['f741c0210f284fcf9632355c5c10a0fb_clip_2.mp4'], 'pred': [0.8043205142021179], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 22.56, 'end': 31.56, 'speaker': 'SPEAKER_00', 'text': 'ÿßŸáŸÑÿß ÿ®ŸÉŸÖ. ÿßŸÜÿß ÿßŸÑŸÖÿ™ÿ≠ÿØÿ´ ÿ®ÿßÿ≥ŸÖ ÿßŸÑÿ¨Ÿäÿ¥ ÿßŸÑŸÖÿ≥ÿ±Ÿä ŸÖŸÇÿ™ŸÑ ÿπÿ¥ÿ±ÿ© ŸÖŸÜ', 'reason': 'Claims about military casualties by the Egyptian army spokesman.', 'context': 'Statement made by an Egyptian army spokesman during a military briefing or press statement related to conflict in Sinai, likely around the period of increased insurgent activity in the 2020s.', 'frame_path': 'statement_frames\\\\SPEAKER_00_002256.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5226649045944214}, {'start': 31.56, 'end': 61.28, 'speaker': 'SPEAKER_01', 'text': 'ŸÖŸÜ ÿ≥ŸÖŸáŸÖ ÿßÿ±Ÿáÿßÿ®ŸäŸÜ ŸÅŸä ÿ¥ŸÖÿßŸÑ ÿ≥ŸäŸÜÿßÿ°. ÿßÿ∂ÿßŸÅÿ© ÿßŸÑÿßÿ∑ŸÇÿßŸÑ ÿßÿ±ÿ®ÿπÿ© ŸàÿÆŸÖÿ≥ŸäŸÜ ÿßÿÆÿ±ŸäŸÜ ŸÅŸä ÿ≥ŸäŸÜÿßÿ° ŸàÿßŸÑÿßÿ≥ŸÖÿπŸÑŸä ŸàÿßŸÑÿØŸÇŸáŸÑŸä. ŸÉŸÖÿß ÿ®ÿ≥ÿ™ Ÿàÿ≤ÿßÿ±ÿ© ÿßŸÑÿØŸÅÿßÿπ ÿ™ÿ¨ŸäŸÑ ŸÖÿµŸàÿ±ÿß Ÿäÿ™ŸÅÿ± ÿπŸÖŸÑŸäÿ© ÿßŸÑÿ¨Ÿäÿ¥ ŸÅŸä ÿ≥ŸäŸÜÿßÿ°. Ÿàÿ™ÿ£ÿ™ÿÆÿ∑Ÿàÿ© ÿßŸÑÿ¨Ÿäÿ¥ ÿßŸÑŸÖÿ≥ÿ±Ÿäÿ® ÿπÿØŸâ ÿßŸÑÿ≥ÿπÿßÿ™ŸÑ ŸÖŸÜ ÿ®ÿ´Ÿä ÿ¨ŸÖÿπÿ™Ÿä ÿßŸÜÿµÿßÿ± ÿ®Ÿäÿ™ ÿßŸÑŸÖŸÇÿØÿ≥ ÿ™ÿ¨ŸäŸÑ ŸàÿµŸàÿ±ÿß ÿ™ÿ®ŸÜŸâ ŸÅŸäŸá ÿßŸÑŸáÿ¨ŸàŸÖ ÿπŸÑŸâ ŸÉŸÖŸäŸÜ ÿßŸÑŸÉÿ±ÿßŸÖ ÿßŸÑŸÇŸàÿØŸä ÿ≥ŸÑÿØŸä ÿßÿØŸâ ŸÑŸÖŸÇÿ™ŸÑŸä ÿ´ŸÑÿßÿ´ŸäŸÜ ÿ¨ŸÜÿØŸäŸäŸÜ.', 'reason': 'Reports casualties of insurgents and soldiers, military operations in Sinai involving Ansar Beit al-Maqdis group, and media releases by the Ministry of Defense.', 'context': \"Continuation of the Egyptian military spokesman's briefing on counter-terrorism operations in northern Sinai, discussing casualties and claims of militant attacks, presumably during mid to late 2010s or later.\", 'frame_path': 'statement_frames\\\\SPEAKER_01_003156.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.8043205142021179}]\n",
      "‚ö†Ô∏è Statement ÿßŸáŸÑÿß ÿ®ŸÉŸÖ. ÿßŸÜÿß ÿßŸÑŸÖÿ™ÿ≠ÿØÿ´ ÿ®ÿßÿ≥ŸÖ ÿßŸÑÿ¨Ÿäÿ¥ ÿßŸÑŸÖÿ≥ÿ±Ÿä ŸÖŸÇÿ™ŸÑ ÿπÿ¥ÿ±ÿ© ŸÖŸÜ is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\559.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 560 videos\n",
      "üìº Processing video 561: ../data/dfw_youtube_release\\560.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\560.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_02...\n",
      "‚úÖ SPEAKER_02 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-4.00] Unknown: Avais-vous d√©j√† vu ? Valcani qui paie ses imp√¥ts.\n",
      "[12.00-14.00] SPEAKER_00: La restation de Balcani Montana\n",
      "[31.00-33.00] Unknown: L'h√¥pital de la France\n",
      "[39.00-43.00] SPEAKER_02: J'ai fait ma m√©chier ! C'est √† l'horreur, c'est √† l'horreur.\n",
      "[43.00-50.00] Unknown: Tu veux faire chier ? C'est √† l'horreur ! Tu veux le regard ?\n",
      "[50.00-52.00] SPEAKER_02: Je veux le lourd.\n",
      "[52.00-53.00] Unknown: Rote !\n",
      "[53.00-54.00] SPEAKER_02: Am√®ne-toi !\n",
      "[54.00-58.00] Unknown: Tu veux un go√ªt√© du cas ? Tu as √©t√© au p√©ril.\n",
      "[58.00-59.00] SPEAKER_02: Tu veux le faire ?\n",
      "[59.00-61.00] Unknown: Tu veux un coup ?\n",
      "[61.00-63.00] SPEAKER_02: Tu veux le faire ?\n",
      "[63.00-71.00] Unknown: Je veux le faire ! Je veux le faire !\n",
      "[71.00-74.00] SPEAKER_02: Tu veux le faire ?\n",
      "[74.00-76.00] Unknown: Tu veux le faire ?\n",
      "[76.00-77.00] SPEAKER_00: Maintenant oui !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 4.0, 'speaker': 'Unknown', 'text': 'Avais-vous d√©j√† vu ? Valcani qui paie ses imp√¥ts.', 'reason': 'Makes a factual claim questioning whether someone named Valcani pays taxes, implying tax evasion or non-payment.', 'context': 'Likely from a political debate or discussion in French, around the early part of a recorded session, discussing financial or political accountability related to tax payment, possibly about a public figure named Valcani.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}, {'start': 12.0, 'end': 14.0, 'speaker': 'SPEAKER_00', 'text': 'La restation de Balcani Montana', 'reason': \"Claims or mentions a location or event called 'restation de Balcani Montana' which might refer to a political or social development, needing verification.\", 'context': 'In the same French-speaking political or social discussion setting, likely referring to a place or event relevant to regional politics or infrastructure.', 'frame_path': 'statement_frames\\\\SPEAKER_00_001200.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\560\\clip_1.mp4 from 0.00s to 4.00s\n",
      "‚úÇÔ∏è Cutting statement_clips\\560\\clip_2.mp4 from 12.00s to 14.00s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\560\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['eff7b42cb36540a99532484e8a0c3abb_clip_1.mp4'], 'pred': [0.5], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['dae8e265d13447c0a8d738d2bcdc9db0_clip_2.mp4'], 'pred': [0.5], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 4.0, 'speaker': 'Unknown', 'text': 'Avais-vous d√©j√† vu ? Valcani qui paie ses imp√¥ts.', 'reason': 'Makes a factual claim questioning whether someone named Valcani pays taxes, implying tax evasion or non-payment.', 'context': 'Likely from a political debate or discussion in French, around the early part of a recorded session, discussing financial or political accountability related to tax payment, possibly about a public figure named Valcani.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5}, {'start': 12.0, 'end': 14.0, 'speaker': 'SPEAKER_00', 'text': 'La restation de Balcani Montana', 'reason': \"Claims or mentions a location or event called 'restation de Balcani Montana' which might refer to a political or social development, needing verification.\", 'context': 'In the same French-speaking political or social discussion setting, likely referring to a place or event relevant to regional politics or infrastructure.', 'frame_path': 'statement_frames\\\\SPEAKER_00_001200.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5}]\n",
      "‚ö†Ô∏è Statement Avais-vous d√©j√† vu ? Valcani qui paie ses imp√¥ts. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\560.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 561 videos\n",
      "üìº Processing video 562: ../data/dfw_youtube_release\\561.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\561.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_03...\n",
      "‚úÖ SPEAKER_03 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-31.60] Unknown: All-en s√®che la lyche ! R cortisol ? Tr√®s OP, si t'as dit ! Je n'ai pas pu sencher ! VÈõÜ, Nico, tu pourr√©es ous ? Je veux la bellicion ! Attends ! J'ai eu‚Ä¶ Die-–∫–∏–π Inter van ! Allez enceonent ! Tue n√®tes de √ßa Sy!\n",
      "[31.62-42.66] SPEAKER_03: 24 pouces il peut s'dessuser Ah-hhh ! Ah-hh!\n",
      "[42.98-89.32] Unknown: Ah-hhhh Ah-hhhh !! No ! No ! Nooo ! ... ... C'est Saluste ! C'est Saluste ! Il a voulu tuer le roi ! Arr√™tez-le ! Tenez, il est l√† !\n",
      "[89.32-96.32] SPEAKER_03: C'est pas mon √¢ge, tu es l√† ! Je suis pas mongeble ! Salut !\n",
      "[96.32-98.32] Unknown: Saluste !\n",
      "[98.32-102.32] SPEAKER_03: Non, sir, pour une fois, c'est pas moi ! J'√©tais l√†, je priais !\n",
      "[105.32-107.32] Unknown: Chosonne nocton d'angui, Vienzang,\n",
      "[107.32-116.32] SPEAKER_00: Chosonne m'injozy, Vienngochou, ... ... ... ... ... ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 checkworthy statements.\n",
      "[{'start': 42.98, 'end': 89.32, 'speaker': 'Unknown', 'text': \"Ah-hhhh Ah-hhhh !! No ! No ! Nooo ! ... ... C'est Saluste ! C'est Saluste ! Il a voulu tuer le roi ! Arr√™tez-le ! Tenez, il est l√† !\", 'reason': 'Claims an assassination attempt on the king, a significant historical or political event.', 'context': 'This appears to be a dramatic or political dialogue, possibly from a fictional or historical reenactment, around an attempted regicide conveyed during a performance or recorded speech.', 'frame_path': 'statement_frames\\\\Unknown_004298.jpg'}, {'start': 98.32, 'end': 102.32, 'speaker': 'SPEAKER_03', 'text': \"Non, sir, pour une fois, c'est pas moi ! J'√©tais l√†, je priais !\", 'reason': 'Speaker denies involvement in the assassination attempt, making a personal alibi.', 'context': 'This statement is part of a dialogue reacting to the accusation of trying to kill the king, possibly during a theatrical debate or role-play scenario relating to political intrigue or historical events.', 'frame_path': 'statement_frames\\\\SPEAKER_03_009832.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\561\\clip_1.mp4 from 42.98s to 89.32s\n",
      "‚úÇÔ∏è Cutting statement_clips\\561\\clip_2.mp4 from 98.32s to 102.32s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\561\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['2a634d1e181244469688c12ac063a24f_clip_1.mp4'], 'pred': [0.41962432861328125], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['9b4b48bdf97e4811a15315698d3a269f_clip_2.mp4'], 'pred': [0.5162826776504517], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 42.98, 'end': 89.32, 'speaker': 'Unknown', 'text': \"Ah-hhhh Ah-hhhh !! No ! No ! Nooo ! ... ... C'est Saluste ! C'est Saluste ! Il a voulu tuer le roi ! Arr√™tez-le ! Tenez, il est l√† !\", 'reason': 'Claims an assassination attempt on the king, a significant historical or political event.', 'context': 'This appears to be a dramatic or political dialogue, possibly from a fictional or historical reenactment, around an attempted regicide conveyed during a performance or recorded speech.', 'frame_path': 'statement_frames\\\\Unknown_004298.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.41962432861328125}, {'start': 98.32, 'end': 102.32, 'speaker': 'SPEAKER_03', 'text': \"Non, sir, pour une fois, c'est pas moi ! J'√©tais l√†, je priais !\", 'reason': 'Speaker denies involvement in the assassination attempt, making a personal alibi.', 'context': 'This statement is part of a dialogue reacting to the accusation of trying to kill the king, possibly during a theatrical debate or role-play scenario relating to political intrigue or historical events.', 'frame_path': 'statement_frames\\\\SPEAKER_03_009832.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5162826776504517}]\n",
      "‚ö†Ô∏è Statement Non, sir, pour une fois, c'est pas moi ! J'√©tais l√†, je priais ! is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\561.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 562 videos\n",
      "üìº Processing video 563: ../data/dfw_youtube_release\\562.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\562.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-14.78] Unknown: I You\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 14.78, 'speaker': 'Unknown', 'text': 'I You', 'reason': 'The segment is not a checkworthy statement as it lacks a factual claim or meaningful content.', 'context': 'Unknown setting; the statement appears to be incomplete or non-substantive with no clear topic or question.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\562\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\562.mp4, 672000 bytes wanted but 0 bytes read,at frame 2107/2109, at time 70.23/70.29 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n",
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\562.mp4, 672000 bytes wanted but 0 bytes read,at frame 2108/2109, at time 70.27/70.29 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['a276c1d28389481aa7f1962a65f1e39e_clip_1.mp4'], 'pred': [0.531938374042511], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 14.78, 'speaker': 'Unknown', 'text': 'I You', 'reason': 'The segment is not a checkworthy statement as it lacks a factual claim or meaningful content.', 'context': 'Unknown setting; the statement appears to be incomplete or non-substantive with no clear topic or question.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.531938374042511}]\n",
      "‚ö†Ô∏è Statement I You is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\562.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 563 videos\n",
      "üìº Processing video 564: ../data/dfw_youtube_release\\563.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\563.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-7.00] Unknown: Mais si cela m'est en gagn√©, je m'adapte ma dame, je mets le voile avant de mettre les voiles.\n",
      "[7.00-10.00] SPEAKER_01: Je vous remercie dans ce moment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 7.0, 'speaker': 'Unknown', 'text': \"Mais si cela m'est en gagn√©, je m'adapte ma dame, je mets le voile avant de mettre les voiles.\", 'reason': 'The speaker claims they would adapt by wearing the veil in certain conditions, implying a political or cultural statement regarding the veil, which can be linked to laws or societal norms about wearing the veil.', 'context': 'The quote was made in a short exchange, likely a political debate or discussion in French, possibly touching on topics of cultural adaptation or religious expression, during a recent political event or discussion.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\563\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\563.mp4, 2764800 bytes wanted but 0 bytes read,at frame 383/384, at time 12.77/12.77 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['48ea8177da564d67a4813d0b95c6649e_clip_1.mp4'], 'pred': [0.7056555151939392], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 7.0, 'speaker': 'Unknown', 'text': \"Mais si cela m'est en gagn√©, je m'adapte ma dame, je mets le voile avant de mettre les voiles.\", 'reason': 'The speaker claims they would adapt by wearing the veil in certain conditions, implying a political or cultural statement regarding the veil, which can be linked to laws or societal norms about wearing the veil.', 'context': 'The quote was made in a short exchange, likely a political debate or discussion in French, possibly touching on topics of cultural adaptation or religious expression, during a recent political event or discussion.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.7056555151939392}]\n",
      "‚ö†Ô∏è Statement Mais si cela m'est en gagn√©, je m'adapte ma dame, je mets le voile avant de mettre les voiles. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\563.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 564 videos\n",
      "üìº Processing video 565: ../data/dfw_youtube_release\\564.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\564.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-31.50] Unknown: Is Donald J. Trump and Awid Al Trion for really the same person? That is what we are gonna check today. The Speech Everything started in 2017 in Qatar. When a lookalike of Donald J. Trump made a polemical speech on Al Jazeera.\n",
      "[32.50-35.50] SPEAKER_02: Here is the extract of the video, please let me know your thoughts.\n",
      "[41.50-54.50] SPEAKER_00: Salafi'ian or Qwan or Sufian, any of them were allowed to come. These measures are not available on the land of the country, the idea and ideas. Maybe you are wondering what about the hair, which is a fair question.\n",
      "[73.50-76.50] Unknown: As you can see here the hair of black and not orange.\n",
      "[76.50-91.50] SPEAKER_02: And it is just because Donald Trump is bald as a ball sack. There is even an article about that on New York Times. So he was just wearing a black wig. Are you convinced now my friend? If you are not here as the second reason why Trump and Trump are the same person.\n",
      "[94.50-103.50] Unknown: The Hidden Video To find this clue I had to watch 200 hours of Donald Trump's speeches framed by frame.\n",
      "[103.50-123.50] SPEAKER_02: My guts told me that there were something off and I was right. In one frame I have found an odd writing. It was written BP1jlabk14, which after investigation is the YouTube address of a hidden video, named Dawid Al-Trayunfa. You can see it here. And we can also see that it was uploaded by someone named GL Morocco.\n",
      "[124.50-126.50] Unknown: Which appears to be the Moroccan Freemasonry.\n",
      "[126.50-131.50] SPEAKER_02: Is Donald Trump a triple agent? Or is it a blackmail video? You decide.\n",
      "[134.50-136.50] Unknown: A terrorist?\n",
      "[136.50-138.50] SPEAKER_04: And you're not?\n",
      "[138.50-139.50] Unknown: No I'm not.\n",
      "[139.50-149.50] SPEAKER_04: I want a lawyer. Bismillahirrahmanirrahim. Alhamdulillahirrahim. Alhamdulillahirrahim.\n",
      "[149.50-156.50] Unknown: Alhamdulillahirrahim. My theory about this video is pretty simple.\n",
      "[156.50-171.50] SPEAKER_02: In Trunfia there are the same letters as Iran and I don't believe in coincidences. I believe that Trunfia is in fact a triple agent for Iran and help the economic relationship between Iran and Qatar, while being the president of the United States.\n",
      "[171.50-179.50] Unknown: During the UAE crisis with Qatar, Trunfia helped a lot Qatar economy by creating an embargo for Iran from the USA.\n",
      "[179.50-190.50] SPEAKER_02: The Iran is the only choice to do business with Qatar because the other countries was forbidden to deal with Iran. But if you need another proof to be convinced I have another one for you.\n",
      "[192.50-207.50] Unknown: Weird call at Fox News. This segment has been deleted since, but one of my hacker friends succeeded to hack it from Fox News. Enjoy. It's just beautiful to honor our troops.\n",
      "[207.50-218.50] SPEAKER_01: Today's flag day, it's the birthday for the Army. It is your birthday today and you are painting Air Force One, Red, White and Blue. Thank you so much for joining us, Mr. President. Happy birthday.\n",
      "[218.50-231.50] Unknown: Thank you and just to let you guys know you have to pray five times a day or you are going to hell. Five times a day equals of course to Islam, just to be sure I have made a little voice comparison between Trump's voice Trunfias.\n",
      "[231.50-241.50] SPEAKER_02: Thank you and just to let you guys know you have to pray five times a day or... And without any surprise the voice match is perfect. I am now sure that Trunfia and Trump are the same person.\n",
      "[241.50-247.50] Unknown: But you, do you believe it? If you did you or Amoran.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 checkworthy statements.\n",
      "[{'start': 156.5, 'end': 171.5, 'speaker': 'SPEAKER_02', 'text': \"In Trunfia there are the same letters as Iran and I don't believe in coincidences. I believe that Trunfia is in fact a triple agent for Iran and help the economic relationship between Iran and Qatar, while being the president of the United States.\", 'reason': \"Claims that 'Trunfia' is a triple agent for Iran helping economic relations between Iran and Qatar while also being US president, a bold and controversial political assertion.\", 'context': \"Discussion in a video analyzing suspicious claims about a person named 'Trunfia' being linked to Donald Trump and alleged covert actions, during a speculative internet video in 2020s discussing foreign espionage and politics.\", 'frame_path': 'statement_frames\\\\SPEAKER_02_015650.jpg'}, {'start': 179.5, 'end': 190.5, 'speaker': 'SPEAKER_02', 'text': 'The Iran is the only choice to do business with Qatar because the other countries was forbidden to deal with Iran. But if you need another proof to be convinced I have another one for you.', 'reason': 'Claims that only Iran could do business with Qatar due to embargoes, insinuating geopolitical restrictions relevant to Middle East economic sanctions.', 'context': 'Same speculative video discussing political-economic relations involving Iran and Qatar during a Middle Eastern regional diplomatic crisis period.', 'frame_path': 'statement_frames\\\\SPEAKER_02_017950.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\564\\clip_1.mp4 from 156.50s to 171.50s\n",
      "‚úÇÔ∏è Cutting statement_clips\\564\\clip_2.mp4 from 179.50s to 190.50s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\564\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['64b454b4986648618e0dfb3b4fee23d1_clip_1.mp4'], 'pred': [0.5], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['f9abf4375b04467bb3469d279b433364_clip_2.mp4'], 'pred': [0.5], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 156.5, 'end': 171.5, 'speaker': 'SPEAKER_02', 'text': \"In Trunfia there are the same letters as Iran and I don't believe in coincidences. I believe that Trunfia is in fact a triple agent for Iran and help the economic relationship between Iran and Qatar, while being the president of the United States.\", 'reason': \"Claims that 'Trunfia' is a triple agent for Iran helping economic relations between Iran and Qatar while also being US president, a bold and controversial political assertion.\", 'context': \"Discussion in a video analyzing suspicious claims about a person named 'Trunfia' being linked to Donald Trump and alleged covert actions, during a speculative internet video in 2020s discussing foreign espionage and politics.\", 'frame_path': 'statement_frames\\\\SPEAKER_02_015650.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5}, {'start': 179.5, 'end': 190.5, 'speaker': 'SPEAKER_02', 'text': 'The Iran is the only choice to do business with Qatar because the other countries was forbidden to deal with Iran. But if you need another proof to be convinced I have another one for you.', 'reason': 'Claims that only Iran could do business with Qatar due to embargoes, insinuating geopolitical restrictions relevant to Middle East economic sanctions.', 'context': 'Same speculative video discussing political-economic relations involving Iran and Qatar during a Middle Eastern regional diplomatic crisis period.', 'frame_path': 'statement_frames\\\\SPEAKER_02_017950.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5}]\n",
      "‚ö†Ô∏è Statement In Trunfia there are the same letters as Iran and I don't believe in coincidences. I believe that Trunfia is in fact a triple agent for Iran and help the economic relationship between Iran and Qatar, while being the president of the United States. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\564.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 565 videos\n",
      "üìº Processing video 566: ../data/dfw_youtube_release\\565.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\565.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-46.16] Unknown: Ha ha ha ha ! Fou ! Fou ! Fou ! Fou ! Et mes jolis petits t√©tons ont fait une tour de France. Le chacha et je danse le chacha comme une fillette de quatre ans. Vous voyez m'excusez ? Euh ... Oh ...\n",
      "[46.16-51.26] SPEAKER_00: Next Making r√≥i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 46.16, 'end': 51.26, 'speaker': 'SPEAKER_00', 'text': 'Next Making r√≥i', 'reason': 'Contains a fragment of a statement that may relate to future actions or claims; however, it is incomplete and unclear.', 'context': 'This short segment is from an unknown video or event, likely a meeting or discussion, during which SPEAKER_00 speaks briefly. The context and topic are unclear.', 'frame_path': 'statement_frames\\\\SPEAKER_00_004616.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\565\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\565.mp4, 2688000 bytes wanted but 0 bytes read,at frame 1856/1857, at time 61.87/61.88 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['38aafe0bbe7243f6b60091cf28bc1db6_clip_1.mp4'], 'pred': [0.43581312894821167], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 46.16, 'end': 51.26, 'speaker': 'SPEAKER_00', 'text': 'Next Making r√≥i', 'reason': 'Contains a fragment of a statement that may relate to future actions or claims; however, it is incomplete and unclear.', 'context': 'This short segment is from an unknown video or event, likely a meeting or discussion, during which SPEAKER_00 speaks briefly. The context and topic are unclear.', 'frame_path': 'statement_frames\\\\SPEAKER_00_004616.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.43581312894821167}]\n",
      "üì∞ Enriching statements with articles...\n",
      "https://www.bing.com/search?q=Next Making r√≥i\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"6c59a021b68be94600716124cf10e432\", element=\"f.02C51EE559B8F91556F700E16C1E0976.d.E5CA57ABC5364C224306285DAED424BE.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"6c59a021b68be94600716124cf10e432\", element=\"f.02C51EE559B8F91556F700E16C1E0976.d.E5CA57ABC5364C224306285DAED424BE.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"6c59a021b68be94600716124cf10e432\", element=\"f.02C51EE559B8F91556F700E16C1E0976.d.E5CA57ABC5364C224306285DAED424BE.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"6c59a021b68be94600716124cf10e432\", element=\"f.02C51EE559B8F91556F700E16C1E0976.d.E5CA57ABC5364C224306285DAED424BE.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"6c59a021b68be94600716124cf10e432\", element=\"f.02C51EE559B8F91556F700E16C1E0976.d.E5CA57ABC5364C224306285DAED424BE.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"6c59a021b68be94600716124cf10e432\", element=\"f.02C51EE559B8F91556F700E16C1E0976.d.E5CA57ABC5364C224306285DAED424BE.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"6c59a021b68be94600716124cf10e432\", element=\"f.02C51EE559B8F91556F700E16C1E0976.d.E5CA57ABC5364C224306285DAED424BE.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"6c59a021b68be94600716124cf10e432\", element=\"f.02C51EE559B8F91556F700E16C1E0976.d.E5CA57ABC5364C224306285DAED424BE.e.27\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"6c59a021b68be94600716124cf10e432\", element=\"f.02C51EE559B8F91556F700E16C1E0976.d.E5CA57ABC5364C224306285DAED424BE.e.28\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"6c59a021b68be94600716124cf10e432\", element=\"f.02C51EE559B8F91556F700E16C1E0976.d.E5CA57ABC5364C224306285DAED424BE.e.29\")>]\n",
      "K·ªπ thu·∫≠t nu√¥i, nh√¢n gi·ªëng c√° r√≥i l·ª£i nhu·∫≠n kh·ªßng gi√∫p ‚Ä¶\n",
      "https://thuvien.mard.gov.vn/tin-tuc/diem-bao/ky-thuat-nuoi-nhan-giong-ca-roi-loi-nhuan-khung-giup-nguoi-nong-dan-doi-doi--2354/\n",
      "Google D·ªãch\n",
      "https://translate.google.com.vn/\n",
      "Found 3 relevant links:\n",
      "[{'title': 'Next Making r√≥i', 'link': 'https://www.bing.com/search?q=Next Making r√≥i'}, {'title': 'K·ªπ thu·∫≠t nu√¥i, nh√¢n gi·ªëng c√° r√≥i l·ª£i nhu·∫≠n kh·ªßng gi√∫p ‚Ä¶', 'link': 'https://thuvien.mard.gov.vn/tin-tuc/diem-bao/ky-thuat-nuoi-nhan-giong-ca-roi-loi-nhuan-khung-giup-nguoi-nong-dan-doi-doi--2354/'}, {'title': 'Google D·ªãch', 'link': 'https://translate.google.com.vn/'}]\n",
      "‚è≥ Attempt 1: Crawling https://thuvien.mard.gov.vn/tin-tuc/diem-bao/ky-thuat-nuoi-nhan-giong-ca-roi-loi-nhuan-khung-giup-nguoi-nong-dan-doi-doi--2354/ with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=Next Making r√≥i with wait_time=10s\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=Next Making r√≥i:\n",
      "Nov 30, 2018¬†¬∑ H∆∞·ªõng d·∫´n l√†m r·ªëi ng√≥n tay | C√°ch l√†m r·ªëi tay k·ªÉ chuy·ªán | DIY finger puppetsB√© nh√† b·∫°n s·∫Ω th√≠ch m√™ v·ªõi nh·ªØng con r·ªëi ng√≥n tay s·∫∑c s·ª° v√† ƒë√°ng y√™u theo l·ªùi k·ªÉ ...\n",
      "R·ªèi N·ªëi T·ª´ l√† m·ªôt tr√≤ ch∆°i tr√≠ tu·ªá ph·ªï bi·∫øn ·ªü Vi·ªát Nam, ƒë·∫∑c bi·ªát l√† trong c√°c ho·∫°t ƒë·ªông gi·∫£i tr√≠ gia ƒë√¨nh v√† gi√°o d·ª•c. Tr√≤ ch∆°i n√†y kh√¥ng ch·ªâ gi√∫p ng∆∞·ªùi ch∆°i m·ªü r·ªông v·ªën t·ª´ v·ª±ng m√† c√≤n ph√°t tri·ªÉn k·ªπ nƒÉng t∆∞ duy ng√¥n ng·ªØ v√† kh·∫£ nƒÉng ‚Ä¶\n",
      "We are Chinloo and Sal üë©üèª‚Äçü§ù‚Äçüßëüèº, partners in life, two engineers, and both high-tech artisa...\n",
      "‚ö†Ô∏è Attempt 1 failed for https://thuvien.mard.gov.vn/tin-tuc/diem-bao/ky-thuat-nuoi-nhan-giong-ca-roi-loi-nhuan-khung-giup-nguoi-nong-dan-doi-doi--2354/: Message: unknown error: net::ERR_CONNECTION_TIMED_OUT\n",
      "  (Session info: chrome=138.0.7204.158)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xef1a33+62339]\n",
      "\tGetHandleVerifier [0x0xef1a74+62404]\n",
      "\t(No symbol) [0x0xd32123]\n",
      "\t(No symbol) [0x0xd2f85b]\n",
      "\t(No symbol) [0x0xd230d2]\n",
      "\t(No symbol) [0x0xd24b05]\n",
      "\t(No symbol) [0x0xd23368]\n",
      "\t(No symbol) [0x0xd22ea3]\n",
      "\t(No symbol) [0x0xd22bb1]\n",
      "\t(No symbol) [0x0xd20b54]\n",
      "\t(No symbol) [0x0xd214fb]\n",
      "\t(No symbol) [0x0xd35b4e]\n",
      "\t(No symbol) [0x0xdc1367]\n",
      "\t(No symbol) [0x0xd9f3bc]\n",
      "\t(No symbol) [0x0xdc07a3]\n",
      "\t(No symbol) [0x0xd9f1b6]\n",
      "\t(No symbol) [0x0xd6e7a2]\n",
      "\t(No symbol) [0x0xd6f644]\n",
      "\tGetHandleVerifier [0x0x11665c3+2637587]\n",
      "\tGetHandleVerifier [0x0x11619ca+2618138]\n",
      "\tGetHandleVerifier [0x0xf184aa+220666]\n",
      "\tGetHandleVerifier [0x0xf088d8+156200]\n",
      "\tGetHandleVerifier [0x0xf0f06d+182717]\n",
      "\tGetHandleVerifier [0x0xef9978+94920]\n",
      "\tGetHandleVerifier [0x0xef9b02+95314]\n",
      "\tGetHandleVerifier [0x0xee4c4a+9626]\n",
      "\tBaseThreadInitThunk [0x0x758e7ba9+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7733c3ab+107]\n",
      "\tRtlClearBits [0x0x7733c32f+191]\n",
      "\n",
      "‚è≥ Attempt 2: Crawling https://thuvien.mard.gov.vn/tin-tuc/diem-bao/ky-thuat-nuoi-nhan-giong-ca-roi-loi-nhuan-khung-giup-nguoi-nong-dan-doi-doi--2354/ with wait_time=310s\n",
      "‚ö†Ô∏è Attempt 2 failed for https://thuvien.mard.gov.vn/tin-tuc/diem-bao/ky-thuat-nuoi-nhan-giong-ca-roi-loi-nhuan-khung-giup-nguoi-nong-dan-doi-doi--2354/: Message: unknown error: net::ERR_CONNECTION_TIMED_OUT\n",
      "  (Session info: chrome=138.0.7204.158)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xef1a33+62339]\n",
      "\tGetHandleVerifier [0x0xef1a74+62404]\n",
      "\t(No symbol) [0x0xd32123]\n",
      "\t(No symbol) [0x0xd2f85b]\n",
      "\t(No symbol) [0x0xd230d2]\n",
      "\t(No symbol) [0x0xd24b05]\n",
      "\t(No symbol) [0x0xd23368]\n",
      "\t(No symbol) [0x0xd22ea3]\n",
      "\t(No symbol) [0x0xd22bb1]\n",
      "\t(No symbol) [0x0xd20b54]\n",
      "\t(No symbol) [0x0xd214fb]\n",
      "\t(No symbol) [0x0xd35b4e]\n",
      "\t(No symbol) [0x0xdc1367]\n",
      "\t(No symbol) [0x0xd9f3bc]\n",
      "\t(No symbol) [0x0xdc07a3]\n",
      "\t(No symbol) [0x0xd9f1b6]\n",
      "\t(No symbol) [0x0xd6e7a2]\n",
      "\t(No symbol) [0x0xd6f644]\n",
      "\tGetHandleVerifier [0x0x11665c3+2637587]\n",
      "\tGetHandleVerifier [0x0x11619ca+2618138]\n",
      "\tGetHandleVerifier [0x0xf184aa+220666]\n",
      "\tGetHandleVerifier [0x0xf088d8+156200]\n",
      "\tGetHandleVerifier [0x0xf0f06d+182717]\n",
      "\tGetHandleVerifier [0x0xef9978+94920]\n",
      "\tGetHandleVerifier [0x0xef9b02+95314]\n",
      "\tGetHandleVerifier [0x0xee4c4a+9626]\n",
      "\tBaseThreadInitThunk [0x0x758e7ba9+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7733c3ab+107]\n",
      "\tRtlClearBits [0x0x7733c32f+191]\n",
      "\n",
      "‚è≥ Attempt 3: Crawling https://thuvien.mard.gov.vn/tin-tuc/diem-bao/ky-thuat-nuoi-nhan-giong-ca-roi-loi-nhuan-khung-giup-nguoi-nong-dan-doi-doi--2354/ with wait_time=610s\n",
      "‚ö†Ô∏è Attempt 3 failed for https://thuvien.mard.gov.vn/tin-tuc/diem-bao/ky-thuat-nuoi-nhan-giong-ca-roi-loi-nhuan-khung-giup-nguoi-nong-dan-doi-doi--2354/: Message: unknown error: net::ERR_CONNECTION_TIMED_OUT\n",
      "  (Session info: chrome=138.0.7204.158)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xef1a33+62339]\n",
      "\tGetHandleVerifier [0x0xef1a74+62404]\n",
      "\t(No symbol) [0x0xd32123]\n",
      "\t(No symbol) [0x0xd2f85b]\n",
      "\t(No symbol) [0x0xd230d2]\n",
      "\t(No symbol) [0x0xd24b05]\n",
      "\t(No symbol) [0x0xd23368]\n",
      "\t(No symbol) [0x0xd22ea3]\n",
      "\t(No symbol) [0x0xd22bb1]\n",
      "\t(No symbol) [0x0xd20b54]\n",
      "\t(No symbol) [0x0xd214fb]\n",
      "\t(No symbol) [0x0xd35b4e]\n",
      "\t(No symbol) [0x0xdc1367]\n",
      "\t(No symbol) [0x0xd9f3bc]\n",
      "\t(No symbol) [0x0xdc07a3]\n",
      "\t(No symbol) [0x0xd9f1b6]\n",
      "\t(No symbol) [0x0xd6e7a2]\n",
      "\t(No symbol) [0x0xd6f644]\n",
      "\tGetHandleVerifier [0x0x11665c3+2637587]\n",
      "\tGetHandleVerifier [0x0x11619ca+2618138]\n",
      "\tGetHandleVerifier [0x0xf184aa+220666]\n",
      "\tGetHandleVerifier [0x0xf088d8+156200]\n",
      "\tGetHandleVerifier [0x0xf0f06d+182717]\n",
      "\tGetHandleVerifier [0x0xef9978+94920]\n",
      "\tGetHandleVerifier [0x0xef9b02+95314]\n",
      "\tGetHandleVerifier [0x0xee4c4a+9626]\n",
      "\tBaseThreadInitThunk [0x0x758e7ba9+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7733c3ab+107]\n",
      "\tRtlClearBits [0x0x7733c32f+191]\n",
      "\n",
      "‚è≥ Attempt 4: Crawling https://thuvien.mard.gov.vn/tin-tuc/diem-bao/ky-thuat-nuoi-nhan-giong-ca-roi-loi-nhuan-khung-giup-nguoi-nong-dan-doi-doi--2354/ with wait_time=910s\n",
      "‚ö†Ô∏è Attempt 4 failed for https://thuvien.mard.gov.vn/tin-tuc/diem-bao/ky-thuat-nuoi-nhan-giong-ca-roi-loi-nhuan-khung-giup-nguoi-nong-dan-doi-doi--2354/: Message: unknown error: net::ERR_CONNECTION_TIMED_OUT\n",
      "  (Session info: chrome=138.0.7204.158)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xef1a33+62339]\n",
      "\tGetHandleVerifier [0x0xef1a74+62404]\n",
      "\t(No symbol) [0x0xd32123]\n",
      "\t(No symbol) [0x0xd2f85b]\n",
      "\t(No symbol) [0x0xd230d2]\n",
      "\t(No symbol) [0x0xd24b05]\n",
      "\t(No symbol) [0x0xd23368]\n",
      "\t(No symbol) [0x0xd22ea3]\n",
      "\t(No symbol) [0x0xd22bb1]\n",
      "\t(No symbol) [0x0xd20b54]\n",
      "\t(No symbol) [0x0xd214fb]\n",
      "\t(No symbol) [0x0xd35b4e]\n",
      "\t(No symbol) [0x0xdc1367]\n",
      "\t(No symbol) [0x0xd9f3bc]\n",
      "\t(No symbol) [0x0xdc07a3]\n",
      "\t(No symbol) [0x0xd9f1b6]\n",
      "\t(No symbol) [0x0xd6e7a2]\n",
      "\t(No symbol) [0x0xd6f644]\n",
      "\tGetHandleVerifier [0x0x11665c3+2637587]\n",
      "\tGetHandleVerifier [0x0x11619ca+2618138]\n",
      "\tGetHandleVerifier [0x0xf184aa+220666]\n",
      "\tGetHandleVerifier [0x0xf088d8+156200]\n",
      "\tGetHandleVerifier [0x0xf0f06d+182717]\n",
      "\tGetHandleVerifier [0x0xef9978+94920]\n",
      "\tGetHandleVerifier [0x0xef9b02+95314]\n",
      "\tGetHandleVerifier [0x0xee4c4a+9626]\n",
      "\tBaseThreadInitThunk [0x0x758e7ba9+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7733c3ab+107]\n",
      "\tRtlClearBits [0x0x7733c32f+191]\n",
      "\n",
      "‚è≥ Attempt 5: Crawling https://thuvien.mard.gov.vn/tin-tuc/diem-bao/ky-thuat-nuoi-nhan-giong-ca-roi-loi-nhuan-khung-giup-nguoi-nong-dan-doi-doi--2354/ with wait_time=1210s\n",
      "‚ö†Ô∏è Attempt 5 failed for https://thuvien.mard.gov.vn/tin-tuc/diem-bao/ky-thuat-nuoi-nhan-giong-ca-roi-loi-nhuan-khung-giup-nguoi-nong-dan-doi-doi--2354/: Message: unknown error: net::ERR_CONNECTION_TIMED_OUT\n",
      "  (Session info: chrome=138.0.7204.158)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xef1a33+62339]\n",
      "\tGetHandleVerifier [0x0xef1a74+62404]\n",
      "\t(No symbol) [0x0xd32123]\n",
      "\t(No symbol) [0x0xd2f85b]\n",
      "\t(No symbol) [0x0xd230d2]\n",
      "\t(No symbol) [0x0xd24b05]\n",
      "\t(No symbol) [0x0xd23368]\n",
      "\t(No symbol) [0x0xd22ea3]\n",
      "\t(No symbol) [0x0xd22bb1]\n",
      "\t(No symbol) [0x0xd20b54]\n",
      "\t(No symbol) [0x0xd214fb]\n",
      "\t(No symbol) [0x0xd35b4e]\n",
      "\t(No symbol) [0x0xdc1367]\n",
      "\t(No symbol) [0x0xd9f3bc]\n",
      "\t(No symbol) [0x0xdc07a3]\n",
      "\t(No symbol) [0x0xd9f1b6]\n",
      "\t(No symbol) [0x0xd6e7a2]\n",
      "\t(No symbol) [0x0xd6f644]\n",
      "\tGetHandleVerifier [0x0x11665c3+2637587]\n",
      "\tGetHandleVerifier [0x0x11619ca+2618138]\n",
      "\tGetHandleVerifier [0x0xf184aa+220666]\n",
      "\tGetHandleVerifier [0x0xf088d8+156200]\n",
      "\tGetHandleVerifier [0x0xf0f06d+182717]\n",
      "\tGetHandleVerifier [0x0xef9978+94920]\n",
      "\tGetHandleVerifier [0x0xef9b02+95314]\n",
      "\tGetHandleVerifier [0x0xee4c4a+9626]\n",
      "\tBaseThreadInitThunk [0x0x758e7ba9+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7733c3ab+107]\n",
      "\tRtlClearBits [0x0x7733c32f+191]\n",
      "\n",
      "‚ùå Failed to crawl article from https://thuvien.mard.gov.vn/tin-tuc/diem-bao/ky-thuat-nuoi-nhan-giong-ca-roi-loi-nhuan-khung-giup-nguoi-nong-dan-doi-doi--2354/ after 5 attempts.\n",
      "https://www.bing.com/search?q=This short segment is from an unknown video or event, likely a meeting or discussion, during which SPEAKER_00 speaks briefly. The context and topic are unclear.\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"491c2481941297144aee725de9a191cf\", element=\"f.CB7F1EF122B012E83A41CDB4A3E08B06.d.FB109960F8904CA905EB59A0E5EAFE5C.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"491c2481941297144aee725de9a191cf\", element=\"f.CB7F1EF122B012E83A41CDB4A3E08B06.d.FB109960F8904CA905EB59A0E5EAFE5C.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"491c2481941297144aee725de9a191cf\", element=\"f.CB7F1EF122B012E83A41CDB4A3E08B06.d.FB109960F8904CA905EB59A0E5EAFE5C.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"491c2481941297144aee725de9a191cf\", element=\"f.CB7F1EF122B012E83A41CDB4A3E08B06.d.FB109960F8904CA905EB59A0E5EAFE5C.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"491c2481941297144aee725de9a191cf\", element=\"f.CB7F1EF122B012E83A41CDB4A3E08B06.d.FB109960F8904CA905EB59A0E5EAFE5C.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"491c2481941297144aee725de9a191cf\", element=\"f.CB7F1EF122B012E83A41CDB4A3E08B06.d.FB109960F8904CA905EB59A0E5EAFE5C.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"491c2481941297144aee725de9a191cf\", element=\"f.CB7F1EF122B012E83A41CDB4A3E08B06.d.FB109960F8904CA905EB59A0E5EAFE5C.e.27\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"491c2481941297144aee725de9a191cf\", element=\"f.CB7F1EF122B012E83A41CDB4A3E08B06.d.FB109960F8904CA905EB59A0E5EAFE5C.e.28\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"491c2481941297144aee725de9a191cf\", element=\"f.CB7F1EF122B012E83A41CDB4A3E08B06.d.FB109960F8904CA905EB59A0E5EAFE5C.e.29\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"491c2481941297144aee725de9a191cf\", element=\"f.CB7F1EF122B012E83A41CDB4A3E08B06.d.FB109960F8904CA905EB59A0E5EAFE5C.e.30\")>]\n",
      "Journalism - FBLA Flashcards | Quizlet\n",
      "https://quizlet.com/902467476/journalism-fbla-flash-cards/\n",
      "[Solved] Please help me select a videothat discusses ‚Ä¶\n",
      "https://www.studocu.com/en-us/messages/question/10781967/please-help-me-select-a-video-that-discusses-a-recent-event-or-issue-the-video-should-be-from-a\n",
      "Found 3 relevant links:\n",
      "[{'title': 'This short segment is from an ', 'link': 'https://www.bing.com/search?q=This short segment is from an unknown video or event, likely a meeting or discussion, during which SPEAKER_00 speaks briefly. The context and topic are unclear.'}, {'title': 'Journalism - FBLA Flashcards | Quizlet', 'link': 'https://quizlet.com/902467476/journalism-fbla-flash-cards/'}, {'title': '[Solved] Please help me select a videothat discusses ‚Ä¶', 'link': 'https://www.studocu.com/en-us/messages/question/10781967/please-help-me-select-a-video-that-discusses-a-recent-event-or-issue-the-video-should-be-from-a'}]\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=This short segment is from an unknown video or event, likely a meeting or discussion, during which SPEAKER_00 speaks briefly. The context and topic are unclear. with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://quizlet.com/902467476/journalism-fbla-flash-cards/ with wait_time=10s\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=This short segment is from an unknown video or event, likely a meeting or discussion, during which SPEAKER_00 speaks briefly. The context and topic are unclear.:\n",
      "A short audio or video segment produced to advertise an upcoming news bulletin or news items is called a (n): teaser. News as a product has two important economic features. One feature is ‚Ä¶\n",
      "A media clip is a short segment of audio or video content that is either intended for release to the media or is made out of some pre-existing media. Clips are generally short, often no more ‚Ä¶\n",
      "Oct 4, 2021¬†¬∑ Are short clips of video or movie, usually part of a longer recording a trailer b. news flash c. short ...\n",
      "‚úÖ Crawled content from https://quizlet.com/902467476/journalism-fbla-flash-cards/:\n",
      "¬© 2025 Quizlet, Inc....\n",
      "‚úÖ Finished enriching statements with articles.\n",
      "üß™ Running fact-checks on statements...\n",
      "{'start': 46.16, 'end': 51.26, 'speaker': 'SPEAKER_00', 'text': 'Next Making r√≥i', 'reason': 'Contains a fragment of a statement that may relate to future actions or claims; however, it is incomplete and unclear.', 'context': 'This short segment is from an unknown video or event, likely a meeting or discussion, during which SPEAKER_00 speaks briefly. The context and topic are unclear.', 'frame_path': 'statement_frames\\\\SPEAKER_00_004616.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.43581312894821167, 'article_texts': '### Next Making r√≥i\\nNov 30, 2018\\xa0¬∑ H∆∞·ªõng d·∫´n l√†m r·ªëi ng√≥n tay | C√°ch l√†m r·ªëi tay k·ªÉ chuy·ªán | DIY finger puppetsB√© nh√† b·∫°n s·∫Ω th√≠ch m√™ v·ªõi nh·ªØng con r·ªëi ng√≥n tay s·∫∑c s·ª° v√† ƒë√°ng y√™u theo l·ªùi k·ªÉ ...\\nR·ªèi N·ªëi T·ª´ l√† m·ªôt tr√≤ ch∆°i tr√≠ tu·ªá ph·ªï bi·∫øn ·ªü Vi·ªát Nam, ƒë·∫∑c bi·ªát l√† trong c√°c ho·∫°t ƒë·ªông gi·∫£i tr√≠ gia ƒë√¨nh v√† gi√°o d·ª•c. Tr√≤ ch∆°i n√†y kh√¥ng ch·ªâ gi√∫p ng∆∞·ªùi ch∆°i m·ªü r·ªông v·ªën t·ª´ v·ª±ng m√† c√≤n ph√°t tri·ªÉn k·ªπ nƒÉng t∆∞ duy ng√¥n ng·ªØ v√† kh·∫£ nƒÉng ‚Ä¶\\nWe are Chinloo and Sal üë©üèª\\u200dü§ù\\u200düßëüèº, partners in life, two engineers, and both high-tech artisans. We have a passion for problem solving and making things with our hands, and hope to share our skills ‚Ä¶\\nTr√≤ ch∆°i n·ªëi t·ª´ l√† m·ªôt h√¨nh th·ª©c gi·∫£i tr√≠ v·ª´a vui nh·ªôn v·ª´a mang t√≠nh gi√°o d·ª•c, gi√∫p ng∆∞·ªùi ch∆°i ph√°t tri·ªÉn t·ª´ v·ª±ng, k·ªπ nƒÉng ng√¥n ng·ªØ, v√† kh·∫£ nƒÉng t∆∞ duy logic. D∆∞·ªõi ƒë√¢y l√† chi ti·∫øt v·ªÅ kh√°i ‚Ä¶\\nÊé°Áî® Êñ∞„Åü„Å™„Ç§„Éé„Éô„Éº„Ç∑„Éß„É≥„ÇíÁîü„ÇÄ„Å®„ÅÑ„ÅÜ„Åì„Å®„ÅØ„ÄÅ‰∏ÄÊ≠©Ë∏è„ÅøÂá∫„ÅôÂøó„Å®ËªåÈÅì‰øÆÊ≠£„ÅÆÁπ∞„ÇäËøî„Åó„Åß„Åô„ÄÇ NEXT MAKE„ÅÆÊΩ§Ê≤¢„Å™„É™„ÇΩ„Éº„Çπ„ÇíÂ≠òÂàÜ„Å´Ê¥ªÁî®„Åó„Å¶„ÄÅÂ§±Êïó„ÇíÊÅê„Çå„Åö„Å´Â∏∏„Å´ÊåëÊà¶„ÅóÁ∂ö„Åë„Çã„É°„É≥„Éê„Éº„ÇíÊ±Ç„ÇÅ„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\nNextMaker Settings provides tools and resources for configuring and customizing your NextMaker experience.\\nChatGPT helps you get answers, find inspiration and be more productive. It is free to use and easy to try. Just ask and ChatGPT can help with writing, learning, brainstorming and more.\\n\\n### This short segment is from an \\nA short audio or video segment produced to advertise an upcoming news bulletin or news items is called a (n): teaser. News as a product has two important economic features. One feature is ‚Ä¶\\nA media clip is a short segment of audio or video content that is either intended for release to the media or is made out of some pre-existing media. Clips are generally short, often no more ‚Ä¶\\nOct 4, 2021\\xa0¬∑ Are short clips of video or movie, usually part of a longer recording a trailer b. news flash c. short new program d. movie clip 11. It is also known as a preview that gives highlights ‚Ä¶\\nActuality footage: for instance - a news reader reports breaking news and a short clip of footage is shown from the event/story itself. Piece to camera: when a reporter presents directly to the...\\nFeb 15, 2019\\xa0¬∑ While searching our database we found 1 possible solution for the: Video segment crossword clue. This crossword clue was last seen on February 15 2019 LA Times Crossword ‚Ä¶\\nA media clip is a short segment of electronic media, either an audio clip or a video clip. Media clips may be promotional in nature, as with movie clips. For example, to promote upcoming ‚Ä¶\\nAn alpha test group is made up of people associated with the project, while a beta test group is made up of people from outside the organization. What is the difference, if any, between an ‚Ä¶\\n\\n### Journalism - FBLA Flashcards | Quizlet\\n¬© 2025 Quizlet, Inc.'}\n",
      "üßê Fact-checking: Next Making r√≥i...\n",
      "‚úÖ All statements are supported or unverified.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\565.mp4\n",
      "Deepfake label: REAL, Fact-check label: True\n",
      "üíæ Saved checkpoint after 566 videos\n",
      "üìº Processing video 567: ../data/dfw_youtube_release\\566.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\566.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-8.00] Unknown: We are in the beginning of a mass extinction and all you can talk about is money and fairytales\n",
      "[8.00-47.56] SPEAKER_00: of eternal economic growth. How dare you? For more than 30 years, the science has been crystal clear. How dare you continue to look away and come here saying that you are doing enough when the politics and solutions needed are still nowhere in some but no matter how sad and angry I am, I do not want to believe that because if you really understood the situation and still kept on failing to act, then you would be evil and that I refuse to believe.\n",
      "[47.56-56.56] Unknown: I am your friend, I remind you of the times.\n",
      "[56.56-58.56] SPEAKER_01: You are right, it's ridiculous.\n",
      "[58.56-67.56] Unknown: Here is the gift of Noel. Thank you. I said gift of Noel.\n",
      "[67.56-70.56] SPEAKER_01: It's because it's not my name.\n",
      "[70.56-72.56] SPEAKER_00: Yes, that's what I had understood. Thank you.\n",
      "[72.56-91.56] Unknown: You are so good. There is also the balls. Noel. Oh, I'm sorry. It's a little long.\n",
      "[91.56-100.56] SPEAKER_01: I'm sorry, I'm not very good.\n",
      "[100.56-112.56] Unknown: Thank you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 8.0, 'speaker': 'Unknown', 'text': 'We are in the beginning of a mass extinction and all you can talk about is money and fairytales', 'reason': 'Claims that humanity is at the start of a mass extinction, a significant environmental assertion.', 'context': 'This statement was made at the beginning of a political or environmental debate or discussion during the 2020s, addressing climate change and environmental policy, calling out focus on economics over ecological crises.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}, {'start': 8.0, 'end': 47.56, 'speaker': 'SPEAKER_00', 'text': 'of eternal economic growth. How dare you? For more than 30 years, the science has been crystal clear. How dare you continue to look away and come here saying that you are doing enough when the politics and solutions needed are still nowhere in some but no matter how sad and angry I am, I do not want to believe that because if you really understood the situation and still kept on failing to act, then you would be evil and that I refuse to believe.', 'reason': 'Asserts a clear timeline of scientific consensus on environmental issues spanning over 30 years and criticizes political inaction despite this.', 'context': \"Part of a speech or debate focused on climate change policy during the early 21st century, highlighting the urgency of action and criticizing political leaders' insufficient responses.\", 'frame_path': 'statement_frames\\\\SPEAKER_00_000800.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\566\\clip_1.mp4 from 0.00s to 8.00s\n",
      "‚úÇÔ∏è Cutting statement_clips\\566\\clip_2.mp4 from 8.00s to 47.56s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\566\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['8bce36a0acf245d0b1a5258fb7ab581c_clip_1.mp4'], 'pred': [0.9738860726356506], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['9e0cc11a0f8741cda33563299c1a3b67_clip_2.mp4'], 'pred': [0.7167971730232239], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 8.0, 'speaker': 'Unknown', 'text': 'We are in the beginning of a mass extinction and all you can talk about is money and fairytales', 'reason': 'Claims that humanity is at the start of a mass extinction, a significant environmental assertion.', 'context': 'This statement was made at the beginning of a political or environmental debate or discussion during the 2020s, addressing climate change and environmental policy, calling out focus on economics over ecological crises.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.9738860726356506}, {'start': 8.0, 'end': 47.56, 'speaker': 'SPEAKER_00', 'text': 'of eternal economic growth. How dare you? For more than 30 years, the science has been crystal clear. How dare you continue to look away and come here saying that you are doing enough when the politics and solutions needed are still nowhere in some but no matter how sad and angry I am, I do not want to believe that because if you really understood the situation and still kept on failing to act, then you would be evil and that I refuse to believe.', 'reason': 'Asserts a clear timeline of scientific consensus on environmental issues spanning over 30 years and criticizes political inaction despite this.', 'context': \"Part of a speech or debate focused on climate change policy during the early 21st century, highlighting the urgency of action and criticizing political leaders' insufficient responses.\", 'frame_path': 'statement_frames\\\\SPEAKER_00_000800.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.7167971730232239}]\n",
      "‚ö†Ô∏è Statement We are in the beginning of a mass extinction and all you can talk about is money and fairytales is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\566.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 567 videos\n",
      "üìº Processing video 568: ../data/dfw_youtube_release\\567.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\567.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-45.80] Unknown: ◊û◊ì◊¢◊ë◊ï◊†◊ô ◊ô◊ï◊¶◊û◊ì◊î ◊ú◊ô ◊ë◊©◊†◊ô◊ù ◊î◊ê◊ó◊®◊ï◊†◊ï◊™ ◊™◊ë◊ô◊ì ◊©◊ú ◊û◊ï◊©◊ó◊™. ◊™◊ß◊ï◊§◊™ ◊ß◊ô◊ï◊†◊™◊ô ◊õ◊®◊ê◊© ◊î◊û◊û◊©◊ú◊î ◊î◊°◊™◊ô◊ô◊û◊î ◊ë◊™◊®◊û◊ê◊ô◊™ ◊ï◊ë◊¶◊ô◊ú◊ü ◊©◊ú ◊ó◊ß◊ô◊®◊ï◊™ ◊û◊©◊ò◊®◊î. ◊ï◊î◊ô◊ï◊ù ◊ê◊†◊ô ◊®◊ê◊© ◊û◊û◊©◊ú◊î ◊ú◊©◊¢◊ë◊® ◊©◊ê◊ï◊û◊ì ◊ú◊®◊¶◊ï◊™ ◊ê◊ï ◊†◊©◊û◊¢ ◊¢◊©◊®. ◊ñ◊î ◊î◊ï◊û◊î ◊ú◊ó◊®◊ô◊í ◊ï◊ó◊û◊ï◊®. ◊©◊ô◊© ◊û◊ô◊©◊ô ◊ô◊®◊ï◊ë ◊ê◊ï ◊ô◊ô◊©◊ï◊® ◊ú◊ó◊ï◊õ◊î ◊©◊ú ◊î◊ì◊û◊ï◊ß◊®◊ß◊ô◊î ◊ô◊©◊®◊ê◊ú◊ô◊™. ◊ê◊†◊ô ◊û◊®◊õ◊© ◊ë◊ê◊ï◊™◊ü ◊î◊©◊ô◊û◊ê ◊í◊ù ◊ú◊î◊¢◊ú◊ï◊™ ◊ê◊™ ◊î◊î◊ë◊©◊®◊ï◊™ ◊©◊õ◊ì◊ï◊® ◊î◊©◊ú◊í ◊î◊û◊©◊§◊ò◊ô ◊ë◊¢◊†◊ô◊†◊ô, ◊î◊ú◊õ ◊ï◊™◊§◊ó ◊û◊©◊ú◊ú ◊°◊ô◊ë◊ï◊™ ◊†◊ï◊°◊§◊ï◊™ ◊©◊ê◊ô◊†◊ü ◊û◊©◊§◊ò◊ô◊ï◊™ ◊§◊ú◊ï◊ï◊™. ◊ê◊ï◊ú◊ô ◊õ◊©◊™◊ô◊©◊õ◊ï◊™ ◊î◊©◊¢◊®◊î ◊ï◊î◊¢◊ô◊°◊ï◊ß ◊ë◊û◊î ◊©◊°◊ï◊ë◊ë ◊ê◊ï◊™◊ô ◊ô◊ó◊ñ◊ï◊® ◊ú◊§◊®◊ï◊§◊ï◊¶◊ô◊î ◊†◊ï◊®◊û◊ú◊ô◊™, ◊ô◊ß◊ë◊ú◊ï ◊ó◊ú◊ß ◊û◊î◊ì◊ë◊®◊ô◊ù ◊§◊®◊©◊†◊ï◊™ ◊ê◊ó◊®◊™ ◊ï◊û◊û◊ì◊ô◊ù ◊©◊§◊ï◊ô◊ô◊ù ◊ô◊ï◊™◊®.\n",
      "‚úÖ Found 1 checkworthy statements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 0.0, 'end': 45.8, 'speaker': 'Unknown', 'text': '◊û◊ì◊¢◊ë◊ï◊†◊ô ◊ô◊ï◊¶◊û◊ì◊î ◊ú◊ô ◊ë◊©◊†◊ô◊ù ◊î◊ê◊ó◊®◊ï◊†◊ï◊™ ◊™◊ë◊ô◊ì ◊©◊ú ◊û◊ï◊©◊ó◊™. ◊™◊ß◊ï◊§◊™ ◊ß◊ô◊ï◊†◊™◊ô ◊õ◊®◊ê◊© ◊î◊û◊û◊©◊ú◊î ◊î◊°◊™◊ô◊ô◊û◊î ◊ë◊™◊®◊û◊ê◊ô◊™ ◊ï◊ë◊¶◊ô◊ú◊ü ◊©◊ú ◊ó◊ß◊ô◊®◊ï◊™ ◊û◊©◊ò◊®◊î. ◊ï◊î◊ô◊ï◊ù ◊ê◊†◊ô ◊®◊ê◊© ◊û◊û◊©◊ú◊î ◊ú◊©◊¢◊ë◊® ◊©◊ê◊ï◊û◊ì ◊ú◊®◊¶◊ï◊™ ◊ê◊ï ◊†◊©◊û◊¢ ◊¢◊©◊®. ◊ñ◊î ◊î◊ï◊û◊î ◊ú◊ó◊®◊ô◊í ◊ï◊ó◊û◊ï◊®. ◊©◊ô◊© ◊û◊ô◊©◊ô ◊ô◊®◊ï◊ë ◊ê◊ï ◊ô◊ô◊©◊ï◊® ◊ú◊ó◊ï◊õ◊î ◊©◊ú ◊î◊ì◊û◊ï◊ß◊®◊ß◊ô◊î ◊ô◊©◊®◊ê◊ú◊ô◊™. ◊ê◊†◊ô ◊û◊®◊õ◊© ◊ë◊ê◊ï◊™◊ü ◊î◊©◊ô◊û◊ê ◊í◊ù ◊ú◊î◊¢◊ú◊ï◊™ ◊ê◊™ ◊î◊î◊ë◊©◊®◊ï◊™ ◊©◊õ◊ì◊ï◊® ◊î◊©◊ú◊í ◊î◊û◊©◊§◊ò◊ô ◊ë◊¢◊†◊ô◊†◊ô, ◊î◊ú◊õ ◊ï◊™◊§◊ó ◊û◊©◊ú◊ú ◊°◊ô◊ë◊ï◊™ ◊†◊ï◊°◊§◊ï◊™ ◊©◊ê◊ô◊†◊ü ◊û◊©◊§◊ò◊ô◊ï◊™ ◊§◊ú◊ï◊ï◊™. ◊ê◊ï◊ú◊ô ◊õ◊©◊™◊ô◊©◊õ◊ï◊™ ◊î◊©◊¢◊®◊î ◊ï◊î◊¢◊ô◊°◊ï◊ß ◊ë◊û◊î ◊©◊°◊ï◊ë◊ë ◊ê◊ï◊™◊ô ◊ô◊ó◊ñ◊ï◊® ◊ú◊§◊®◊ï◊§◊ï◊¶◊ô◊î ◊†◊ï◊®◊û◊ú◊ô◊™, ◊ô◊ß◊ë◊ú◊ï ◊ó◊ú◊ß ◊û◊î◊ì◊ë◊®◊ô◊ù ◊§◊®◊©◊†◊ï◊™ ◊ê◊ó◊®◊™ ◊ï◊û◊û◊ì◊ô◊ù ◊©◊§◊ï◊ô◊ô◊ù ◊ô◊ï◊™◊®.', 'reason': 'Claims of corruption accusations and legal investigations against a former prime minister, alleging disproportionate judicial actions and impact on Israeli democracy, which are significant political and legal claims worth verifying.', 'context': 'Statement made by a former Israeli prime minister during a public speech or interview in recent years, discussing his time in office, subsequent police investigations, and the broader political and judicial environment in Israel.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\567\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\567.mp4, 2764800 bytes wanted but 0 bytes read,at frame 1292/1293, at time 51.68/51.69 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['612f62b4a64a4a6cb8a0a3accd193185_clip_1.mp4'], 'pred': [0.5653418898582458], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 45.8, 'speaker': 'Unknown', 'text': '◊û◊ì◊¢◊ë◊ï◊†◊ô ◊ô◊ï◊¶◊û◊ì◊î ◊ú◊ô ◊ë◊©◊†◊ô◊ù ◊î◊ê◊ó◊®◊ï◊†◊ï◊™ ◊™◊ë◊ô◊ì ◊©◊ú ◊û◊ï◊©◊ó◊™. ◊™◊ß◊ï◊§◊™ ◊ß◊ô◊ï◊†◊™◊ô ◊õ◊®◊ê◊© ◊î◊û◊û◊©◊ú◊î ◊î◊°◊™◊ô◊ô◊û◊î ◊ë◊™◊®◊û◊ê◊ô◊™ ◊ï◊ë◊¶◊ô◊ú◊ü ◊©◊ú ◊ó◊ß◊ô◊®◊ï◊™ ◊û◊©◊ò◊®◊î. ◊ï◊î◊ô◊ï◊ù ◊ê◊†◊ô ◊®◊ê◊© ◊û◊û◊©◊ú◊î ◊ú◊©◊¢◊ë◊® ◊©◊ê◊ï◊û◊ì ◊ú◊®◊¶◊ï◊™ ◊ê◊ï ◊†◊©◊û◊¢ ◊¢◊©◊®. ◊ñ◊î ◊î◊ï◊û◊î ◊ú◊ó◊®◊ô◊í ◊ï◊ó◊û◊ï◊®. ◊©◊ô◊© ◊û◊ô◊©◊ô ◊ô◊®◊ï◊ë ◊ê◊ï ◊ô◊ô◊©◊ï◊® ◊ú◊ó◊ï◊õ◊î ◊©◊ú ◊î◊ì◊û◊ï◊ß◊®◊ß◊ô◊î ◊ô◊©◊®◊ê◊ú◊ô◊™. ◊ê◊†◊ô ◊û◊®◊õ◊© ◊ë◊ê◊ï◊™◊ü ◊î◊©◊ô◊û◊ê ◊í◊ù ◊ú◊î◊¢◊ú◊ï◊™ ◊ê◊™ ◊î◊î◊ë◊©◊®◊ï◊™ ◊©◊õ◊ì◊ï◊® ◊î◊©◊ú◊í ◊î◊û◊©◊§◊ò◊ô ◊ë◊¢◊†◊ô◊†◊ô, ◊î◊ú◊õ ◊ï◊™◊§◊ó ◊û◊©◊ú◊ú ◊°◊ô◊ë◊ï◊™ ◊†◊ï◊°◊§◊ï◊™ ◊©◊ê◊ô◊†◊ü ◊û◊©◊§◊ò◊ô◊ï◊™ ◊§◊ú◊ï◊ï◊™. ◊ê◊ï◊ú◊ô ◊õ◊©◊™◊ô◊©◊õ◊ï◊™ ◊î◊©◊¢◊®◊î ◊ï◊î◊¢◊ô◊°◊ï◊ß ◊ë◊û◊î ◊©◊°◊ï◊ë◊ë ◊ê◊ï◊™◊ô ◊ô◊ó◊ñ◊ï◊® ◊ú◊§◊®◊ï◊§◊ï◊¶◊ô◊î ◊†◊ï◊®◊û◊ú◊ô◊™, ◊ô◊ß◊ë◊ú◊ï ◊ó◊ú◊ß ◊û◊î◊ì◊ë◊®◊ô◊ù ◊§◊®◊©◊†◊ï◊™ ◊ê◊ó◊®◊™ ◊ï◊û◊û◊ì◊ô◊ù ◊©◊§◊ï◊ô◊ô◊ù ◊ô◊ï◊™◊®.', 'reason': 'Claims of corruption accusations and legal investigations against a former prime minister, alleging disproportionate judicial actions and impact on Israeli democracy, which are significant political and legal claims worth verifying.', 'context': 'Statement made by a former Israeli prime minister during a public speech or interview in recent years, discussing his time in office, subsequent police investigations, and the broader political and judicial environment in Israel.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5653418898582458}]\n",
      "‚ö†Ô∏è Statement ◊û◊ì◊¢◊ë◊ï◊†◊ô ◊ô◊ï◊¶◊û◊ì◊î ◊ú◊ô ◊ë◊©◊†◊ô◊ù ◊î◊ê◊ó◊®◊ï◊†◊ï◊™ ◊™◊ë◊ô◊ì ◊©◊ú ◊û◊ï◊©◊ó◊™. ◊™◊ß◊ï◊§◊™ ◊ß◊ô◊ï◊†◊™◊ô ◊õ◊®◊ê◊© ◊î◊û◊û◊©◊ú◊î ◊î◊°◊™◊ô◊ô◊û◊î ◊ë◊™◊®◊û◊ê◊ô◊™ ◊ï◊ë◊¶◊ô◊ú◊ü ◊©◊ú ◊ó◊ß◊ô◊®◊ï◊™ ◊û◊©◊ò◊®◊î. ◊ï◊î◊ô◊ï◊ù ◊ê◊†◊ô ◊®◊ê◊© ◊û◊û◊©◊ú◊î ◊ú◊©◊¢◊ë◊® ◊©◊ê◊ï◊û◊ì ◊ú◊®◊¶◊ï◊™ ◊ê◊ï ◊†◊©◊û◊¢ ◊¢◊©◊®. ◊ñ◊î ◊î◊ï◊û◊î ◊ú◊ó◊®◊ô◊í ◊ï◊ó◊û◊ï◊®. ◊©◊ô◊© ◊û◊ô◊©◊ô ◊ô◊®◊ï◊ë ◊ê◊ï ◊ô◊ô◊©◊ï◊® ◊ú◊ó◊ï◊õ◊î ◊©◊ú ◊î◊ì◊û◊ï◊ß◊®◊ß◊ô◊î ◊ô◊©◊®◊ê◊ú◊ô◊™. ◊ê◊†◊ô ◊û◊®◊õ◊© ◊ë◊ê◊ï◊™◊ü ◊î◊©◊ô◊û◊ê ◊í◊ù ◊ú◊î◊¢◊ú◊ï◊™ ◊ê◊™ ◊î◊î◊ë◊©◊®◊ï◊™ ◊©◊õ◊ì◊ï◊® ◊î◊©◊ú◊í ◊î◊û◊©◊§◊ò◊ô ◊ë◊¢◊†◊ô◊†◊ô, ◊î◊ú◊õ ◊ï◊™◊§◊ó ◊û◊©◊ú◊ú ◊°◊ô◊ë◊ï◊™ ◊†◊ï◊°◊§◊ï◊™ ◊©◊ê◊ô◊†◊ü ◊û◊©◊§◊ò◊ô◊ï◊™ ◊§◊ú◊ï◊ï◊™. ◊ê◊ï◊ú◊ô ◊õ◊©◊™◊ô◊©◊õ◊ï◊™ ◊î◊©◊¢◊®◊î ◊ï◊î◊¢◊ô◊°◊ï◊ß ◊ë◊û◊î ◊©◊°◊ï◊ë◊ë ◊ê◊ï◊™◊ô ◊ô◊ó◊ñ◊ï◊® ◊ú◊§◊®◊ï◊§◊ï◊¶◊ô◊î ◊†◊ï◊®◊û◊ú◊ô◊™, ◊ô◊ß◊ë◊ú◊ï ◊ó◊ú◊ß ◊û◊î◊ì◊ë◊®◊ô◊ù ◊§◊®◊©◊†◊ï◊™ ◊ê◊ó◊®◊™ ◊ï◊û◊û◊ì◊ô◊ù ◊©◊§◊ï◊ô◊ô◊ù ◊ô◊ï◊™◊®. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\567.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 568 videos\n",
      "üìº Processing video 569: ../data/dfw_youtube_release\\568.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\568.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Jean-Claude Van Damme\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Jean-Claude Van Damme\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Jean-Claude Van Damme\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_02...\n",
      "‚úÖ SPEAKER_02 ‚Üí Jean-Claude Van Damme\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-12.00] Unknown: ...\n",
      "[12.00-15.00] Jean-Claude Van Damme: Souvent en France, je suis aussi dans beaucoup de pays.\n",
      "[15.00-18.00] Unknown: Je fais beaucoup de TV, mais dans diff√©rents pays.\n",
      "[18.00-27.00] Jean-Claude Van Damme: Et si on a d'ici un tour, on se trouve. C'est pas possible d'√™tre partout. J'ai toujours un TV. La main-faisant des Grandes √âcartes, vous ne pouvez pas t'entendre ou j'√©tais c√©l√®bre. On est tous c√©l√®bre aujourd'hui, j'en suis un peu demandable.\n",
      "[27.00-30.00] Unknown: Oui, mais je sais de...\n",
      "[30.00-33.00] Jean-Claude Van Damme: C'est de l'autod√©rision. Oui, voil√†.\n",
      "[33.00-36.00] Unknown: On vous arr√™te. Exactement.\n",
      "[36.00-38.00] Jean-Claude Van Damme: Comment...\n",
      "[38.00-39.00] Unknown: Pourquoi ?\n",
      "[39.00-61.00] Jean-Claude Van Damme: Il faut savoir... C'est comme une arme. C'est comme une peinture de quelle couleur, une arme. Quel arme j'ai. J'ai un canon, j'ai un fusil, j'ai une mitraillette, j'ai... J'ai un marteau. Mais l√†, vous avez quoi, comme arme, en ce moment ? Non, mais je sais d'y spiquer avec, parce que j'ai tr√®s dur. Je reviens des √âtats-Unis. √Ä qu'un spiking, je me donne...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 39.0, 'end': 61.0, 'speaker': 'Jean-Claude Van Damme', 'text': \"Il faut savoir... C'est comme une arme. C'est comme une peinture de quelle couleur, une arme. Quel arme j'ai. J'ai un canon, j'ai un fusil, j'ai une mitraillette, j'ai... J'ai un marteau. Mais l√†, vous avez quoi, comme arme, en ce moment ? Non, mais je sais d'y spiquer avec, parce que j'ai tr√®s dur. Je reviens des √âtats-Unis. √Ä qu'un spiking, je me donne...\", 'reason': 'The speaker mentions returning from the United States and metaphorically discusses weapons, implying a comparison or statement about power or influence, which could be related to his career or public presence; this is a claim that can be fact-checked regarding his activities or statements about his career and travels.', 'context': 'The quote is taken from an informal interview or talk involving Jean-Claude Van Damme around the 2020s, discussing his international presence and metaphorically referring to power or tools in his career, likely in response to questions about his professional activities or status.', 'frame_path': 'statement_frames\\\\Jean-Claude Van Damme_003900.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\568\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\568.mp4, 2764800 bytes wanted but 0 bytes read,at frame 1737/1738, at time 72.45/72.47 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['b17fff6e591f4fc1bf2e8e832f4b7381_clip_1.mp4'], 'pred': [0.6152282953262329], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 39.0, 'end': 61.0, 'speaker': 'Jean-Claude Van Damme', 'text': \"Il faut savoir... C'est comme une arme. C'est comme une peinture de quelle couleur, une arme. Quel arme j'ai. J'ai un canon, j'ai un fusil, j'ai une mitraillette, j'ai... J'ai un marteau. Mais l√†, vous avez quoi, comme arme, en ce moment ? Non, mais je sais d'y spiquer avec, parce que j'ai tr√®s dur. Je reviens des √âtats-Unis. √Ä qu'un spiking, je me donne...\", 'reason': 'The speaker mentions returning from the United States and metaphorically discusses weapons, implying a comparison or statement about power or influence, which could be related to his career or public presence; this is a claim that can be fact-checked regarding his activities or statements about his career and travels.', 'context': 'The quote is taken from an informal interview or talk involving Jean-Claude Van Damme around the 2020s, discussing his international presence and metaphorically referring to power or tools in his career, likely in response to questions about his professional activities or status.', 'frame_path': 'statement_frames\\\\Jean-Claude Van Damme_003900.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.6152282953262329}]\n",
      "‚ö†Ô∏è Statement Il faut savoir... C'est comme une arme. C'est comme une peinture de quelle couleur, une arme. Quel arme j'ai. J'ai un canon, j'ai un fusil, j'ai une mitraillette, j'ai... J'ai un marteau. Mais l√†, vous avez quoi, comme arme, en ce moment ? Non, mais je sais d'y spiquer avec, parce que j'ai tr√®s dur. Je reviens des √âtats-Unis. √Ä qu'un spiking, je me donne... is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\568.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 569 videos\n",
      "üìº Processing video 570: ../data/dfw_youtube_release\\569.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\569.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "‚ùå No checkworthy statements found.\n",
      "‚úÖ Found 0 checkworthy statements.\n",
      "[]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\569\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚ùå Error 422: {\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"videos\"],\"msg\":\"Field required\",\"input\":null}]}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[]\n",
      "üì∞ Enriching statements with articles...\n",
      "‚úÖ Finished enriching statements with articles.\n",
      "üß™ Running fact-checks on statements...\n",
      "‚úÖ All statements are supported or unverified.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\569.mp4\n",
      "Deepfake label: REAL, Fact-check label: True\n",
      "üíæ Saved checkpoint after 570 videos\n",
      "üìº Processing video 571: ../data/dfw_youtube_release\\570.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\570.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-25.50] Unknown: C'est une parodie justice, M. Quand un gouvernement tombe √† ce niveau, il montre sa bancroute morale au monde entier. Reg honnes r√©duction technologies, comme crushed, assetÔøΩ ou privatisation,\n",
      "[25.56-30.44] SPEAKER_01: est divendue, extol√©dimensionalit√© !\n",
      "[36.94-42.28] Unknown: ÂåÖÊã¨ingle et √©tat Insertion d'ambalousie !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 25.5, 'speaker': 'Unknown', 'text': \"C'est une parodie justice, M. Quand un gouvernement tombe √† ce niveau, il montre sa bancroute morale au monde entier. Reg honnes r√©duction technologies, comme crushed, assetÔøΩ ou privatisation,\", 'reason': 'The speaker claims that the government is morally bankrupt and highlights issues like reduction technologies and privatization as examples, which can be fact-checked for accuracy and context.', 'context': 'This statement was made by an unknown speaker in a political debate or speech, likely during a discussion of government performance and policy critique. The timing is unspecified but seems to be a recent event given the topics mentioned.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\570\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\570.mp4, 2764800 bytes wanted but 0 bytes read,at frame 781/782, at time 32.57/32.58 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['a7e8d30a00304a52bad1a72b24adeafe_clip_1.mp4'], 'pred': [0.5807284116744995], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 25.5, 'speaker': 'Unknown', 'text': \"C'est une parodie justice, M. Quand un gouvernement tombe √† ce niveau, il montre sa bancroute morale au monde entier. Reg honnes r√©duction technologies, comme crushed, assetÔøΩ ou privatisation,\", 'reason': 'The speaker claims that the government is morally bankrupt and highlights issues like reduction technologies and privatization as examples, which can be fact-checked for accuracy and context.', 'context': 'This statement was made by an unknown speaker in a political debate or speech, likely during a discussion of government performance and policy critique. The timing is unspecified but seems to be a recent event given the topics mentioned.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5807284116744995}]\n",
      "‚ö†Ô∏è Statement C'est une parodie justice, M. Quand un gouvernement tombe √† ce niveau, il montre sa bancroute morale au monde entier. Reg honnes r√©duction technologies, comme crushed, assetÔøΩ ou privatisation, is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\570.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 571 videos\n",
      "üìº Processing video 572: ../data/dfw_youtube_release\\571.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\571.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-17.04] Unknown: I'm guilty guilty Is that what you want to hear? Have you nothing to say in your defense? Nothing but this I Did not do it. I Did not kill chief Keith, but I wish that I had\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 17.04, 'speaker': 'Unknown', 'text': \"I'm guilty guilty Is that what you want to hear? Have you nothing to say in your defense? Nothing but this I Did not do it. I Did not kill chief Keith, but I wish that I had\", 'reason': 'Claims innocence and expresses regret over not killing a person named Chief Keith, which is a bold and potentially controversial assertion involving a serious crime.', 'context': 'Likely part of a dramatic or theatrical dialogue or a personal confession in a recorded statement, with no explicit date or event given.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\571\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\571.mp4, 2764800 bytes wanted but 0 bytes read,at frame 418/419, at time 17.43/17.44 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['715ee070d8124e52abb8143160125f5d_clip_1.mp4'], 'pred': [0.8032311797142029], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 17.04, 'speaker': 'Unknown', 'text': \"I'm guilty guilty Is that what you want to hear? Have you nothing to say in your defense? Nothing but this I Did not do it. I Did not kill chief Keith, but I wish that I had\", 'reason': 'Claims innocence and expresses regret over not killing a person named Chief Keith, which is a bold and potentially controversial assertion involving a serious crime.', 'context': 'Likely part of a dramatic or theatrical dialogue or a personal confession in a recorded statement, with no explicit date or event given.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.8032311797142029}]\n",
      "‚ö†Ô∏è Statement I'm guilty guilty Is that what you want to hear? Have you nothing to say in your defense? Nothing but this I Did not do it. I Did not kill chief Keith, but I wish that I had is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\571.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 572 videos\n",
      "üìº Processing video 573: ../data/dfw_youtube_release\\572.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\572.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-4.08] Unknown: Talk about your influences. That's how you figure out what kind of band you want to be.\n",
      "[4.08-5.60] SPEAKER_01: So who do you like?\n",
      "[5.60-14.32] Unknown: You, shortstop. Puff Daddy. Wrong. Billy. Liza Menele? What are you guys?\n",
      "[14.32-20.84] SPEAKER_00: This project is called Rock Band. I'm talking about bands that rock. Led Zeppelin.\n",
      "[27.16-29.68] Unknown: Don't tell me you guys have never gotten the lead out.\n",
      "[29.68-37.16] SPEAKER_01: Jimmy Page, Robert Plant, Riggany Bells. What about Sabbath?\n",
      "[37.16-39.48] Unknown: ACDC.\n",
      "[39.48-43.24] SPEAKER_01: Summer, you're the class whatever. Go to the board.\n",
      "[43.24-50.52] Unknown: Fac totem. Fac totem. New schedule. 815 to 10.\n",
      "[50.52-52.76] SPEAKER_01: Rock history.\n",
      "[52.76-54.04] Unknown: 10 to 11.\n",
      "[54.04-57.76] SPEAKER_01: Rock appreciation and theory.\n",
      "[57.76-61.36] Unknown: And then band practice till the end of the day. What about math?\n",
      "[61.36-68.88] SPEAKER_01: No, not important. World cultures? Not important. You guys, we need to focus here. Don't you want to win this contest? It's prestigious.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 checkworthy statements.\n",
      "[{'start': 14.32, 'end': 20.84, 'speaker': 'SPEAKER_00', 'text': \"This project is called Rock Band. I'm talking about bands that rock. Led Zeppelin.\", 'reason': 'Mentions a specific band (Led Zeppelin) as a reference point to define the concept of a band that rocks, which can be verified based on music history and influence.', 'context': \"The quote was made during an informal conversation or interview about musical influences and preferences, discussing the theme of a project called 'Rock Band'. The context is about determining what kind of band to be, focusing on rock music legends like Led Zeppelin.\", 'frame_path': 'statement_frames\\\\SPEAKER_00_001432.jpg'}, {'start': 61.36, 'end': 68.88, 'speaker': 'SPEAKER_01', 'text': \"No, not important. World cultures? Not important. You guys, we need to focus here. Don't you want to win this contest? It's prestigious.\", 'reason': \"Claims that certain academic subjects are not important in the context of a competition, and asserts the prestige of the contest, which involves evaluative judgments and a factual basis for the contest's prestige.\", 'context': 'This occurred during a discussion about priorities and schedules among students or band members, emphasizing the importance of a music contest over other subjects like math and world cultures, aiming to motivate the group to focus on winning the prestigious contest.', 'frame_path': 'statement_frames\\\\SPEAKER_01_006136.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\572\\clip_1.mp4 from 14.32s to 20.84s\n",
      "‚úÇÔ∏è Cutting statement_clips\\572\\clip_2.mp4 from 61.36s to 68.88s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\572\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['0ce5da4987f64dc6b446d2032024c1f5_clip_1.mp4'], 'pred': [0.6817797422409058], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['ba0cfa45cb274a97b8d95a14b849ab9b_clip_2.mp4'], 'pred': [0.6675630211830139], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 14.32, 'end': 20.84, 'speaker': 'SPEAKER_00', 'text': \"This project is called Rock Band. I'm talking about bands that rock. Led Zeppelin.\", 'reason': 'Mentions a specific band (Led Zeppelin) as a reference point to define the concept of a band that rocks, which can be verified based on music history and influence.', 'context': \"The quote was made during an informal conversation or interview about musical influences and preferences, discussing the theme of a project called 'Rock Band'. The context is about determining what kind of band to be, focusing on rock music legends like Led Zeppelin.\", 'frame_path': 'statement_frames\\\\SPEAKER_00_001432.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.6817797422409058}, {'start': 61.36, 'end': 68.88, 'speaker': 'SPEAKER_01', 'text': \"No, not important. World cultures? Not important. You guys, we need to focus here. Don't you want to win this contest? It's prestigious.\", 'reason': \"Claims that certain academic subjects are not important in the context of a competition, and asserts the prestige of the contest, which involves evaluative judgments and a factual basis for the contest's prestige.\", 'context': 'This occurred during a discussion about priorities and schedules among students or band members, emphasizing the importance of a music contest over other subjects like math and world cultures, aiming to motivate the group to focus on winning the prestigious contest.', 'frame_path': 'statement_frames\\\\SPEAKER_01_006136.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.6675630211830139}]\n",
      "‚ö†Ô∏è Statement This project is called Rock Band. I'm talking about bands that rock. Led Zeppelin. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\572.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 573 videos\n",
      "üìº Processing video 574: ../data/dfw_youtube_release\\573.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\573.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_03...\n",
      "‚úÖ SPEAKER_03 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_02...\n",
      "‚úÖ SPEAKER_02 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Action Bronson\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-2.60] Unknown: You believe in this shit or what you believe in aliens?\n",
      "[2.60-8.80] SPEAKER_03: I don't know what the fuck I'm doing here. Just answer the fucking question. Do you like aliens? Yeah, they're sick.\n",
      "[8.80-25.60] Unknown: What are you on? Carried a powerful chemical in its beak, a substance capable of melting stone. Saksa Wa Man means the hit of the falcon. Falcons.\n",
      "[25.60-36.60] SPEAKER_02: What the fuck are we looking at? But maybe we're some Falcons, or maybe some alert people who could connect with us. Yo, this nigga crazy. He said it looks like a falcon's head.\n",
      "[36.60-47.20] Unknown: But maybe a bird that some people would think is a falcon. Who from cavemen were quarrying these giant stones?\n",
      "[47.20-51.40] SPEAKER_01: Some of them weighing 100, 200 tons. His voice is sick.\n",
      "[51.40-57.20] SPEAKER_03: 50 tons. And you see him the reveal. He always got to tell you some shit right there.\n",
      "[57.20-62.20] Unknown: Did ancient aliens really help to shape our history?\n",
      "[62.20-67.20] Action Bronson: And if so, is there an extraterrestrial explanation\n",
      "[67.20-71.40] Unknown: for the Earth's most mysterious unexplained structures?\n",
      "‚úÖ Found 2 checkworthy statements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 8.8, 'end': 25.6, 'speaker': 'Unknown', 'text': 'What are you on? Carried a powerful chemical in its beak, a substance capable of melting stone. Saksa Wa Man means the hit of the falcon. Falcons.', 'reason': \"Makes a factual claim about a chemical substance capable of melting stone carried by a bird and provides a translation of a phrase related to 'falcon'.\", 'context': 'This claim occurs in a discussion potentially about ancient mysteries or extraterrestrial theories, during a conversation involving multiple speakers questioning alien or ancient influences on historical constructions.', 'frame_path': 'statement_frames\\\\Unknown_000880.jpg'}, {'start': 57.2, 'end': 62.2, 'speaker': 'Unknown', 'text': 'Did ancient aliens really help to shape our history?', 'reason': 'Poses a checkworthy factual claim or hypothesis about the involvement of ancient aliens in shaping human history, inviting verification.', 'context': \"This question is asked in the context of a conversation or documentary segment exploring extraterrestrial explanations for historical events or mysterious structures, reflecting common claims in 'ancient aliens' theories.\", 'frame_path': 'statement_frames\\\\Unknown_005720.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\573\\clip_1.mp4 from 8.80s to 25.60s\n",
      "‚úÇÔ∏è Cutting statement_clips\\573\\clip_2.mp4 from 57.20s to 62.20s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\573\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['e49b696c95dc41d490e83cdc34bc5d5b_clip_1.mp4'], 'pred': [0.9530226588249207], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['f6dcf5b14cf1481186e069c87a8d9b1b_clip_2.mp4'], 'pred': [0.5], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 8.8, 'end': 25.6, 'speaker': 'Unknown', 'text': 'What are you on? Carried a powerful chemical in its beak, a substance capable of melting stone. Saksa Wa Man means the hit of the falcon. Falcons.', 'reason': \"Makes a factual claim about a chemical substance capable of melting stone carried by a bird and provides a translation of a phrase related to 'falcon'.\", 'context': 'This claim occurs in a discussion potentially about ancient mysteries or extraterrestrial theories, during a conversation involving multiple speakers questioning alien or ancient influences on historical constructions.', 'frame_path': 'statement_frames\\\\Unknown_000880.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.9530226588249207}, {'start': 57.2, 'end': 62.2, 'speaker': 'Unknown', 'text': 'Did ancient aliens really help to shape our history?', 'reason': 'Poses a checkworthy factual claim or hypothesis about the involvement of ancient aliens in shaping human history, inviting verification.', 'context': \"This question is asked in the context of a conversation or documentary segment exploring extraterrestrial explanations for historical events or mysterious structures, reflecting common claims in 'ancient aliens' theories.\", 'frame_path': 'statement_frames\\\\Unknown_005720.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5}]\n",
      "‚ö†Ô∏è Statement What are you on? Carried a powerful chemical in its beak, a substance capable of melting stone. Saksa Wa Man means the hit of the falcon. Falcons. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\573.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 574 videos\n",
      "üìº Processing video 575: ../data/dfw_youtube_release\\574.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\574.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Thor Odinson\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Thor Odinson\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-16.00] Unknown: I just looked at the field and being a Bible man myself and I would be labeled as way out there on the right. But that's not entirely true.\n",
      "[16.00-35.00] Thor Odinson: But Cruz I knew was a strict constitutionalist and I knew his daddy was a preacher. So I thought he probably had good values and was raised right. So I looked at the Supreme Court nominees coming up and I said you know I love the Anthony Scalia.\n",
      "‚úÖ Found 1 checkworthy statements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 16.0, 'end': 35.0, 'speaker': 'Thor Odinson', 'text': 'But Cruz I knew was a strict constitutionalist and I knew his daddy was a preacher. So I thought he probably had good values and was raised right. So I looked at the Supreme Court nominees coming up and I said you know I love the Anthony Scalia.', 'reason': \"Claims about Ted Cruz's constitutionalist stance, family background, and opinion on Supreme Court nominees such as Anthony Scalia, which can be fact-checked for accuracy.\", 'context': \"Statement made during a political discussion or interview, reflecting on Ted Cruz's character and Supreme Court nominations. The timing suggests a commentary on conservative values and judicial appointments, possibly during campaign events or political commentary in the 2020s.\", 'frame_path': 'statement_frames\\\\Thor Odinson_001600.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\574\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\574.mp4, 2764800 bytes wanted but 0 bytes read,at frame 1053/1054, at time 35.10/35.11 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['d9d31b9ac7c8430cb73edb8a11141ad3_clip_1.mp4'], 'pred': [0.9902594089508057], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 16.0, 'end': 35.0, 'speaker': 'Thor Odinson', 'text': 'But Cruz I knew was a strict constitutionalist and I knew his daddy was a preacher. So I thought he probably had good values and was raised right. So I looked at the Supreme Court nominees coming up and I said you know I love the Anthony Scalia.', 'reason': \"Claims about Ted Cruz's constitutionalist stance, family background, and opinion on Supreme Court nominees such as Anthony Scalia, which can be fact-checked for accuracy.\", 'context': \"Statement made during a political discussion or interview, reflecting on Ted Cruz's character and Supreme Court nominations. The timing suggests a commentary on conservative values and judicial appointments, possibly during campaign events or political commentary in the 2020s.\", 'frame_path': 'statement_frames\\\\Thor Odinson_001600.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.9902594089508057}]\n",
      "‚ö†Ô∏è Statement But Cruz I knew was a strict constitutionalist and I knew his daddy was a preacher. So I thought he probably had good values and was raised right. So I looked at the Supreme Court nominees coming up and I said you know I love the Anthony Scalia. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\574.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 575 videos\n",
      "üìº Processing video 576: ../data/dfw_youtube_release\\575.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\575.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-17.00] Unknown: What's left to say? These prayers and work in anymore Every word shunned down in flesh\n",
      "[17.00-27.00] SPEAKER_00: What's left to do with these broken pieces on the floor?\n",
      "[28.00-60.00] Unknown: I'm losing my voice calling on you Cause I've been shaking, I've been bending by words to love and blow Watching all these dreams go up and it's snow You left beauty from the outer my chest\n",
      "[60.00-77.00] SPEAKER_00: You left beauty from the outer my chest And when I pray to call for my ashes\n",
      "[77.00-113.00] Unknown: Can you be coming out of my chest? Can you use these tears to put out the fires in my soul? Cause I need you here Cause I've been shaking, I've been bending by words to love and blow\n",
      "[114.00-120.00] SPEAKER_00: Watching all these dreams go up and it's snow\n",
      "[120.00-129.00] Unknown: You left beauty from the outer my chest\n",
      "[129.00-135.00] SPEAKER_00: You left beauty from the outer my chest\n",
      "‚ùå No checkworthy statements found.\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-17.00] Unknown: What's left to say? These prayers and work in anymore Every word shunned down in flesh\n",
      "[17.00-27.00] SPEAKER_00: What's left to do with these broken pieces on the floor?\n",
      "[28.00-60.00] Unknown: I'm losing my voice calling on you Cause I've been shaking, I've been bending by words to love and blow Watching all these dreams go up and it's snow You left beauty from the outer my chest\n",
      "[60.00-77.00] SPEAKER_00: You left beauty from the outer my chest And when I pray to call for my ashes\n",
      "[77.00-113.00] Unknown: Can you be coming out of my chest? Can you use these tears to put out the fires in my soul? Cause I need you here Cause I've been shaking, I've been bending by words to love and blow\n",
      "[114.00-120.00] SPEAKER_00: Watching all these dreams go up and it's snow\n",
      "[120.00-129.00] Unknown: You left beauty from the outer my chest\n",
      "[129.00-135.00] SPEAKER_00: You left beauty from the outer my chest\n",
      "‚úÖ Found 0 checkworthy statements.\n",
      "[]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\575\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚ùå Error 422: {\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"videos\"],\"msg\":\"Field required\",\"input\":null}]}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[]\n",
      "üì∞ Enriching statements with articles...\n",
      "‚úÖ Finished enriching statements with articles.\n",
      "üß™ Running fact-checks on statements...\n",
      "‚úÖ All statements are supported or unverified.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\575.mp4\n",
      "Deepfake label: REAL, Fact-check label: True\n",
      "üíæ Saved checkpoint after 576 videos\n",
      "üìº Processing video 577: ../data/dfw_youtube_release\\576.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\576.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-6.16] Unknown: I hate to say this. I think there's someone hanging right there. Hmm. I'm not even fucking kidding.\n",
      "[6.16-7.16] SPEAKER_00: Do you see it?\n",
      "[7.16-8.16] Unknown: I'm not even...\n",
      "[8.16-9.16] SPEAKER_00: This isn't a f***ing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 6.16, 'speaker': 'Unknown', 'text': \"I hate to say this. I think there's someone hanging right there. Hmm. I'm not even fucking kidding.\", 'reason': 'Makes a serious and potentially factual claim about seeing a person hanging, which is urgent and alarming and thus important to verify.', 'context': 'Spontaneous statement during a possibly live or recorded event, no clear information about location or date. The topic is an emergency or alarming observation noticed in the moment, possibly outside or on a street.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\576\\clip_1.mp4\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['ffa90fad76a04756839f40b41b30d2c7_clip_1.mp4'], 'pred': [0.7759007215499878], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 6.16, 'speaker': 'Unknown', 'text': \"I hate to say this. I think there's someone hanging right there. Hmm. I'm not even fucking kidding.\", 'reason': 'Makes a serious and potentially factual claim about seeing a person hanging, which is urgent and alarming and thus important to verify.', 'context': 'Spontaneous statement during a possibly live or recorded event, no clear information about location or date. The topic is an emergency or alarming observation noticed in the moment, possibly outside or on a street.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.7759007215499878}]\n",
      "‚ö†Ô∏è Statement I hate to say this. I think there's someone hanging right there. Hmm. I'm not even fucking kidding. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\576.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 577 videos\n",
      "üìº Processing video 578: ../data/dfw_youtube_release\\577.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\577.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-2.30] Unknown: Then one day I get into accident.\n",
      "[2.30-5.30] Tommy: What happened? Guy run red lie and smash.\n",
      "[5.30-5.80] Unknown: Wow.\n",
      "[5.80-7.50] Tommy: Very bad for Tommy.\n",
      "[7.50-12.00] Unknown: I almost die. But then I survive. Wow.\n",
      "[12.00-33.30] Tommy: It was like wake up call you could say. Yeah, definitely. After that, I stopped doing all the other things. And I go back to my dream. And everybody say, you're such crazy guys. You're such a stupid guy. I said, I don't care. I do it. Yes. And now I can do it. It's bullshit. I did not hit her. I did not.\n",
      "[33.30-34.20] Unknown: Oh, hi, Mark.\n",
      "[34.20-38.00] Tommy: What the fuck are you looking? What doesn't work if you're looking at the camera?\n",
      "[38.00-40.80] Bill: What? Takes.\n",
      "[40.80-41.50] Unknown: Yeah.\n",
      "[41.50-44.00] Tommy: Good day, everybody. See you tomorrow.\n",
      "[44.00-52.50] Bill: All right. Great job. I'm not believe it. Let's go to the bar and arrange the memory of today.\n",
      "[52.50-53.50] Unknown: Hey, Sandy.\n",
      "[53.50-55.30] Tommy: Rafael. Yep.\n",
      "[55.30-61.80] Unknown: I'm talking about it. Good day, sir. Good day. Come on.\n",
      "[61.80-69.30] Tommy: That's a big louder. Tommy, I just don't worry about these people. They're only you and they only me. Let's do it.\n",
      "[69.30-70.80] Unknown: Put your hat.\n",
      "[70.80-74.30] Tommy: OK. Good day, sir. OK.\n",
      "[74.30-75.30] Unknown: Don't be weird.\n",
      "[75.30-76.30] Tommy: I'm doing it.\n",
      "[76.30-77.80] SPEAKER_01: I'm sorry.\n",
      "[77.80-82.80] Unknown: Have I, the honor of visit from the illustrious God, Jupiter, Tony?\n",
      "[82.80-83.80] SPEAKER_01: I'm kidding.\n",
      "[83.80-90.80] Tommy: He's going. All right. Is this the foulest she does? Costumes? What do you think my character does like this?\n",
      "[90.80-93.80] SPEAKER_00: Maybe we could get rid of one of the belts. What?\n",
      "[93.80-98.80] Tommy: No. No way. Like my butt looked good. OK. Pretend I'm boyfriend.\n",
      "[98.80-102.80] Unknown: Go. Go. And what do you do?\n",
      "[102.80-103.80] Tommy: You remember Bill?\n",
      "[103.80-105.80] SPEAKER_01: You know Bill? Come on.\n",
      "[105.80-106.80] Tommy: That's all to the equipment.\n",
      "[106.80-113.80] Bill: Yeah. Bill, I didn't know it was you. We are able to sell you all the equipment.\n",
      "[113.80-116.80] Tommy: OK. There we go. I didn't say yes.\n",
      "[116.80-133.80] Bill: And we're also willing to give it to you at a reduced rate if you decide to shoot here in our studio. What do you think? We shoot here. Yeah. We want to be in business with you, Tom. OK. We make American movie with the American discount. All right. OK. That's the deal.\n",
      "[133.80-139.80] Unknown: All right. I'm from New Orleans. New Orleans. From the bio. You guys hear that?\n",
      "[139.80-143.80] Tommy: This guy with this fucking accent is from the bio. I'm going to buy you.\n",
      "[143.80-144.80] Unknown: Go ahead.\n",
      "[144.80-148.80] SPEAKER_01: Now you want an easier question? Let's see. Where does the money come from, huh? All right.\n",
      "[148.80-157.80] Tommy: Stop. This is on camera. I know it's on camera just like you wanted. All right. Everything gray on my end. You heard a constant teen Santa's Losski? Of course.\n",
      "[157.80-158.80] Unknown: Yeah.\n",
      "[158.80-169.80] Tommy: He's like the greatest acting teacher of all time. Yeah. And now he's Tommy acting teacher. He seems something special on me. You know, maybe. You know, I become a big star. So I have first class this evening.\n",
      "[170.80-173.80] Unknown: Oh, I'm pretty sure Santa's Losski's dead.\n",
      "[173.80-175.80] Tommy: No, he's not dead.\n",
      "[175.80-177.80] Unknown: I just speak to him for your information.\n",
      "[177.80-179.80] Tommy: Wow.\n",
      "[179.80-181.80] Unknown: How old are you?\n",
      "[181.80-188.80] SPEAKER_00: Wow, this question has my bad question. Don't want to get it. You're 19? Yeah.\n",
      "[188.80-189.80] Unknown: I just turned 14.\n",
      "[189.80-190.80] SPEAKER_00: Wow.\n",
      "[190.80-192.80] Tommy: Happy birthday. OK.\n",
      "[192.80-198.80] SPEAKER_00: Tommy, what is it about my son that you find so intriguing? Nothing, Dale. Baby face cool guy.\n",
      "[198.80-199.80] Tommy: Baby face.\n",
      "[199.80-200.80] Unknown: OK, all right, mom.\n",
      "[200.80-208.80] Tommy: It's a long drive. Oh, my God. Oh, my God. Look at him. I'm just son. You know, son. Yeah, I know what a son it is.\n",
      "[208.80-214.80] Bill: But I think what I'm asking is why on earth would you choose to do that here? I do the shags.\n",
      "[214.80-241.80] Tommy: Have you looked at yourself? Yeah, I see myself. This is no offense. You have a malevolent presence. You are a perfect villain. I'm not scary, God. I could see you as Dracula, Frankenstein. No, Frankenstein. I'm trying to give you a shortcut to success. Keep your shortcut in your pocket. Have you read any? Shakespeare. I know all Shakespeare. On the tempest? Yeah.\n",
      "[241.80-242.80] Unknown: You're Calibur.\n",
      "[242.80-245.80] Tommy: Yeah, what he do. He hear all? He is.\n",
      "[245.80-247.80] Unknown: It's fucking incredible.\n",
      "[247.80-250.80] SPEAKER_01: How many people can say they do something like that?\n",
      "[250.80-251.80] Unknown: No.\n",
      "[251.80-253.80] SPEAKER_01: 1,000.\n",
      "[253.80-257.80] Unknown: And yeah, maybe it didn't turn out exactly as you hoped.\n",
      "[257.80-259.80] SPEAKER_01: But just listen for a second.\n",
      "[266.80-268.80] Unknown: I'm like, wow.\n",
      "[268.80-287.80] Tommy: He do this movie, Birds. Yeah, I'm aware of the Birds. On this movie? He terrified actors. He locked them in room. He threw, he threw birds at them. Real Birds. Nasty stop. The actors, they cry every day. This movie, when every award is Mr. Hitchcock Bad Man? No, he's great director.\n",
      "‚úÖ Found 3 checkworthy statements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 12.0, 'end': 33.3, 'speaker': 'Tommy', 'text': \"It was like wake up call you could say. Yeah, definitely. After that, I stopped doing all the other things. And I go back to my dream. And everybody say, you're such crazy guys. You're such a stupid guy. I said, I don't care. I do it. Yes. And now I can do it. It's bullshit. I did not hit her. I did not.\", 'reason': 'Claims a personal turning point after a car accident and denies an allegation of hitting someone, which is noteworthy for personal narrative and potential controversy.', 'context': 'Spoken during a casual conversation or interview, around the middle of the recording, likely reflecting on a significant personal event and addressing accusations. Topic concerns personal life story and clarification against claims.', 'frame_path': 'statement_frames\\\\Tommy_001200.jpg'}, {'start': 116.8, 'end': 133.8, 'speaker': 'Bill', 'text': \"And we're also willing to give it to you at a reduced rate if you decide to shoot here in our studio. What do you think? We shoot here. Yeah. We want to be in business with you, Tom. OK. We make American movie with the American discount. All right. OK. That's the deal.\", 'reason': 'Makes a factual claim about business terms to produce a film including a discounted offer, which can be verified.', 'context': 'Spoken during a negotiation scene about film production equipment and shooting location, likely mid-recording. Topic involves business and film industry commitments and agreements.', 'frame_path': 'statement_frames\\\\Bill_011680.jpg'}, {'start': 268.8, 'end': 287.8, 'speaker': 'Tommy', 'text': \"He do this movie, Birds. Yeah, I'm aware of the Birds. On this movie? He terrified actors. He locked them in room. He threw, he threw birds at them. Real Birds. Nasty stop. The actors, they cry every day. This movie, when every award is Mr. Hitchcock Bad Man? No, he's great director.\", 'reason': 'Describes factual and controversial allegations about Alfred Hitchcock\\'s directing methods during the making of \"The Birds,\" which are notable claims about historical events in film.', 'context': \"Spoken towards the end of the audio recording in a discussion about film directors and films' production stories, highlighting both criticism and praise about Hitchcock's work methods and reputation.\", 'frame_path': 'statement_frames\\\\Tommy_026880.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\577\\clip_1.mp4 from 12.00s to 33.30s\n",
      "‚úÇÔ∏è Cutting statement_clips\\577\\clip_2.mp4 from 116.80s to 133.80s\n",
      "‚úÇÔ∏è Cutting statement_clips\\577\\clip_3.mp4 from 268.80s to 287.80s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\577\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['35053d1ef0f140a7a0810bb87e728931_clip_1.mp4'], 'pred': [0.49377477169036865], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['b973aafb9d654c968785620181dc7004_clip_2.mp4'], 'pred': [0.3865134119987488], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "clip_3.mp4: {'name': ['2a114170800f4b1d937901fa6b592eca_clip_3.mp4'], 'pred': [0.4636234641075134], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 12.0, 'end': 33.3, 'speaker': 'Tommy', 'text': \"It was like wake up call you could say. Yeah, definitely. After that, I stopped doing all the other things. And I go back to my dream. And everybody say, you're such crazy guys. You're such a stupid guy. I said, I don't care. I do it. Yes. And now I can do it. It's bullshit. I did not hit her. I did not.\", 'reason': 'Claims a personal turning point after a car accident and denies an allegation of hitting someone, which is noteworthy for personal narrative and potential controversy.', 'context': 'Spoken during a casual conversation or interview, around the middle of the recording, likely reflecting on a significant personal event and addressing accusations. Topic concerns personal life story and clarification against claims.', 'frame_path': 'statement_frames\\\\Tommy_001200.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.49377477169036865}, {'start': 116.8, 'end': 133.8, 'speaker': 'Bill', 'text': \"And we're also willing to give it to you at a reduced rate if you decide to shoot here in our studio. What do you think? We shoot here. Yeah. We want to be in business with you, Tom. OK. We make American movie with the American discount. All right. OK. That's the deal.\", 'reason': 'Makes a factual claim about business terms to produce a film including a discounted offer, which can be verified.', 'context': 'Spoken during a negotiation scene about film production equipment and shooting location, likely mid-recording. Topic involves business and film industry commitments and agreements.', 'frame_path': 'statement_frames\\\\Bill_011680.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.3865134119987488}, {'start': 268.8, 'end': 287.8, 'speaker': 'Tommy', 'text': \"He do this movie, Birds. Yeah, I'm aware of the Birds. On this movie? He terrified actors. He locked them in room. He threw, he threw birds at them. Real Birds. Nasty stop. The actors, they cry every day. This movie, when every award is Mr. Hitchcock Bad Man? No, he's great director.\", 'reason': 'Describes factual and controversial allegations about Alfred Hitchcock\\'s directing methods during the making of \"The Birds,\" which are notable claims about historical events in film.', 'context': \"Spoken towards the end of the audio recording in a discussion about film directors and films' production stories, highlighting both criticism and praise about Hitchcock's work methods and reputation.\", 'frame_path': 'statement_frames\\\\Tommy_026880.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.4636234641075134}]\n",
      "üì∞ Enriching statements with articles...\n",
      "https://www.bing.com/search?q=And we're also willing to give it to you at a reduced rate if you decide to shoot here in our studio. What do you think? We shoot here. Yeah. We want to be in business with you, Tom. OK. We make American movie with the American discount. All right. OK. That's the deal.https://www.bing.com/search?q=It was like wake up call you could say. Yeah, definitely. After that, I stopped doing all the other things. And I go back to my dream. And everybody say, you're such crazy guys. You're such a stupid guy. I said, I don't care. I do it. Yes. And now I can do it. It's bullshit. I did not hit her. I did not.\n",
      "https://www.bing.com/search?q=He do this movie, Birds. Yeah, I'm aware of the Birds. On this movie? He terrified actors. He locked them in room. He threw, he threw birds at them. Real Birds. Nasty stop. The actors, they cry every day. This movie, when every award is Mr. Hitchcock Bad Man? No, he's great director.\n",
      "\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"a0491c76d4deee8dee603862e723b11c\", element=\"f.A32F91DF104B08160458C17C32F73EDF.d.1F12507DE7A6341B93DCDF0BD7596793.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a0491c76d4deee8dee603862e723b11c\", element=\"f.A32F91DF104B08160458C17C32F73EDF.d.1F12507DE7A6341B93DCDF0BD7596793.e.15\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a0491c76d4deee8dee603862e723b11c\", element=\"f.A32F91DF104B08160458C17C32F73EDF.d.1F12507DE7A6341B93DCDF0BD7596793.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a0491c76d4deee8dee603862e723b11c\", element=\"f.A32F91DF104B08160458C17C32F73EDF.d.1F12507DE7A6341B93DCDF0BD7596793.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a0491c76d4deee8dee603862e723b11c\", element=\"f.A32F91DF104B08160458C17C32F73EDF.d.1F12507DE7A6341B93DCDF0BD7596793.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a0491c76d4deee8dee603862e723b11c\", element=\"f.A32F91DF104B08160458C17C32F73EDF.d.1F12507DE7A6341B93DCDF0BD7596793.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a0491c76d4deee8dee603862e723b11c\", element=\"f.A32F91DF104B08160458C17C32F73EDF.d.1F12507DE7A6341B93DCDF0BD7596793.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a0491c76d4deee8dee603862e723b11c\", element=\"f.A32F91DF104B08160458C17C32F73EDF.d.1F12507DE7A6341B93DCDF0BD7596793.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a0491c76d4deee8dee603862e723b11c\", element=\"f.A32F91DF104B08160458C17C32F73EDF.d.1F12507DE7A6341B93DCDF0BD7596793.e.27\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a0491c76d4deee8dee603862e723b11c\", element=\"f.A32F91DF104B08160458C17C32F73EDF.d.1F12507DE7A6341B93DCDF0BD7596793.e.28\")>]\n",
      "Google Translate\n",
      "https://translate.google.co.uk/\n",
      "20 Sample Emails Giving Discount on Quotation - Written Samples\n",
      "https://writtensamples.com/sample-emails-giving-discount-on-quotation/\n",
      "Found 9 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"4c572fd6c0d3dafa04d44042c19238f8\", element=\"f.719A4E857C60CB5C7C98F9C1BC8C51C7.d.CCCF5EE88520BB460637E76C5202EBE8.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4c572fd6c0d3dafa04d44042c19238f8\", element=\"f.719A4E857C60CB5C7C98F9C1BC8C51C7.d.CCCF5EE88520BB460637E76C5202EBE8.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4c572fd6c0d3dafa04d44042c19238f8\", element=\"f.719A4E857C60CB5C7C98F9C1BC8C51C7.d.CCCF5EE88520BB460637E76C5202EBE8.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4c572fd6c0d3dafa04d44042c19238f8\", element=\"f.719A4E857C60CB5C7C98F9C1BC8C51C7.d.CCCF5EE88520BB460637E76C5202EBE8.e.27\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4c572fd6c0d3dafa04d44042c19238f8\", element=\"f.719A4E857C60CB5C7C98F9C1BC8C51C7.d.CCCF5EE88520BB460637E76C5202EBE8.e.28\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4c572fd6c0d3dafa04d44042c19238f8\", element=\"f.719A4E857C60CB5C7C98F9C1BC8C51C7.d.CCCF5EE88520BB460637E76C5202EBE8.e.29\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4c572fd6c0d3dafa04d44042c19238f8\", element=\"f.719A4E857C60CB5C7C98F9C1BC8C51C7.d.CCCF5EE88520BB460637E76C5202EBE8.e.30\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4c572fd6c0d3dafa04d44042c19238f8\", element=\"f.719A4E857C60CB5C7C98F9C1BC8C51C7.d.CCCF5EE88520BB460637E76C5202EBE8.e.31\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"4c572fd6c0d3dafa04d44042c19238f8\", element=\"f.719A4E857C60CB5C7C98F9C1BC8C51C7.d.CCCF5EE88520BB460637E76C5202EBE8.e.32\")>]\n",
      "The Angry Birds Movie (2016) Movie Script | SS\n",
      "https://www.springfieldspringfield.co.uk/movie_script.php?movie=the-angry-birds-movie\n",
      "The Disaster Artist (2017) - Quotes - IMDb\n",
      "https://www.imdb.com/title/tt3521126/quotes/\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"a4a89c7baae1e3141adcfaf59b78bc88\", element=\"f.5584CE6960EB0F1F5EEF0777DC9C0B24.d.A16B7BF8D7704001FB30B5330940FF97.e.19\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a4a89c7baae1e3141adcfaf59b78bc88\", element=\"f.5584CE6960EB0F1F5EEF0777DC9C0B24.d.A16B7BF8D7704001FB30B5330940FF97.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a4a89c7baae1e3141adcfaf59b78bc88\", element=\"f.5584CE6960EB0F1F5EEF0777DC9C0B24.d.A16B7BF8D7704001FB30B5330940FF97.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a4a89c7baae1e3141adcfaf59b78bc88\", element=\"f.5584CE6960EB0F1F5EEF0777DC9C0B24.d.A16B7BF8D7704001FB30B5330940FF97.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a4a89c7baae1e3141adcfaf59b78bc88\", element=\"f.5584CE6960EB0F1F5EEF0777DC9C0B24.d.A16B7BF8D7704001FB30B5330940FF97.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a4a89c7baae1e3141adcfaf59b78bc88\", element=\"f.5584CE6960EB0F1F5EEF0777DC9C0B24.d.A16B7BF8D7704001FB30B5330940FF97.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a4a89c7baae1e3141adcfaf59b78bc88\", element=\"f.5584CE6960EB0F1F5EEF0777DC9C0B24.d.A16B7BF8D7704001FB30B5330940FF97.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a4a89c7baae1e3141adcfaf59b78bc88\", element=\"f.5584CE6960EB0F1F5EEF0777DC9C0B24.d.A16B7BF8D7704001FB30B5330940FF97.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a4a89c7baae1e3141adcfaf59b78bc88\", element=\"f.5584CE6960EB0F1F5EEF0777DC9C0B24.d.A16B7BF8D7704001FB30B5330940FF97.e.27\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"a4a89c7baae1e3141adcfaf59b78bc88\", element=\"f.5584CE6960EB0F1F5EEF0777DC9C0B24.d.A16B7BF8D7704001FB30B5330940FF97.e.28\")>]\n",
      "Memorable Quotes from Cowboy Bebop\n",
      "https://cowboybebop.fandom.com/wiki/Memorable_Quotes_from_Cowboy_Bebop\n",
      "[Serious] What was your wake up call? And what did you do/how ‚Ä¶\n",
      "https://www.reddit.com/r/AskReddit/comments/w3yg3a/serious_what_was_your_wake_up_call_and_what_did/\n",
      "Found 3 relevant links:\n",
      "[{'title': \"And we're also willing to give\", 'link': \"https://www.bing.com/search?q=And we're also willing to give it to you at a reduced rate if you decide to shoot here in our studio. What do you think? We shoot here. Yeah. We want to be in business with you, Tom. OK. We make American movie with the American discount. All right. OK. That's the deal.\"}, {'title': 'Google Translate', 'link': 'https://translate.google.co.uk/'}, {'title': '20 Sample Emails Giving Discount on Quotation - Written Samples', 'link': 'https://writtensamples.com/sample-emails-giving-discount-on-quotation/'}]Found 3 relevant links:\n",
      "[{'title': 'He do this movie, Birds. Yeah,', 'link': \"https://www.bing.com/search?q=He do this movie, Birds. Yeah, I'm aware of the Birds. On this movie? He terrified actors. He locked them in room. He threw, he threw birds at them. Real Birds. Nasty stop. The actors, they cry every day. This movie, when every award is Mr. Hitchcock Bad Man? No, he's great director.\"}, {'title': 'The Angry Birds Movie (2016) Movie Script | SS', 'link': 'https://www.springfieldspringfield.co.uk/movie_script.php?movie=the-angry-birds-movie'}, {'title': 'The Disaster Artist (2017) - Quotes - IMDb', 'link': 'https://www.imdb.com/title/tt3521126/quotes/'}]\n",
      "\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=He do this movie, Birds. Yeah, I'm aware of the Birds. On this movie? He terrified actors. He locked them in room. He threw, he threw birds at them. Real Birds. Nasty stop. The actors, they cry every day. This movie, when every award is Mr. Hitchcock Bad Man? No, he's great director. with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://www.springfieldspringfield.co.uk/movie_script.php?movie=the-angry-birds-movie with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=And we're also willing to give it to you at a reduced rate if you decide to shoot here in our studio. What do you think? We shoot here. Yeah. We want to be in business with you, Tom. OK. We make American movie with the American discount. All right. OK. That's the deal. with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://translate.google.co.uk/ with wait_time=10s\n",
      "Found 3 relevant links:\n",
      "[{'title': 'It was like wake up call you c', 'link': \"https://www.bing.com/search?q=It was like wake up call you could say. Yeah, definitely. After that, I stopped doing all the other things. And I go back to my dream. And everybody say, you're such crazy guys. You're such a stupid guy. I said, I don't care. I do it. Yes. And now I can do it. It's bullshit. I did not hit her. I did not.\"}, {'title': 'Memorable Quotes from Cowboy Bebop', 'link': 'https://cowboybebop.fandom.com/wiki/Memorable_Quotes_from_Cowboy_Bebop'}, {'title': '[Serious] What was your wake up call? And what did you do/how ‚Ä¶', 'link': 'https://www.reddit.com/r/AskReddit/comments/w3yg3a/serious_what_was_your_wake_up_call_and_what_did/'}]\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=It was like wake up call you could say. Yeah, definitely. After that, I stopped doing all the other things. And I go back to my dream. And everybody say, you're such crazy guys. You're such a stupid guy. I said, I don't care. I do it. Yes. And now I can do it. It's bullshit. I did not hit her. I did not. with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://cowboybebop.fandom.com/wiki/Memorable_Quotes_from_Cowboy_Bebop with wait_time=10s\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=And we're also willing to give it to you at a reduced rate if you decide to shoot here in our studio. What do you think? We shoot here. Yeah. We want to be in business with you, Tom. OK. We make American movie with the American discount. All right. OK. That's the deal.:\n",
      "Nov 6, 2024¬†¬∑ You want to strike the right balance between being persuasive and professional, while also making it clear what value you‚Äôre providing. That‚Äôs where this guide comes in. ‚Ä¶\n",
      "Feb 27, 2025¬†¬∑ Below are seven distinct, detailed templates for a price reduction letter to customers. You can customize each template‚Äôs specifics‚Äîsuch as names, dates, pricing ‚Ä¶\n",
      "Nov 20, 2018¬†¬∑ Whether you are a salesperson, customer service representative, or simply want to express your professional demeanor, th...\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=He do this movie, Birds. Yeah, I'm aware of the Birds. On this movie? He terrified actors. He locked them in room. He threw, he threw birds at them. Real Birds. Nasty stop. The actors, they cry every day. This movie, when every award is Mr. Hitchcock Bad Man? No, he's great director.:\n",
      "The Disaster Artist clip with quote Yeah, I'm aware of The Birds. Yarn is the best search for video clips by quote. Find the exact moment in a TV show, movie, or music video you want to share. Easily move forward or backward to get to the ‚Ä¶\n",
      "Type any quote, watch the scenes. Search millions of movie clips for language learning and cinema research.\n",
      "Academy Awards, USA\n",
      "Nominations: 1\n",
      "Screen Actors Guild Awards\n",
      "Nominations: 1\n",
      "Golden Globes, USA\n",
      "Wins: 1 ¬∑ Nominations: 2...\n",
      "‚úÖ Crawled content from https://translate.google.co.uk/:\n",
      "Enter a URL...\n",
      "‚úÖ Crawled content from https://www.springfieldspringfield.co.uk/movie_script.php?movie=the-angry-birds-movie:\n",
      "...\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=It was like wake up call you could say. Yeah, definitely. After that, I stopped doing all the other things. And I go back to my dream. And everybody say, you're such crazy guys. You're such a stupid guy. I said, I don't care. I do it. Yes. And now I can do it. It's bullshit. I did not hit her. I did not.:\n",
      "The Matrix: Directed by Lana Wachowski, Lilly Wachowski. With Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving. When a beautiful stranger leads computer hacker Neo to a forbidding underworld, he discovers ‚Ä¶\n",
      "This page contains a collection of memorable quotes from every session of Cowboy Bebop Plus the feature movie. All quotes are categorized by Session.\n",
      "Dazed and Confused: Directed by Richard Linklater. With Jason London, Joey Lauren Adams, Milla Jovovich, Shawn Andrews. The adv...\n",
      "https://www.bing.com/search?q=Spoken towards the end of the audio recording in a discussion about film directors and films' production stories, highlighting both criticism and praise about Hitchcock's work methods and reputation.\n",
      "https://www.bing.com/search?q=Spoken during a negotiation scene about film production equipment and shooting location, likely mid-recording. Topic involves business and film industry commitments and agreements.\n",
      "‚úÖ Crawled content from https://cowboybebop.fandom.com/wiki/Memorable_Quotes_from_Cowboy_Bebop:\n",
      "This page contains a collection of memorable quotes from every session of Cowboy Bebop Plus the feature movie. All quotes are categorized by Session.\n",
      "This is a modal window.\n",
      "Beginning of dialog window. Escape will cancel and close the window.\n",
      "End of dialog window.\n",
      "[As written in the titles with the original grammatical errors]\n",
      "\"Once upon a time, in New York City in 1941....\n",
      "At this club open to all comers to play, Night after night\n",
      "at a club named \"MINSTONS PLAY HOUSE\" in Harlem,\n",
      "they play jazz ...\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"017683777b7f58492c5defbca796a630\", element=\"f.44CA8128D3456E87E687C5A518FA34D1.d.1AC2AED27DD2A32DC00A16EBADCE4520.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"017683777b7f58492c5defbca796a630\", element=\"f.44CA8128D3456E87E687C5A518FA34D1.d.1AC2AED27DD2A32DC00A16EBADCE4520.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"017683777b7f58492c5defbca796a630\", element=\"f.44CA8128D3456E87E687C5A518FA34D1.d.1AC2AED27DD2A32DC00A16EBADCE4520.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"017683777b7f58492c5defbca796a630\", element=\"f.44CA8128D3456E87E687C5A518FA34D1.d.1AC2AED27DD2A32DC00A16EBADCE4520.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"017683777b7f58492c5defbca796a630\", element=\"f.44CA8128D3456E87E687C5A518FA34D1.d.1AC2AED27DD2A32DC00A16EBADCE4520.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"017683777b7f58492c5defbca796a630\", element=\"f.44CA8128D3456E87E687C5A518FA34D1.d.1AC2AED27DD2A32DC00A16EBADCE4520.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"017683777b7f58492c5defbca796a630\", element=\"f.44CA8128D3456E87E687C5A518FA34D1.d.1AC2AED27DD2A32DC00A16EBADCE4520.e.27\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"017683777b7f58492c5defbca796a630\", element=\"f.44CA8128D3456E87E687C5A518FA34D1.d.1AC2AED27DD2A32DC00A16EBADCE4520.e.28\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"017683777b7f58492c5defbca796a630\", element=\"f.44CA8128D3456E87E687C5A518FA34D1.d.1AC2AED27DD2A32DC00A16EBADCE4520.e.29\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"017683777b7f58492c5defbca796a630\", element=\"f.44CA8128D3456E87E687C5A518FA34D1.d.1AC2AED27DD2A32DC00A16EBADCE4520.e.30\")>]\n",
      "Analysis of Negotiation Scenes From Movie ‚ÄúJobs (2013\n",
      "https://www.bing.com/ck/a?!&&p=004e6090f78849b9a9c096a67fec1b6a14fd43d2fd0bd8e5fc8da8988a73327bJmltdHM9MTc1Mjk0Nzc2Ng&ptn=3&fclid=a45ec1ad-64c9-11f0-aae7-59a5d3807c74&ntb=1&u=a1L3ZpZGVvcy9yaXZlcnZpZXcvcmVsYXRlZHZpZGVvP3E9U3Bva2VuK2R1cmluZythK25lZ290aWF0aW9uK3NjZW5lK2Fib3V0K2ZpbG0rcHJvZHVjdGlvbitlcXVpcG1lbnQrYW5kK3Nob290aW5nK2xvY2F0aW9uJTJjK2xpa2VseSttaWQtcmVjb3JkaW5nLitUb3BpYytpbnZvbHZlcytidXNpbmVzcythbmQrZmlsbStpbmR1c3RyeStjb21taXRtZW50cythbmQrYWdyZWVtZW50cy4mcnU9JTJmc2VhcmNoJTNmcSUzZFNwb2tlbiUyNTIwZHVyaW5nJTI1MjBhJTI1MjBuZWdvdGlhdGlvbiUyNTIwc2NlbmUlMjUyMGFib3V0JTI1MjBmaWxtJTI1MjBwcm9kdWN0aW9uJTI1MjBlcXVpcG1lbnQlMjUyMGFuZCUyNTIwc2hvb3RpbmclMjUyMGxvY2F0aW9uJTJjJTI1MjBsaWtlbHklMjUyMG1pZC1yZWNvcmRpbmcuJTI1MjBUb3BpYyUyNTIwaW52b2x2ZXMlMjUyMGJ1c2luZXNzJTI1MjBhbmQlMjUyMGZpbG0lMjUyMGluZHVzdHJ5JTI1MjBjb21taXRtZW50cyUyNTIwYW5kJTI1MjBhZ3JlZW1lbnRzLiZtbXNjbj12d3JjJm1pZD1BMDU1REVEMDA4N0Q0ODVERjRBNkEwNTVERUQwMDg3RDQ4NURGNEE2JkZPUk09V1JWT1JDJm50Yj0xJm1zb2NraWQ9YTQ1ZWMxYWQ2NGM5MTFmMGFhZTc1OWE1ZDM4MDdjNzQ\n",
      "Importance of Film Production Negotiation - Filmustage Blog\n",
      "https://filmustage.com/blog/mastering-negotiation-the-art-of-dealing-with-your-film-crew/\n",
      "Found 3 relevant links:\n",
      "[{'title': 'Spoken during a negotiation sc', 'link': 'https://www.bing.com/search?q=Spoken during a negotiation scene about film production equipment and shooting location, likely mid-recording. Topic involves business and film industry commitments and agreements.'}, {'title': 'Analysis of Negotiation Scenes From Movie ‚ÄúJobs (2013', 'link': 'https://www.bing.com/ck/a?!&&p=004e6090f78849b9a9c096a67fec1b6a14fd43d2fd0bd8e5fc8da8988a73327bJmltdHM9MTc1Mjk0Nzc2Ng&ptn=3&fclid=a45ec1ad-64c9-11f0-aae7-59a5d3807c74&ntb=1&u=a1L3ZpZGVvcy9yaXZlcnZpZXcvcmVsYXRlZHZpZGVvP3E9U3Bva2VuK2R1cmluZythK25lZ290aWF0aW9uK3NjZW5lK2Fib3V0K2ZpbG0rcHJvZHVjdGlvbitlcXVpcG1lbnQrYW5kK3Nob290aW5nK2xvY2F0aW9uJTJjK2xpa2VseSttaWQtcmVjb3JkaW5nLitUb3BpYytpbnZvbHZlcytidXNpbmVzcythbmQrZmlsbStpbmR1c3RyeStjb21taXRtZW50cythbmQrYWdyZWVtZW50cy4mcnU9JTJmc2VhcmNoJTNmcSUzZFNwb2tlbiUyNTIwZHVyaW5nJTI1MjBhJTI1MjBuZWdvdGlhdGlvbiUyNTIwc2NlbmUlMjUyMGFib3V0JTI1MjBmaWxtJTI1MjBwcm9kdWN0aW9uJTI1MjBlcXVpcG1lbnQlMjUyMGFuZCUyNTIwc2hvb3RpbmclMjUyMGxvY2F0aW9uJTJjJTI1MjBsaWtlbHklMjUyMG1pZC1yZWNvcmRpbmcuJTI1MjBUb3BpYyUyNTIwaW52b2x2ZXMlMjUyMGJ1c2luZXNzJTI1MjBhbmQlMjUyMGZpbG0lMjUyMGluZHVzdHJ5JTI1MjBjb21taXRtZW50cyUyNTIwYW5kJTI1MjBhZ3JlZW1lbnRzLiZtbXNjbj12d3JjJm1pZD1BMDU1REVEMDA4N0Q0ODVERjRBNkEwNTVERUQwMDg3RDQ4NURGNEE2JkZPUk09V1JWT1JDJm50Yj0xJm1zb2NraWQ9YTQ1ZWMxYWQ2NGM5MTFmMGFhZTc1OWE1ZDM4MDdjNzQ'}, {'title': 'Importance of Film Production Negotiation - Filmustage Blog', 'link': 'https://filmustage.com/blog/mastering-negotiation-the-art-of-dealing-with-your-film-crew/'}]\n",
      "https://www.bing.com/search?q=Spoken during a casual conversation or interview, around the middle of the recording, likely reflecting on a significant personal event and addressing accusations. Topic concerns personal life story and clarification against claims.\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=Spoken during a negotiation scene about film production equipment and shooting location, likely mid-recording. Topic involves business and film industry commitments and agreements. with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/ck/a?!&&p=004e6090f78849b9a9c096a67fec1b6a14fd43d2fd0bd8e5fc8da8988a73327bJmltdHM9MTc1Mjk0Nzc2Ng&ptn=3&fclid=a45ec1ad-64c9-11f0-aae7-59a5d3807c74&ntb=1&u=a1L3ZpZGVvcy9yaXZlcnZpZXcvcmVsYXRlZHZpZGVvP3E9U3Bva2VuK2R1cmluZythK25lZ290aWF0aW9uK3NjZW5lK2Fib3V0K2ZpbG0rcHJvZHVjdGlvbitlcXVpcG1lbnQrYW5kK3Nob290aW5nK2xvY2F0aW9uJTJjK2xpa2VseSttaWQtcmVjb3JkaW5nLitUb3BpYytpbnZvbHZlcytidXNpbmVzcythbmQrZmlsbStpbmR1c3RyeStjb21taXRtZW50cythbmQrYWdyZWVtZW50cy4mcnU9JTJmc2VhcmNoJTNmcSUzZFNwb2tlbiUyNTIwZHVyaW5nJTI1MjBhJTI1MjBuZWdvdGlhdGlvbiUyNTIwc2NlbmUlMjUyMGFib3V0JTI1MjBmaWxtJTI1MjBwcm9kdWN0aW9uJTI1MjBlcXVpcG1lbnQlMjUyMGFuZCUyNTIwc2hvb3RpbmclMjUyMGxvY2F0aW9uJTJjJTI1MjBsaWtlbHklMjUyMG1pZC1yZWNvcmRpbmcuJTI1MjBUb3BpYyUyNTIwaW52b2x2ZXMlMjUyMGJ1c2luZXNzJTI1MjBhbmQlMjUyMGZpbG0lMjUyMGluZHVzdHJ5JTI1MjBjb21taXRtZW50cyUyNTIwYW5kJTI1MjBhZ3JlZW1lbnRzLiZtbXNjbj12d3JjJm1pZD1BMDU1REVEMDA4N0Q0ODVERjRBNkEwNTVERUQwMDg3RDQ4NURGNEE2JkZPUk09V1JWT1JDJm50Yj0xJm1zb2NraWQ9YTQ1ZWMxYWQ2NGM5MTFmMGFhZTc1OWE1ZDM4MDdjNzQ with wait_time=10s\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"e212747c28d845cba8725ff676b7fdb9\", element=\"f.9254A1FF7848D0ABA68BD1514601063F.d.7C5268A7A0C60713FB6533050944AE90.e.15\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e212747c28d845cba8725ff676b7fdb9\", element=\"f.9254A1FF7848D0ABA68BD1514601063F.d.7C5268A7A0C60713FB6533050944AE90.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e212747c28d845cba8725ff676b7fdb9\", element=\"f.9254A1FF7848D0ABA68BD1514601063F.d.7C5268A7A0C60713FB6533050944AE90.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e212747c28d845cba8725ff676b7fdb9\", element=\"f.9254A1FF7848D0ABA68BD1514601063F.d.7C5268A7A0C60713FB6533050944AE90.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e212747c28d845cba8725ff676b7fdb9\", element=\"f.9254A1FF7848D0ABA68BD1514601063F.d.7C5268A7A0C60713FB6533050944AE90.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e212747c28d845cba8725ff676b7fdb9\", element=\"f.9254A1FF7848D0ABA68BD1514601063F.d.7C5268A7A0C60713FB6533050944AE90.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e212747c28d845cba8725ff676b7fdb9\", element=\"f.9254A1FF7848D0ABA68BD1514601063F.d.7C5268A7A0C60713FB6533050944AE90.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e212747c28d845cba8725ff676b7fdb9\", element=\"f.9254A1FF7848D0ABA68BD1514601063F.d.7C5268A7A0C60713FB6533050944AE90.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e212747c28d845cba8725ff676b7fdb9\", element=\"f.9254A1FF7848D0ABA68BD1514601063F.d.7C5268A7A0C60713FB6533050944AE90.e.27\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e212747c28d845cba8725ff676b7fdb9\", element=\"f.9254A1FF7848D0ABA68BD1514601063F.d.7C5268A7A0C60713FB6533050944AE90.e.28\")>]\n",
      "For the use of sound. Film sound analysis for audio-description: ‚Ä¶\n",
      "https://www.researchgate.net/publication/269942462_For_the_use_of_sound_Film_sound_analysis_for_audio-description_some_key_issues\n",
      "Sound Recording for Films: A Crucial Element of ‚Ä¶\n",
      "https://www.photographartdesign.com/2024/09/sound-recording-in-film-crucial-element.html\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"211fa0496b91aa05745241fbee0f5134\", element=\"f.D0F9047D43DEDDBFAFC07B13986A0918.d.A5464DF957E69117E5356FE929A33243.e.18\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"211fa0496b91aa05745241fbee0f5134\", element=\"f.D0F9047D43DEDDBFAFC07B13986A0918.d.A5464DF957E69117E5356FE929A33243.e.19\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"211fa0496b91aa05745241fbee0f5134\", element=\"f.D0F9047D43DEDDBFAFC07B13986A0918.d.A5464DF957E69117E5356FE929A33243.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"211fa0496b91aa05745241fbee0f5134\", element=\"f.D0F9047D43DEDDBFAFC07B13986A0918.d.A5464DF957E69117E5356FE929A33243.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"211fa0496b91aa05745241fbee0f5134\", element=\"f.D0F9047D43DEDDBFAFC07B13986A0918.d.A5464DF957E69117E5356FE929A33243.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"211fa0496b91aa05745241fbee0f5134\", element=\"f.D0F9047D43DEDDBFAFC07B13986A0918.d.A5464DF957E69117E5356FE929A33243.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"211fa0496b91aa05745241fbee0f5134\", element=\"f.D0F9047D43DEDDBFAFC07B13986A0918.d.A5464DF957E69117E5356FE929A33243.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"211fa0496b91aa05745241fbee0f5134\", element=\"f.D0F9047D43DEDDBFAFC07B13986A0918.d.A5464DF957E69117E5356FE929A33243.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"211fa0496b91aa05745241fbee0f5134\", element=\"f.D0F9047D43DEDDBFAFC07B13986A0918.d.A5464DF957E69117E5356FE929A33243.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"211fa0496b91aa05745241fbee0f5134\", element=\"f.D0F9047D43DEDDBFAFC07B13986A0918.d.A5464DF957E69117E5356FE929A33243.e.27\")>]\n",
      "Spontaneous Speaking Skills for Any Situation\n",
      "https://franticallyspeaking.com/spontaneous-speaking-skills-for-any-situation/\n",
      "chapter 1 Flashcards | Quizlet\n",
      "https://quizlet.com/791650046/chapter-1-flash-cards/\n",
      "Found 3 relevant links:\n",
      "[{'title': 'Spoken towards the end of the ', 'link': \"https://www.bing.com/search?q=Spoken towards the end of the audio recording in a discussion about film directors and films' production stories, highlighting both criticism and praise about Hitchcock's work methods and reputation.\"}, {'title': 'For the use of sound. Film sound analysis for audio-description: ‚Ä¶', 'link': 'https://www.researchgate.net/publication/269942462_For_the_use_of_sound_Film_sound_analysis_for_audio-description_some_key_issues'}, {'title': 'Sound Recording for Films: A Crucial Element of ‚Ä¶', 'link': 'https://www.photographartdesign.com/2024/09/sound-recording-in-film-crucial-element.html'}]\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=Spoken towards the end of the audio recording in a discussion about film directors and films' production stories, highlighting both criticism and praise about Hitchcock's work methods and reputation. with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://www.researchgate.net/publication/269942462_For_the_use_of_sound_Film_sound_analysis_for_audio-description_some_key_issues with wait_time=10s\n",
      "Found 3 relevant links:\n",
      "[{'title': 'Spoken during a casual convers', 'link': 'https://www.bing.com/search?q=Spoken during a casual conversation or interview, around the middle of the recording, likely reflecting on a significant personal event and addressing accusations. Topic concerns personal life story and clarification against claims.'}, {'title': 'Spontaneous Speaking Skills for Any Situation', 'link': 'https://franticallyspeaking.com/spontaneous-speaking-skills-for-any-situation/'}, {'title': 'chapter 1 Flashcards | Quizlet', 'link': 'https://quizlet.com/791650046/chapter-1-flash-cards/'}]\n",
      "‚úÖ Crawled content from https://www.bing.com/ck/a?!&&p=004e6090f78849b9a9c096a67fec1b6a14fd43d2fd0bd8e5fc8da8988a73327bJmltdHM9MTc1Mjk0Nzc2Ng&ptn=3&fclid=a45ec1ad-64c9-11f0-aae7-59a5d3807c74&ntb=1&u=a1L3ZpZGVvcy9yaXZlcnZpZXcvcmVsYXRlZHZpZGVvP3E9U3Bva2VuK2R1cmluZythK25lZ290aWF0aW9uK3NjZW5lK2Fib3V0K2ZpbG0rcHJvZHVjdGlvbitlcXVpcG1lbnQrYW5kK3Nob290aW5nK2xvY2F0aW9uJTJjK2xpa2VseSttaWQtcmVjb3JkaW5nLitUb3BpYytpbnZvbHZlcytidXNpbmVzcythbmQrZmlsbStpbmR1c3RyeStjb21taXRtZW50cythbmQrYWdyZWVtZW50cy4mcnU9JTJmc2VhcmNoJTNmcSUzZFNwb2tlbiUyNTIwZHVyaW5nJTI1MjBhJTI1MjBuZWdvdGlhdGlvbiUyNTIwc2NlbmUlMjUyMGFib3V0JTI1MjBmaWxtJTI1MjBwcm9kdWN0aW9uJTI1MjBlcXVpcG1lbnQlMjUyMGFuZCUyNTIwc2hvb3RpbmclMjUyMGxvY2F0aW9uJTJjJTI1MjBsaWtlbHklMjUyMG1pZC1yZWNvcmRpbmcuJTI1MjBUb3BpYyUyNTIwaW52b2x2ZXMlMjUyMGJ1c2luZXNzJTI1MjBhbmQlMjUyMGZpbG0lMjUyMGluZHVzdHJ5JTI1MjBjb21taXRtZW50cyUyNTIwYW5kJTI1MjBhZ3JlZW1lbnRzLiZtbXNjbj12d3JjJm1pZD1BMDU1REVEMDA4N0Q0ODVERjRBNkEwNTVERUQwMDg3RDQ4NURGNEE2JkZPUk09V1JWT1JDJm50Yj0xJm1zb2NraWQ9YTQ1ZWMxYWQ2NGM5MTFmMGFhZTc1OWE1ZDM4MDdjNzQ:\n",
      "Creating...\n",
      "Saving...Removing...\n",
      "Save to Saved to\n",
      "Watch later...\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=Spoken during a negotiation scene about film production equipment and shooting location, likely mid-recording. Topic involves business and film industry commitments and agreements.:\n",
      "Negotiation is a cornerstone of effective film production. Navigating diverse personalities, skills, and expectations requires finesse and understanding. Negotiating with your film crew ensures everyone is aligned with the project's goals and objectives. This ‚Ä¶ See more\n",
      "While it's crucial to resolve conflicts effectively when they arise, preventing them from occurring in the first place is even more beneficial. Here are some strategies: 1. Set clear expectations:From the beginning, clearly commu...\n",
      "‚è≥ Attempt 1: Crawling https://franticallyspeaking.com/spontaneous-speaking-skills-for-any-situation/ with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=Spoken during a casual conversation or interview, around the middle of the recording, likely reflecting on a significant personal event and addressing accusations. Topic concerns personal life story and clarification against claims. with wait_time=10s\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=Spoken towards the end of the audio recording in a discussion about film directors and films' production stories, highlighting both criticism and praise about Hitchcock's work methods and reputation.:\n",
      "Jan 1, 2012¬†¬∑ Film sound analysis for audio-description: some key issues. This article aims to outline the issues involved in the production and reception of film sound with a view to ‚Ä¶\n",
      "Film sound analysis for audio ‚Ä¶\n",
      "¬© 2008-2024 ResearchGate GmbH. All ‚Ä¶\n",
      "This paper examines the interplay between film language, sound editing, and narrative construction within cinema, using examples from various films to illustrate how sound and ‚Ä¶\n",
      "Actors often rerecord their spoken lines after shooting in a proces...\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=Spoken during a casual conversation or interview, around the middle of the recording, likely reflecting on a significant personal event and addressing accusations. Topic concerns personal life story and clarification against claims.:\n",
      "Which of the following tips should you follow to improve your nonverbal communication skills? Observe yourself on video. In addition to her attire and physical engagement during an ‚Ä¶\n",
      "Mar 14, 2025¬†¬∑ An informal interview is the art of obtaining important information through casual conversation, without a rigid structure of questions. Unlike a classic structured interview with prepared questions, an informal conversation ‚Ä¶\n",
      "nonverbal messages. consist of such things as movements, gestures, body pos...\n",
      "‚úÖ Crawled content from https://www.researchgate.net/publication/269942462_For_the_use_of_sound_Film_sound_analysis_for_audio-description_some_key_issues:\n",
      "Discover the world's research...\n",
      "‚úÖ Crawled content from https://franticallyspeaking.com/spontaneous-speaking-skills-for-any-situation/:\n",
      "Book Free Consultation\n",
      "Please enable JavaScript\n",
      "Please enable JavaScript\n",
      "Have you ever found yourself in a situation where you needed to speak on the spot, without any time to prepare? Whether it‚Äôs a job interview, a presentation at work, or even a casual conversation with friends, spontaneous speaking skills can be a valuable asset in navigating life‚Äôs unexpected moments. In this guide, we‚Äôll explore the art of spontaneous speaking and provide you with practical tips and techniques to excel in ...\n",
      "‚úÖ Finished enriching statements with articles.\n",
      "üß™ Running fact-checks on statements...\n",
      "{'start': 12.0, 'end': 33.3, 'speaker': 'Tommy', 'text': \"It was like wake up call you could say. Yeah, definitely. After that, I stopped doing all the other things. And I go back to my dream. And everybody say, you're such crazy guys. You're such a stupid guy. I said, I don't care. I do it. Yes. And now I can do it. It's bullshit. I did not hit her. I did not.\", 'reason': 'Claims a personal turning point after a car accident and denies an allegation of hitting someone, which is noteworthy for personal narrative and potential controversy.', 'context': 'Spoken during a casual conversation or interview, around the middle of the recording, likely reflecting on a significant personal event and addressing accusations. Topic concerns personal life story and clarification against claims.', 'frame_path': 'statement_frames\\\\Tommy_001200.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.49377477169036865, 'article_texts': '### It was like wake up call you c\\nThe Matrix: Directed by Lana Wachowski, Lilly Wachowski. With Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving. When a beautiful stranger leads computer hacker Neo to a forbidding underworld, he discovers ‚Ä¶\\nThis page contains a collection of memorable quotes from every session of Cowboy Bebop Plus the feature movie. All quotes are categorized by Session.\\nDazed and Confused: Directed by Richard Linklater. With Jason London, Joey Lauren Adams, Milla Jovovich, Shawn Andrews. The adventures of high school and junior high students on the last day of school in May 1976.\\n159 votes, 204 comments. 46M subscribers in the AskReddit community. r/AskReddit is the place to ask and answer thought-provoking questions.\\nQuentin Tarantino\\'s / R E S E R V O I R D O G S / October 22, 1990 / ----------------- / This movie is dedicated to these following sources of / inspiration: / TIMOTHY CAREY\\nJul 3, 2024\\xa0¬∑ If you‚Äôre talking about what you can feel, what you can smell, what you can taste and see, then real is simply electrical signals interpreted by your brain. This is the world that you know.\\nJun 5, 2025\\xa0¬∑ As far back as I can remember, I always wanted to be a gangster. Goodfellas is a 1990 film about the rise and fall of three gangsters, spanning three decades. Directed by Martin Scorsese. Written by Nicholas Pileggi and Martin ‚Ä¶\\nMemorable Quotes from Cowboy Bebop\\nThis page contains a collection of memorable quotes from every session of Cowboy Bebop Plus the feature movie. All quotes are categorized by Session.\\n\\n### Memorable Quotes from Cowboy Bebop\\nThis page contains a collection of memorable quotes from every session of Cowboy Bebop Plus the feature movie. All quotes are categorized by Session.\\nThis is a modal window.\\nBeginning of dialog window. Escape will cancel and close the window.\\nEnd of dialog window.\\n[As written in the titles with the original grammatical errors]\\n\"Once upon a time, in New York City in 1941....\\nAt this club open to all comers to play, Night after night\\nat a club named \"MINSTONS PLAY HOUSE\" in Harlem,\\nthey play jazz session competing with others. Young jazz men with new sense are gathering.\\nAt last, they created a new genre itself.\\nThey are sick and tired of conventional fixed style jazz.\\nThey eager to play jazz more freely as they wish. then...in 2071 in the universe.\\nThe bounty hunters, who are gathering in spaceship \"BEBOP\",\\nwill play freely without fear of risky things.\\nThey must create new dreams and films by breaking traditional styles.\\nThe work, which becomes a new genre itself, will be called\\nCOWBOY BEBOP\\nCharacter\\nSPIKE SPIEGEL\\nJET BLACK\\nFAYE VALENTINE\\nEDWARD WANG HWE PEPEL CYBULSKI 4th\\nEIN\\nMachinery\\nTHE BE-BOP\\nSWORDFISH II\\nHAMMERHEAD\\nREDTAIL\"\\n[Spike is eating a plate of stir-fried bell peppers that Jet made.]\\n[Antonio, Carlos and Jobim (aka The Three Old Men) are playing cards.]\\n[Spike smokes a pipe in Laughing Bull‚Äôs tent.]\\n[Laughing Bull\\'s stomach growls.]\\n[Spike is walking Ein to lure Abdul Hakim]\\n[Faye talking to a shopkeeper right before a shootout]\\n[After Faye is captured and handcuffed by the criminal casino owner, Gordon]\\n[Spike and Jet talking in a casino elevator]\\n[After Faye is captured and handcuffed by Spike and Jet]\\n[Jet and Spike talking about the bounty on Faye]\\n[Jet and Spike ordering at a restaurant]\\n[After Spike captured Twinkle Maria]\\n[After Spike captured Faye]\\n[Faye offering to help Spike chase the virus]\\n[Teaser for Ballad of Fallen Angels]\\n[Vicious and Spike face-down at the Cathedral.]\\n[Faye eats the only thing left in the refrigerator, a can of dog food, while Ein waits by his food dish.]\\n[Jet and Spike are watching a bounty target at a nightclub.]\\n[Spike, Jet, and Faye on the Bebop with the crystal ring.]\\n[V.T. comes across Spike crouching on the ground outside of the caf√© holding his thumb out.]\\n[Rocco comes at Spike with a knife and Spike sends Rocco to the ground]\\n[Stella points a gun at Spike who has trespassed onto her shuttle.]\\n[Rocco has been shot and is lying on the ground dying]\\n[to Spike, after Rocco has been shot and is lying on the ground dying]\\n[Spike visits Stella in the hospital and she learns from his silence that Rocco is dead]\\n[Faye gets mad and jams her heel into Jet\\'s foot. This is interesting foreshadowing on Faye\\'s character]\\n[Spike and Faye are getting their bounty from the ATM, Edward twirls Ein into the air.]\\n[Jet and Elisa are sitting inside La Fin.]\\n[Jet and Spike are chasing after Rhint and Elisa in their aircrafts.]\\n[Elisa is holding Jet at gunpoint, but Jet continues to walk towards her.]\\n[Jet and Elisa after the cops have detained Rhint.]\\n[Laughing Bull chants as he and his Son sit around a campfire at night. They are on a moon of Jupiter.]\\n[Laughing Bull begins to chant]\\n[The Van has granted Vicious permission to buy/sell Red Eye on Callisto with Gren.]\\n[Edward, Spike and Jet are searching for Faye after she ran away with their money.]\\n[Spike gasps dropping his cigarette and runs to Edward]\\n[Spike runs off.]\\n[Jet runs after Spike]\\n[Spike refuses to slow down.]\\n[Spike enters the shuttle port.]\\n[Faye at the Blue Crow]\\nGren: Take care. Yeah, that was a close one.\\n[Faye looks at him weird.]\\n[Gren puts his coat around Faye‚Äôs shoulders.]\\n[Laughing Bull chants as he and his Son sit around a campfire at night. They are on a moon of Jupiter.]\\n[Gate Corp CEO complaining about the complaints]\\n[The episode of Big Shot talking about Bebop\\'s bounty catches]\\n[Faye joking about their bounties]\\n[Ed explaining how the game works]\\n[A nonsensical Edwardism]\\n[Jet using a chess pun]\\n[Learning what the Gate Corp has been hiding from the public]\\n[Ed and Hex are both impressed at each other\\'s skill]\\n[Ed focused on her game of chess]\\n[Jet describing the bohemian junkheap]\\n[Jet warning about how the mastermind is seemingly leading them to him]\\n[A couple of bohemians talking at Faye]\\n[Spike and Faye realizing that Hex is not still the mastermind]\\n[Faye and Spike watching Hex play chess]\\n[Jet meeting with the Gate Corp CEO]\\n[Ed still sitting at her e-chessboard]\\n[Jonathan smoking and looking very relaxed]\\n[Hex finally beating Ed at their game]\\n[Edward talking to Ein]\\n[Spike and Jet are trying to play beta in a VHS.]\\n[Looking at the \\'Space Land\\' sign.]\\n[Aboard the Bebop]\\n[At the Masquerede Party]\\n[Aboard the Bebop]\\n[Aboard the Bebop]\\n[Spike and Jet begin laughing together]\\n[Faye points her gun at Spike\\'s head]\\n[As Spike walks away without looking back, Faye points her gun up in the air and fires five shots, then looks as if she is about to start crying.]\\n[Spike and Vicious in a standoff where Spike has Vicious\\'s katana and Vicious has Spike\\'s gun.]\\n[Spike looking up at the sky and seeing Julia with his right eye.]\\n[An injured Spike walks down the syndicate stairs the next day and comes across the remaining syndicate goons.]\\n[Spike and Elektra are held in cells next to each other.]\\n[Ending Title Card]\\n3 Comments\\nDon\\'t have account? Register now\\nThese cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.\\nThese cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.\\nThese cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.\\nThese cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.\\nThese cookies are set by a range of social media services that we have added to the site to enable you to share our content with your friends and networks. They are capable of tracking your browser across other sites and building up a profile of your interests. This may impact the content and messages you see on other websites you visit. If you do not allow these cookies you may not be able to use or see these sharing tools.\\n\\n### Spoken during a casual convers\\nWhich of the following tips should you follow to improve your nonverbal communication skills? Observe yourself on video. In addition to her attire and physical engagement during an ‚Ä¶\\nMar 14, 2025\\xa0¬∑ An informal interview is the art of obtaining important information through casual conversation, without a rigid structure of questions. Unlike a classic structured interview with prepared questions, an informal conversation ‚Ä¶\\nnonverbal messages. consist of such things as movements, gestures, body positions, vocal qualities, and a variety of unspoken signals sent by people, often in conjunction with verbal ‚Ä¶\\nTo maintain your credibility as a speaker, you should answer immediately if someone in the audience begins heckling you. t or f:The more serious your speech topic, the more formally you should dress. t or f: during a speech, ‚Ä¶\\nConversation fillers are words or expressions used to temporarily fill pauses or gaps in speech, providing speakers with time to gather their thoughts or maintain the flow of conversation.\\nJun 15, 2025\\xa0¬∑ Verbal communication is the foundation of how we express thoughts, share information, and build connections with others. From casual conversations to professional presentations, the words we choose and how ‚Ä¶\\nApr 1, 2024\\xa0¬∑ Informal conversations are an essential part of daily life. Whether you‚Äôre chatting with a friend, talking to a coworker in a relaxed setting, or even just meeting someone for the first time at a casual event, informal speech plays a ‚Ä¶\\nNov 8, 2024\\xa0¬∑ Mastering these registers can empower ESL learners to communicate more effectively and appropriately, whether in a formal job interview, a casual conversation with ‚Ä¶\\nWhether it‚Äôs responding to unexpected questions during a job interview, delivering Impromptu speeches, or starting/working at unplanned (and sudden) conversations, mastering Impromptu communication can greatly improve ‚Ä¶\\n\\n### Spontaneous Speaking Skills for Any Situation\\nBook Free Consultation\\nPlease enable JavaScript\\nPlease enable JavaScript\\nHave you ever found yourself in a situation where you needed to speak on the spot, without any time to prepare? Whether it‚Äôs a job interview, a presentation at work, or even a casual conversation with friends, spontaneous speaking skills can be a valuable asset in navigating life‚Äôs unexpected moments. In this guide, we‚Äôll explore the art of spontaneous speaking and provide you with practical tips and techniques to excel in any situation.\\nImagine being able to express yourself confidently and effectively, even when caught off guard. With the right mindset and preparation, anyone can master the art of spontaneous speaking. It‚Äôs not about memorizing scripts or delivering rehearsed lines; it‚Äôs about being adaptable, engaging, and authentic in the moment.\\nThroughout this article, we‚Äôll delve into various aspects of spontaneous speaking, from building confidence and overcoming fear to crafting compelling content on the fly.\\nSo, if you‚Äôre ready to unlock your full potential and become a more confident and effective communicator, join us as we explore the world of spontaneous speaking. Let‚Äôs embark on this journey together and discover the power of words spoken in the moment.\\n‚ÄúYou can speak well if your tongue can deliver the message of your heart.‚Äù\\nWhen you find yourself speaking spontaneously, it‚Äôs natural to feel a bit overwhelmed. But fear not! With a few simple techniques, you can craft compelling content on the fly that will captivate your audience and leave a lasting impression.\\nWhen brainstorming ideas on the fly, it‚Äôs important not to get bogged down by perfectionism. Instead, focus on quantity over quality initially. ‚ÄúFor example, if you‚Äôre asked to give an impromptu speech on the topic of creativity, jot down as many ideas as possible without censoring yourself. Once you have a list of ideas, evaluate them based on relevance and audience interest. Choose the ideas that align most closely with the context of the situation and are likely to resonate with your listeners. For instance, you might prioritize ideas that offer practical tips for fostering creativity in everyday life‚Äù.\\nStories have a unique ability to capture attention and evoke emotion. When speaking spontaneously, look for opportunities to incorporate relevant anecdotes or examples from your own experiences. ‚ÄúFor example, if you‚Äôre discussing the importance of resilience, you could share a personal story about overcoming a challenge or setback‚Äù.\\nMake sure your storytelling is concise and focused, with a clear beginning, middle, and end. Keep the emphasis on the key message or lesson you want to convey. ‚ÄúFor instance, in the context of resilience, your story might highlight the importance of perseverance and determination in the face of adversity‚Äù.\\nEven when speaking spontaneously, your delivery plays a crucial role in engaging your audience. Use dynamic body language, such as gestures and facial expressions, to convey energy and enthusiasm. ‚ÄúFor example, if you‚Äôre discussing a topic you‚Äôre passionate about, let that passion shine through in your demeanor‚Äù.\\nVary your tone and pace to keep your audience‚Äôs attention. Avoid speaking in a monotone voice or using overly formal language. Instead, strive for a conversational tone that feels natural and authentic. ‚ÄúFor instance, if you‚Äôre sharing a humorous anecdote, adjust your tone to match the lightheartedness of the story‚Äù.\\nMake eye contact with your audience to establish a connection and build rapport. Directing your gaze at individuals in the audience can make them feel personally engaged in your speech. ‚ÄúFor example, if you‚Äôre addressing a large group, scan the room and make eye contact with different people throughout your presentation‚Äù.\\nSpontaneous speaking requires flexibility and adaptability. Be prepared to adjust your content on the fly based on audience reactions and feedback. ‚ÄúFor example, if you notice that your audience is particularly interested in a certain aspect of your speech, you might choose to expand on that topic further‚Äù.\\nEmbrace unexpected challenges or changes in the situation as opportunities to showcase your adaptability. ‚ÄúFor instance, if you encounter technical difficulties during your presentation, remain calm and composed as you troubleshoot the issue‚Äù.\\nRemember that spontaneity doesn‚Äôt mean lack of preparation; it means being prepared to think on your feet and respond effectively to whatever comes your way.\\nLike any skill, spontaneous speaking improves with practice. Look for opportunities to practice impromptu speaking in your daily life, such as participating in group discussions, giving spontaneous presentations at work, or even just striking up conversations with strangers.\\nSeek feedback from peers, mentors, or trusted colleagues to help identify areas for improvement. Consider recording yourself speaking spontaneously and reviewing the footage to pinpoint areas where you can refine your delivery or organization.\\nDon‚Äôt be discouraged by mistakes or setbacks along the way. Instead, view them as valuable learning experiences that will ultimately help you become a more confident and effective spontaneous speaker.\\nMastering spontaneous speaking doesn‚Äôt happen overnight. It requires building a solid foundation rooted in confidence, adaptability, and a flexible mindset. Let‚Äôs explore the essential elements that form the bedrock of spontaneous speaking skills.\\nConfidence is like a muscle; the more you exercise it, the stronger it becomes. Start by believing in yourself and your abilities as a speaker. Remind yourself of past successes and focus on your strengths.\\nPractice speaking spontaneously in low-pressure situations to gradually build your confidence. This could be as simple as voicing your opinion in a group discussion or volunteering to give impromptu presentations.\\nEmbrace failure as a stepping stone to success. Every stumble is an opportunity to learn and grow. By reframing mistakes as learning experiences, you‚Äôll become more resilient and self-assured.\\nFear of public speaking is a common challenge, but it‚Äôs not insurmountable. Acknowledge your fears and confront them head-on. Remind yourself that nervousness is natural and can even be beneficial, as it shows you care about the outcome.\\nPractice relaxation techniques such as deep breathing or visualization to calm your nerves before speaking. Focus on the present moment and visualize yourself speaking confidently and articulately.\\nShift your mindset from fearing judgment to embracing the opportunity to connect with your audience. Instead of worrying about what others will think, focus on delivering your message authentically and passionately.\\nSpontaneous speaking requires thinking on your feet and adapting to unexpected situations. Cultivate a mindset of flexibility and openness to change. Be willing to go with the flow and adjust your approach as needed.\\nPractice improvisation exercises to sharpen your ability to think quickly and creatively.\\nEmbrace uncertainty as a catalyst for growth. Instead of seeking perfection, focus on being present in the moment and responding authentically to whatever arises. By letting go of the need for control, you‚Äôll become more comfortable with spontaneity.\\nRemember, it‚Äôs not about being flawless; it‚Äôs about being genuine, adaptable, and confident in your ability to communicate effectively in any situation.\\nPractice is the cornerstone of mastering spontaneous speaking skills. Just like athletes hone their skills through training, speakers can improve their ability to think on their feet through targeted exercises and drills. Let‚Äôs explore some practical strategies to sharpen your spontaneity and confidence in any situation.\\nRole-playing is a fun and effective way to simulate real-life speaking situations. Pair up with a friend or colleague and take turns playing different roles, such as interviewer and interviewee, or customer and service provider.\\nChoose scenarios that are relevant to your personal or professional life, such as a job interview, a sales pitch, or a networking event. This will help you practice responding spontaneously to common situations you may encounter.\\nChallenge yourself with impromptu speaking prompts to improve your ability to think quickly and articulate your thoughts under pressure. Write down a list of topics or questions on index cards and draw one at random to speak about for a minute or two.\\nKeep your responses focused and to the point, emphasizing clarity and coherence. Don‚Äôt worry about being perfect; the goal is to practice thinking on your feet and expressing yourself confidently.\\nParticipating in group discussions and debates can help you develop your ability to think critically and respond persuasively to different viewpoints. Engage in lively discussions with friends, colleagues, or fellow students on topics of mutual interest.\\nPractice active listening and respectful communication, allowing others to express their opinions while also articulating your own views clearly and convincingly. This will enhance your ability to engage in spontaneous dialogue and exchange ideas effectively.\\nConsider joining a Toastmasters club or similar speaking organization to receive structured feedback and support from fellow speakers. These clubs offer opportunities to practice impromptu speaking in a supportive environment and receive constructive criticism to help you improve.\\nParticipate in Table Topics sessions, where members are challenged to speak spontaneously on a given topic for a specified time limit. This will help you build confidence and adaptability in responding to unexpected speaking situations.\\nRecord yourself practicing spontaneous speaking and review the recordings to identify areas for improvement. Pay attention to your delivery, clarity of thought, and ability to maintain coherence under pressure.\\nSeek feedback from peers, mentors, or trusted colleagues to gain valuable insights into your strengths and weaknesses as a spontaneous speaker. Actively listen to their feedback and incorporate constructive criticism into your practice sessions.\\nBy incorporating these exercises and drills into your routine, you‚Äôll gradually build confidence, fluency, and adaptability in your spontaneous speaking skills. Remember, practice may not make perfect, but it certainly makes progress. Keep challenging yourself, pushing beyond your comfort zone, and embracing each opportunity to grow as a speaker.\\nOne of the most effective ways to learn and improve spontaneous speaking skills is by studying real-life examples of individuals who have mastered the art of speaking on the spot. Let‚Äôs delve into some inspiring success stories that highlight the power of spontaneity and adaptability in communication.\\nFew speakers are as renowned for their ability to captivate audiences as the late Apple co-founder, Steve Jobs. Known for his iconic keynote presentations, Jobs had a remarkable knack for delivering compelling speeches without the aid of scripts or teleprompters.\\nJobs‚Äô spontaneous speaking skills were on full display during his famous iPhone launch events, where he would seamlessly transition between planned demonstrations and impromptu interactions with the audience. His ability to think on his feet and respond to unexpected challenges contributed to the success of these events.\\nAs a renowned talk show host and media mogul, Oprah Winfrey has built her career on the ability to engage in authentic and spontaneous conversations with guests and audiences alike. Whether discussing personal struggles, societal issues, or moments of triumph, Oprah‚Äôs spontaneity and empathy shine through.\\nWinfrey‚Äôs ability to connect with her audience on a genuine level has earned her widespread admiration and loyalty over the years. Her skillful blend of preparedness and spontaneity serves as a testament to the power of authenticity in communication.\\nTED Talks are renowned for featuring speakers who deliver powerful, thought-provoking presentations on a wide range of topics. Many of these speakers excel at speaking spontaneously, engaging audiences with compelling stories and ideas.\\nTake, for example, Bren√© Brown‚Äôs TED Talk on vulnerability, where she speaks candidly and spontaneously about her own experiences and insights. Brown‚Äôs ability to connect with her audience through authentic storytelling has made her talk one of the most viewed TED Talks of all time.\\nExpanding your skills in spontaneous speaking doesn‚Äôt have to be a solitary journey. There are numerous resources available to support your growth and development as a confident and effective speaker. Let‚Äôs explore some additional resources that can complement your learning and provide further guidance on mastering spontaneous speaking skills.\\nBooks are a valuable source of knowledge and insight into the art of communication. Look for titles that focus on public speaking, improv techniques, or storytelling to enhance your understanding of spontaneous speaking.\\nRecommended reads include:\\nThese books offer practical tips and strategies for improving your spontaneity and confidence as a speaker.\\nOnline courses and workshops provide convenient and accessible opportunities to hone your spontaneous speaking skills from the comfort of your own home. Look for courses offered by reputable organizations or instructors with expertise in public speaking and communication.\\nPlatforms like Coursera, Udemy, and LinkedIn Learning offer a variety of courses on public speaking, impromptu speaking, and presentation skills. These courses often include video lectures, interactive exercises, and feedback from instructors to help you improve.\\nPodcasts and audiobooks are excellent resources for learning on the go and immersing yourself in the world of public speaking and communication. Listen to podcasts hosted by expert speakers and communication coaches for valuable insights and advice.\\nCheck out podcasts like\\nAudiobooks such as ‚ÄúSpeak Like Churchill, Stand Like Lincoln: 21 Powerful Secrets of History‚Äôs Greatest Speakers‚Äù by James C. Humes can also provide valuable lessons in effective communication.\\nJoining online communities and forums dedicated to public speaking and communication can provide valuable support, feedback, and networking opportunities. Engage with fellow speakers, share experiences, and learn from each other‚Äôs successes and challenges.\\nPlatforms like Reddit‚Äôs r/PublicSpeaking and LinkedIn groups such as Public Speaking & Presentation Skills offer spaces for speakers to connect, ask questions, and share resources. Participating in discussions and seeking advice from experienced speakers can help you grow as a communicator.\\nConsider seeking out a public speaking coach or mentor who can provide personalized guidance and feedback on your spontaneous speaking skills. A coach can offer constructive criticism, tailored exercises, and accountability to help you reach your speaking goals.\\nLook for coaches with experience in spontaneous speaking, improv theater, or storytelling. Many coaches offer individual coaching sessions, workshops, or group programs designed to support speakers at all levels of experience.\\nBy leveraging these resources, you can continue to strengthen your spontaneous speaking skills and become a more confident and compelling communicator in any situation.\\nAs we wrap up our exploration of spontaneous speaking skills, it‚Äôs clear that the ability to communicate confidently and effectively in any situation is a valuable asset. Whether you‚Äôre delivering a presentation at work, engaging in a casual conversation with friends, or facing unexpected challenges, mastering spontaneity in communication can open doors and empower you to connect with others on a deeper level.\\nBut mastering spontaneous speaking is an ongoing process that requires dedication, practice, and guidance. That‚Äôs why we invite you to consider exploring our communication coaching services. Our experienced coaches are here to provide personalized support, tailored feedback, and proven strategies to help you unlock your full potential as a speaker.\\nSo why wait? Take the next step toward becoming a more confident and effective speaker by checking out our communication coaching today click here. With the right guidance and support, you can transform your spontaneous speaking skills and unlock new opportunities for success in every area of your life.\\nSchedule a call with our expert communication coach to know if this program would be the right fit for you\\nCopyright ¬© 2023 Frantically Speaking All rights reserved\\nPlease enable JavaScript'}\n",
      "üßê Fact-checking: It was like wake up call you could say. Yeah, definitely. After that, I stopped ...\n",
      "{'start': 116.8, 'end': 133.8, 'speaker': 'Bill', 'text': \"And we're also willing to give it to you at a reduced rate if you decide to shoot here in our studio. What do you think? We shoot here. Yeah. We want to be in business with you, Tom. OK. We make American movie with the American discount. All right. OK. That's the deal.\", 'reason': 'Makes a factual claim about business terms to produce a film including a discounted offer, which can be verified.', 'context': 'Spoken during a negotiation scene about film production equipment and shooting location, likely mid-recording. Topic involves business and film industry commitments and agreements.', 'frame_path': 'statement_frames\\\\Bill_011680.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.3865134119987488, 'article_texts': '### And we\\'re also willing to give\\nNov 6, 2024\\xa0¬∑ You want to strike the right balance between being persuasive and professional, while also making it clear what value you‚Äôre providing. That‚Äôs where this guide comes in. ‚Ä¶\\nFeb 27, 2025\\xa0¬∑ Below are seven distinct, detailed templates for a price reduction letter to customers. You can customize each template‚Äôs specifics‚Äîsuch as names, dates, pricing ‚Ä¶\\nNov 20, 2018\\xa0¬∑ Whether you are a salesperson, customer service representative, or simply want to express your professional demeanor, this guide will provide you with a range of formal and ‚Ä¶\\nFeb 1, 2022\\xa0¬∑ This blog article will address when and how to offering a discount to customer, as well as some sample emails and phrases.\\nMar 21, 2025\\xa0¬∑ Quoting your price to a potential client can be challenging, especially when they push for additional discounts. You want to be polite yet assertive about your pricing. Knowing how to say, ‚ÄúThis is the best price we ‚Ä¶\\nTo write a discount offer email, start with a clear subject line showing how much the discount is and personalize the email content. Read on for details!\\nDec 20, 2024\\xa0¬∑ The examples shared here, along with each email for giving discount to customer sample, offer a starting point for crafting your unique messages. Tailor these ideas to fit your brand voice and customer needs, and ‚Ä¶\\n\\n### Google Translate\\nEnter a URL\\n\\n### Spoken during a negotiation sc\\nNegotiation is a cornerstone of effective film production. Navigating diverse personalities, skills, and expectations requires finesse and understanding. Negotiating with your film crew ensures everyone is aligned with the project\\'s goals and objectives. This ‚Ä¶ See more\\nWhile it\\'s crucial to resolve conflicts effectively when they arise, preventing them from occurring in the first place is even more beneficial. Here are some strategies: 1. Set clear expectations:From the beginning, clearly communicate your expectations ‚Ä¶ See more\\nConsider the movie \"Moonlight\" (2016), directed by Barry Jenkins. Despite operating on a shoestring budget, the film turned out to be a critically acclaimed masterpiece that won ‚Ä¶ See more\\nSuccessful negotiation is not a matter of winning or losing but creating an environment where everyone feels heard and valued. Here are some crucial soft skills to foster ‚Ä¶ See more\\nTo successfully negotiate with your film crew, it\\'s essential to approach each situation with empathy and understanding. Transparency is key ‚Äì be clear about your expectations and ‚Ä¶ See more\\nMay 7, 2024\\xa0¬∑ Discover the secrets to successful location shooting with our comprehensive guide. From sourcing the perfect film shoot location to overcoming challenges like weather and sound ‚Ä¶\\nAug 8, 2017\\xa0¬∑ Knowing how to speak the language of production will help you prove your experience on a film set ‚Äì even if you‚Äôre still a little green. Some production terms are more ‚Ä¶\\nNov 21, 2024\\xa0¬∑ Logistics play an essential behind-the-scenes role in ensuring that production runs efficiently, minimizing delays, and preventing costly disruptions. Here‚Äôs a look at how logistics shape film production and the transport of ‚Ä¶\\nWe‚Äôre here to guide you through key clauses, negotiation tips, and common pitfalls to avoid. So whether you‚Äôre a seasoned pro or new to the scene, you‚Äôll be equipped to handle the legal side of storytelling with confidence.\\nFeb 1, 2025\\xa0¬∑ Our list of 100+ video production terms covers simple camera movements like dolly shots and tracking shots, and technical concepts like frame rates and audio mixing. Each definition uses straightforward language that ‚Ä¶\\n\\n### Analysis of Negotiation Scenes From Movie ‚ÄúJobs (2013\\nCreating...\\nSaving...Removing...\\nSave to Saved to\\nWatch later'}\n",
      "üßê Fact-checking: And we're also willing to give it to you at a reduced rate if you decide to shoo...\n",
      "{'start': 268.8, 'end': 287.8, 'speaker': 'Tommy', 'text': \"He do this movie, Birds. Yeah, I'm aware of the Birds. On this movie? He terrified actors. He locked them in room. He threw, he threw birds at them. Real Birds. Nasty stop. The actors, they cry every day. This movie, when every award is Mr. Hitchcock Bad Man? No, he's great director.\", 'reason': 'Describes factual and controversial allegations about Alfred Hitchcock\\'s directing methods during the making of \"The Birds,\" which are notable claims about historical events in film.', 'context': \"Spoken towards the end of the audio recording in a discussion about film directors and films' production stories, highlighting both criticism and praise about Hitchcock's work methods and reputation.\", 'frame_path': 'statement_frames\\\\Tommy_026880.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.4636234641075134, 'article_texts': \"### He do this movie, Birds. Yeah,\\nThe Disaster Artist clip with quote Yeah, I'm aware of The Birds. Yarn is the best search for video clips by quote. Find the exact moment in a TV show, movie, or music video you want to share. Easily move forward or backward to get to the ‚Ä¶\\nType any quote, watch the scenes. Search millions of movie clips for language learning and cinema research.\\nAcademy Awards, USA\\nNominations: 1\\nScreen Actors Guild Awards\\nNominations: 1\\nGolden Globes, USA\\nWins: 1 ¬∑ Nominations: 2\\n\\n### Spoken towards the end of the \\nJan 1, 2012\\xa0¬∑ Film sound analysis for audio-description: some key issues. This article aims to outline the issues involved in the production and reception of film sound with a view to ‚Ä¶\\nFilm sound analysis for audio ‚Ä¶\\n¬© 2008-2024 ResearchGate GmbH. All ‚Ä¶\\nThis paper examines the interplay between film language, sound editing, and narrative construction within cinema, using examples from various films to illustrate how sound and ‚Ä¶\\nActors often rerecord their spoken lines after shooting in a process known as ______. Combining sounds into a complete audio tapestry is known as ______. Altering sound so that it is slightly ‚Ä¶\\nSound recording is a fundamental aspect of filmmaking that significantly contributes to the overall cinematic experience. It is the process of capturing and recording audio elements that complement the on-screen visuals.\\nThe job of a Foley artist is to A. establish an overall audio strategy for a film. B. establish on-set sound quality. C. add sound effects during postproduction. D. ‚Ä¶\\nJan 23, 2025\\xa0¬∑ A look at post production audio workflows, departments and methods, and how they contribute to form the perfect soundtrack. Audio post production is laborious and time-consuming. To the uninspired it is also ‚Ä¶\\n\\n### For the use of sound. Film sound analysis for audio-description: ‚Ä¶\\nDiscover the world's research\"}\n",
      "üßê Fact-checking: He do this movie, Birds. Yeah, I'm aware of the Birds. On this movie? He terrifi...\n",
      "‚úÖ All statements are supported or unverified.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\577.mp4\n",
      "Deepfake label: REAL, Fact-check label: True\n",
      "üíæ Saved checkpoint after 578 videos\n",
      "üìº Processing video 579: ../data/dfw_youtube_release\\578.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\578.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_02...\n",
      "‚úÖ SPEAKER_02 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_03...\n",
      "‚úÖ SPEAKER_03 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-2.60] Unknown: No, I'm gonna shut it. Hey, you don't touch that, I don't-\n",
      "[2.60-4.40] SPEAKER_02: Football?\n",
      "[4.40-9.00] Unknown: You wanna watch football? Hey, it's the bear show!\n",
      "[9.00-12.20] SPEAKER_02: Yeah, look at that! I don't, don't just leave it. Leave it on football.\n",
      "[12.20-14.20] Unknown: Hey, I told you leave that alone.\n",
      "[14.20-16.20] SPEAKER_02: Never ever static me.\n",
      "[16.20-23.40] Unknown: You guys are good actors, are you? Come on, cut it out, it's a playoffs! Hey. Cut it out. The keys, brother, the mother.\n",
      "[23.40-25.40] SPEAKER_02: The snuggly, so freshen up.\n",
      "[25.40-28.40] Unknown: You dick. Cut it out. Hit it again.\n",
      "[28.40-31.40] SPEAKER_02: No, no. Yeah? Hit it again.\n",
      "[31.40-38.40] Unknown: All right. Tell you I know what I'm doing. What for me? Damn, you won again.\n",
      "[38.40-39.40] SPEAKER_02: I told you I can play.\n",
      "[39.40-42.40] Unknown: Now listen, I've been thinking about this daddy business.\n",
      "[42.40-45.40] SPEAKER_02: Here's my thoughts. I want you to be my daddy.\n",
      "[45.40-49.40] Unknown: And I'll tell mommy about it. We're gonna go see daddy today.\n",
      "[49.40-52.40] SPEAKER_00: Oh, great, I was just thinking about James.\n",
      "[52.40-55.40] Unknown: You have to look fantastic. What do you think?\n",
      "[55.40-56.40] SPEAKER_00: The blue or the land?\n",
      "[56.40-59.40] SPEAKER_02: Well neither, they both look pretty lame. What do you think?\n",
      "[59.40-62.40] SPEAKER_00: Hey, a fella. What you're doing, huh?\n",
      "[62.40-63.40] Unknown: What you're doing?\n",
      "[63.40-68.40] SPEAKER_02: Are you a hazard label? How about a little milk right in your eye there?\n",
      "[68.40-69.40] Unknown: Get it?\n",
      "[69.40-70.40] SPEAKER_02: Bulls eye.\n",
      "[70.40-74.40] Unknown: Hey, Mikey! Hey, Sarah, hey, how you doing?\n",
      "[74.40-77.40] SPEAKER_02: Hey, come over here, man. I want to talk to you. Where you going?\n",
      "[77.40-83.40] SPEAKER_03: I'm on the run. Gotta go. Yeah, right back at you, babe.\n",
      "[83.40-85.40] SPEAKER_02: Good to see you. Hi, Mikey.\n",
      "[85.40-87.40] SPEAKER_03: Oh, is that a new hatter?\n",
      "[87.40-90.40] SPEAKER_02: It's a time to change the bandage.\n",
      "[90.40-94.40] Unknown: How many babies does it take to screw in a light bulb? How many?\n",
      "[94.40-97.40] SPEAKER_03: What's the light bulb?\n",
      "[97.40-105.40] Unknown: I don't get it. Hey, where's she going?\n",
      "[105.40-108.40] SPEAKER_02: Who's that big guy?\n",
      "[108.40-109.40] Unknown: Who is it?\n",
      "[109.40-116.40] SPEAKER_03: Well, that's okay. That's her daddy. She's gonna go with her daddy, you know, with the daddy. Well, what's her daddy?\n",
      "[116.40-122.40] Unknown: What do they do? Well, you know the big men types and they hang around with the mommies?\n",
      "[122.40-123.40] SPEAKER_03: The mommies.\n",
      "[123.40-127.40] SPEAKER_02: I get it. Well, maybe I'll ask James to be my daddy.\n",
      "[127.40-128.40] Unknown: Mikey, no, no, don't do that.\n",
      "[128.40-131.40] SPEAKER_02: What I do?\n",
      "[131.40-135.40] Unknown: Molly, people find themselves in situations\n",
      "[135.40-143.40] SPEAKER_00: that they don't always have the strength to get out of. What are you trying to say? Mike, mommy said don't touch that. Well, all right.\n",
      "[143.40-148.40] Unknown: Fuck. Come on, come on, dad.\n",
      "[148.40-150.40] SPEAKER_01: Let's go, let's go.\n",
      "[150.40-159.40] Unknown: Stay, stay, go to the body, go to the body. Oh, oh. You're all cleaned up.\n",
      "[159.40-163.40] SPEAKER_01: Hey, hey, why don't you use the washroom in the back, Molly?\n",
      "[163.40-167.40] Unknown: Well, Mike gonna tell him when he asked about his daddy.\n",
      "[167.40-170.40] SPEAKER_01: Oh, no, not him. I want James to be the daddy.\n",
      "[170.40-171.40] SPEAKER_02: Don't do that.\n",
      "[171.40-176.40] SPEAKER_00: Here, that's a $10,000 desk.\n",
      "[176.40-178.40] Unknown: Hi, Tutsk.\n",
      "[178.40-182.40] SPEAKER_02: Which one of you, James, wants to help me find my dad? That's Ida's grandson.\n",
      "[182.40-184.40] SPEAKER_00: Come on, come on, I'm in a hurry here.\n",
      "[184.40-192.40] SPEAKER_02: I just saw the yellow box go by. All right, I'm on the case now.\n",
      "[192.40-201.40] Unknown: Oh, now that is exactly what I need. This looks like a good place to spot him. Mikey!\n",
      "[201.40-204.40] SPEAKER_01: Mikey, stop!\n",
      "[204.40-208.40] Unknown: Hey, James, is that you? Mikey, come on, move.\n",
      "[208.40-211.40] SPEAKER_01: Hey, James, mommy.\n",
      "[211.40-216.40] Unknown: Here I come. Mikey!\n",
      "[216.40-219.40] SPEAKER_01: I'm coming, I'm coming.\n",
      "[219.40-229.40] Unknown: Whoa! Oh, James, you see what just happened?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 checkworthy statements.\n",
      "[{'start': 135.4, 'end': 143.4, 'speaker': 'SPEAKER_00', 'text': \"that they don't always have the strength to get out of. What are you trying to say? Mike, mommy said don't touch that. Well, all right.\", 'reason': \"Claims about people's situations and strength to change them, implying social or personal challenges worth verifying.\", 'context': 'Dialogue in a dramatic or narrative context, discussing personal or family struggles, roughly around 2:15 minutes into the conversation; the topic revolves around family dynamics and personal difficulties.', 'frame_path': 'statement_frames\\\\SPEAKER_00_013540.jpg'}, {'start': 176.4, 'end': 178.4, 'speaker': 'SPEAKER_00', 'text': \"Here, that's a $10,000 desk.\", 'reason': 'Makes a specific monetary claim about the value of an item, which can be verified.', 'context': 'Likely a narrative or dramatic scene discussing possessions or wealth, occurring around 2:56 minutes; possibly part of a family or social situation conversation.', 'frame_path': 'statement_frames\\\\SPEAKER_00_017640.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\578\\clip_1.mp4 from 135.40s to 143.40s\n",
      "‚úÇÔ∏è Cutting statement_clips\\578\\clip_2.mp4 from 176.40s to 178.40s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\578\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['ed94645adb4d46de83d042b99cb6f178_clip_1.mp4'], 'pred': [0.5390627980232239], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['a591ece576a94ba2ba47c132b236c943_clip_2.mp4'], 'pred': [0.6607994437217712], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 135.4, 'end': 143.4, 'speaker': 'SPEAKER_00', 'text': \"that they don't always have the strength to get out of. What are you trying to say? Mike, mommy said don't touch that. Well, all right.\", 'reason': \"Claims about people's situations and strength to change them, implying social or personal challenges worth verifying.\", 'context': 'Dialogue in a dramatic or narrative context, discussing personal or family struggles, roughly around 2:15 minutes into the conversation; the topic revolves around family dynamics and personal difficulties.', 'frame_path': 'statement_frames\\\\SPEAKER_00_013540.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5390627980232239}, {'start': 176.4, 'end': 178.4, 'speaker': 'SPEAKER_00', 'text': \"Here, that's a $10,000 desk.\", 'reason': 'Makes a specific monetary claim about the value of an item, which can be verified.', 'context': 'Likely a narrative or dramatic scene discussing possessions or wealth, occurring around 2:56 minutes; possibly part of a family or social situation conversation.', 'frame_path': 'statement_frames\\\\SPEAKER_00_017640.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.6607994437217712}]\n",
      "‚ö†Ô∏è Statement that they don't always have the strength to get out of. What are you trying to say? Mike, mommy said don't touch that. Well, all right. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\578.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 579 videos\n",
      "üìº Processing video 580: ../data/dfw_youtube_release\\579.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\579.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-84.00] Unknown: You still don't know who I am, do you? Who are you? Who are you? And I Who are you? So are you two love or you and I Who are you?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 84.0, 'speaker': 'Unknown', 'text': \"You still don't know who I am, do you? Who are you? Who are you? And I Who are you? So are you two love or you and I Who are you?\", 'reason': 'The statement is incoherent and does not contain verifiable factual claims or clear checkworthy information.', 'context': 'Unknown speaker, possibly from a recorded video or audio segment, no clear topic or event identifiable due to fragmented and unclear language.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\579\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\579.mp4, 2764800 bytes wanted but 0 bytes read,at frame 2560/2561, at time 106.67/106.67 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['5d4d763c36ac4822bd81bc70eef0cbc8_clip_1.mp4'], 'pred': [0.6638310551643372], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 84.0, 'speaker': 'Unknown', 'text': \"You still don't know who I am, do you? Who are you? Who are you? And I Who are you? So are you two love or you and I Who are you?\", 'reason': 'The statement is incoherent and does not contain verifiable factual claims or clear checkworthy information.', 'context': 'Unknown speaker, possibly from a recorded video or audio segment, no clear topic or event identifiable due to fragmented and unclear language.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.6638310551643372}]\n",
      "‚ö†Ô∏è Statement You still don't know who I am, do you? Who are you? Who are you? And I Who are you? So are you two love or you and I Who are you? is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\579.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 580 videos\n",
      "üìº Processing video 581: ../data/dfw_youtube_release\\580.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\580.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_02...\n",
      "‚úÖ SPEAKER_02 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-126.16] Unknown: MUSIC You may think this can't be probably right Luck gets in the woods on Halloween night\n",
      "[126.16-127.36] SPEAKER_02: Trick or Treat!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 126.16, 'speaker': 'Unknown', 'text': \"MUSIC You may think this can't be probably right Luck gets in the woods on Halloween night\", 'reason': 'The statement is a poetic or lyrical claim possibly implying a superstition or belief associated with Halloween night, which is a cultural/historical topic worth verifying in terms of origins or beliefs.', 'context': 'This statement was made by an unknown speaker during an event involving music, likely a Halloween-related performance or recording, around Halloween time. The topic is cultural beliefs or superstitions related to Halloween.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\580\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\580.mp4, 2764800 bytes wanted but 0 bytes read,at frame 3582/3583, at time 149.25/149.26 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['2c2f7d8339da4a8e9888d39d323a90e5_clip_1.mp4'], 'pred': [0.4095720052719116], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 126.16, 'speaker': 'Unknown', 'text': \"MUSIC You may think this can't be probably right Luck gets in the woods on Halloween night\", 'reason': 'The statement is a poetic or lyrical claim possibly implying a superstition or belief associated with Halloween night, which is a cultural/historical topic worth verifying in terms of origins or beliefs.', 'context': 'This statement was made by an unknown speaker during an event involving music, likely a Halloween-related performance or recording, around Halloween time. The topic is cultural beliefs or superstitions related to Halloween.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.4095720052719116}]\n",
      "üì∞ Enriching statements with articles...\n",
      "https://www.bing.com/search?q=MUSIC You may think this can't be probably right Luck gets in the woods on Halloween night\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"bc3a0829822420792cefa4f5ecf15e53\", element=\"f.55E2A061750C7D021180B2D87C695664.d.6D452D6888002F66B2C23A094FBC0A2E.e.15\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"bc3a0829822420792cefa4f5ecf15e53\", element=\"f.55E2A061750C7D021180B2D87C695664.d.6D452D6888002F66B2C23A094FBC0A2E.e.16\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"bc3a0829822420792cefa4f5ecf15e53\", element=\"f.55E2A061750C7D021180B2D87C695664.d.6D452D6888002F66B2C23A094FBC0A2E.e.17\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"bc3a0829822420792cefa4f5ecf15e53\", element=\"f.55E2A061750C7D021180B2D87C695664.d.6D452D6888002F66B2C23A094FBC0A2E.e.18\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"bc3a0829822420792cefa4f5ecf15e53\", element=\"f.55E2A061750C7D021180B2D87C695664.d.6D452D6888002F66B2C23A094FBC0A2E.e.19\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"bc3a0829822420792cefa4f5ecf15e53\", element=\"f.55E2A061750C7D021180B2D87C695664.d.6D452D6888002F66B2C23A094FBC0A2E.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"bc3a0829822420792cefa4f5ecf15e53\", element=\"f.55E2A061750C7D021180B2D87C695664.d.6D452D6888002F66B2C23A094FBC0A2E.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"bc3a0829822420792cefa4f5ecf15e53\", element=\"f.55E2A061750C7D021180B2D87C695664.d.6D452D6888002F66B2C23A094FBC0A2E.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"bc3a0829822420792cefa4f5ecf15e53\", element=\"f.55E2A061750C7D021180B2D87C695664.d.6D452D6888002F66B2C23A094FBC0A2E.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"bc3a0829822420792cefa4f5ecf15e53\", element=\"f.55E2A061750C7D021180B2D87C695664.d.6D452D6888002F66B2C23A094FBC0A2E.e.24\")>]\n",
      "Lloyd Banks ‚Äì Halloween Intro Lyrics | Genius Lyrics\n",
      "https://genius.com/Lloyd-banks-halloween-intro-lyrics\n",
      "Billy Joel - You May Be Right (Official Audio) - YouTube\n",
      "https://www.bing.com/ck/a?!&&p=2d4da88f8ba97073260ea7e82bfc25c2739b0addefdd38c6059969a3d09b0ea1JmltdHM9MTc1Mjk0OTAzOA&ptn=3&fclid=9a802f1f-64cc-11f0-9f7e-6a36e38416dd&ntb=1&u=a1L3ZpZGVvcy9yaXZlcnZpZXcvcmVsYXRlZHZpZGVvP3E9TVVTSUMrWW91K21heSt0aGluayt0aGlzK2NhbiUyN3QrYmUrcHJvYmFibHkrcmlnaHQrTHVjaytnZXRzK2luK3RoZSt3b29kcytvbitIYWxsb3dlZW4rbmlnaHQmcnU9JTJmc2VhcmNoJTNmcSUzZE1VU0lDJTI1MjBZb3UlMjUyMG1heSUyNTIwdGhpbmslMjUyMHRoaXMlMjUyMGNhbiUyNTI3dCUyNTIwYmUlMjUyMHByb2JhYmx5JTI1MjByaWdodCUyNTIwTHVjayUyNTIwZ2V0cyUyNTIwaW4lMjUyMHRoZSUyNTIwd29vZHMlMjUyMG9uJTI1MjBIYWxsb3dlZW4lMjUyMG5pZ2h0Jm1tc2NuPXZ3cmMmbWlkPTdBOTJGNzg3MEEwNDNBMjUwRTg5N0E5MkY3ODcwQTA0M0EyNTBFODkmRk9STT1XUlZPUkMmbnRiPTEmbXNvY2tpZD05YTgwMmYxZjY0Y2MxMWYwOWY3ZTZhMzZlMzg0MTZkZA\n",
      "Found 3 relevant links:\n",
      "[{'title': \"MUSIC You may think this can't\", 'link': \"https://www.bing.com/search?q=MUSIC You may think this can't be probably right Luck gets in the woods on Halloween night\"}, {'title': 'Lloyd Banks ‚Äì Halloween Intro Lyrics | Genius Lyrics', 'link': 'https://genius.com/Lloyd-banks-halloween-intro-lyrics'}, {'title': 'Billy Joel - You May Be Right (Official Audio) - YouTube', 'link': 'https://www.bing.com/ck/a?!&&p=2d4da88f8ba97073260ea7e82bfc25c2739b0addefdd38c6059969a3d09b0ea1JmltdHM9MTc1Mjk0OTAzOA&ptn=3&fclid=9a802f1f-64cc-11f0-9f7e-6a36e38416dd&ntb=1&u=a1L3ZpZGVvcy9yaXZlcnZpZXcvcmVsYXRlZHZpZGVvP3E9TVVTSUMrWW91K21heSt0aGluayt0aGlzK2NhbiUyN3QrYmUrcHJvYmFibHkrcmlnaHQrTHVjaytnZXRzK2luK3RoZSt3b29kcytvbitIYWxsb3dlZW4rbmlnaHQmcnU9JTJmc2VhcmNoJTNmcSUzZE1VU0lDJTI1MjBZb3UlMjUyMG1heSUyNTIwdGhpbmslMjUyMHRoaXMlMjUyMGNhbiUyNTI3dCUyNTIwYmUlMjUyMHByb2JhYmx5JTI1MjByaWdodCUyNTIwTHVjayUyNTIwZ2V0cyUyNTIwaW4lMjUyMHRoZSUyNTIwd29vZHMlMjUyMG9uJTI1MjBIYWxsb3dlZW4lMjUyMG5pZ2h0Jm1tc2NuPXZ3cmMmbWlkPTdBOTJGNzg3MEEwNDNBMjUwRTg5N0E5MkY3ODcwQTA0M0EyNTBFODkmRk9STT1XUlZPUkMmbnRiPTEmbXNvY2tpZD05YTgwMmYxZjY0Y2MxMWYwOWY3ZTZhMzZlMzg0MTZkZA'}]\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=MUSIC You may think this can't be probably right Luck gets in the woods on Halloween night with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://genius.com/Lloyd-banks-halloween-intro-lyrics with wait_time=10s\n",
      "‚úÖ Crawled content from https://genius.com/Lloyd-banks-halloween-intro-lyrics:\n",
      "Follow @genius...\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=MUSIC You may think this can't be probably right Luck gets in the woods on Halloween night:\n",
      "Halloween Intro Lyrics: Black cats and goblins and broomsticks and ghosts / Covens of witches with all of their hosts / You may think they scare me; you're probably right / Black cats...\n",
      "Maybe if you put some time in to your ‚Ä¶\n",
      "Shot Down Lyrics: 2 G's Up! {DAMN!} ‚Ä¶\n",
      "Bomb First Lyrics: Bomb First Lyrics / ‚Ä¶\n",
      "Play House Lyrics: If you new weather, ‚Ä¶\n",
      "How to Format Lyrics: Type out all lyrics, ‚Ä¶\n",
      "Chorus: (He know...) I got a stack! (He ‚Ä¶\n",
      "[Intro: Lloyd Banks (DJ Whoo Kid)] ‚Ä¶\n",
      "Apr 3, 2013¬†¬∑ Official Audio ...\n",
      "https://www.bing.com/search?q=This statement was made by an unknown speaker during an event involving music, likely a Halloween-related performance or recording, around Halloween time. The topic is cultural beliefs or superstitions related to Halloween.\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"1ac6cbcf7d426cdca6acea73c7335eaf\", element=\"f.85390B91AD1A87E2A3AACF3A81B279D2.d.95A28783E363A96C03B682FF49090BD4.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"1ac6cbcf7d426cdca6acea73c7335eaf\", element=\"f.85390B91AD1A87E2A3AACF3A81B279D2.d.95A28783E363A96C03B682FF49090BD4.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"1ac6cbcf7d426cdca6acea73c7335eaf\", element=\"f.85390B91AD1A87E2A3AACF3A81B279D2.d.95A28783E363A96C03B682FF49090BD4.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"1ac6cbcf7d426cdca6acea73c7335eaf\", element=\"f.85390B91AD1A87E2A3AACF3A81B279D2.d.95A28783E363A96C03B682FF49090BD4.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"1ac6cbcf7d426cdca6acea73c7335eaf\", element=\"f.85390B91AD1A87E2A3AACF3A81B279D2.d.95A28783E363A96C03B682FF49090BD4.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"1ac6cbcf7d426cdca6acea73c7335eaf\", element=\"f.85390B91AD1A87E2A3AACF3A81B279D2.d.95A28783E363A96C03B682FF49090BD4.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"1ac6cbcf7d426cdca6acea73c7335eaf\", element=\"f.85390B91AD1A87E2A3AACF3A81B279D2.d.95A28783E363A96C03B682FF49090BD4.e.27\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"1ac6cbcf7d426cdca6acea73c7335eaf\", element=\"f.85390B91AD1A87E2A3AACF3A81B279D2.d.95A28783E363A96C03B682FF49090BD4.e.28\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"1ac6cbcf7d426cdca6acea73c7335eaf\", element=\"f.85390B91AD1A87E2A3AACF3A81B279D2.d.95A28783E363A96C03B682FF49090BD4.e.29\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"1ac6cbcf7d426cdca6acea73c7335eaf\", element=\"f.85390B91AD1A87E2A3AACF3A81B279D2.d.95A28783E363A96C03B682FF49090BD4.e.30\")>]\n",
      "Ch11 Quiz - SPCH 1311 Flashcards | Quizlet\n",
      "https://quizlet.com/568563465/ch11-quiz-spch-1311-flash-cards/\n",
      "Luy·ªán T·∫≠p Theo D·∫°ng C√¢u H·ªèi\n",
      "https://luyenieltsonline.com/ielts-listening/ielts-listening-luyen-tap-theo-dang-cau-hoi.html?view=quiz&quiz_id=265\n",
      "Found 3 relevant links:\n",
      "[{'title': 'This statement was made by an ', 'link': 'https://www.bing.com/search?q=This statement was made by an unknown speaker during an event involving music, likely a Halloween-related performance or recording, around Halloween time. The topic is cultural beliefs or superstitions related to Halloween.'}, {'title': 'Ch11 Quiz - SPCH 1311 Flashcards | Quizlet', 'link': 'https://quizlet.com/568563465/ch11-quiz-spch-1311-flash-cards/'}, {'title': 'Luy·ªán T·∫≠p Theo D·∫°ng C√¢u H·ªèi', 'link': 'https://luyenieltsonline.com/ielts-listening/ielts-listening-luyen-tap-theo-dang-cau-hoi.html?view=quiz&quiz_id=265'}]\n",
      "‚è≥ Attempt 1: Crawling https://quizlet.com/568563465/ch11-quiz-spch-1311-flash-cards/ with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=This statement was made by an unknown speaker during an event involving music, likely a Halloween-related performance or recording, around Halloween time. The topic is cultural beliefs or superstitions related to Halloween. with wait_time=10s\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=This statement was made by an unknown speaker during an event involving music, likely a Halloween-related performance or recording, around Halloween time. The topic is cultural beliefs or superstitions related to Halloween.:\n",
      "Speakers should offer definitions of all technical or little-known terms in their presentation. A citation from a work of fiction or nonfiction is an example of a literary quotation. If Gwen knows ‚Ä¶\n",
      "Questions 1-5 Choose the correct letter, A, B or C 1. The speaker says that the conference includes issues which A. were requested by participants. B. are seldom discussed. C. cause ‚Ä¶\n",
      "Select the example in which cultural differences between the speaker and the audience may affect communication. The m...\n",
      "‚úÖ Crawled content from https://quizlet.com/568563465/ch11-quiz-spch-1311-flash-cards/:\n",
      "¬© 2025 Quizlet, Inc....\n",
      "‚úÖ Finished enriching statements with articles.\n",
      "üß™ Running fact-checks on statements...\n",
      "{'start': 0.0, 'end': 126.16, 'speaker': 'Unknown', 'text': \"MUSIC You may think this can't be probably right Luck gets in the woods on Halloween night\", 'reason': 'The statement is a poetic or lyrical claim possibly implying a superstition or belief associated with Halloween night, which is a cultural/historical topic worth verifying in terms of origins or beliefs.', 'context': 'This statement was made by an unknown speaker during an event involving music, likely a Halloween-related performance or recording, around Halloween time. The topic is cultural beliefs or superstitions related to Halloween.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.4095720052719116, 'article_texts': '### MUSIC You may think this can\\'t\\nHalloween Intro Lyrics: Black cats and goblins and broomsticks and ghosts / Covens of witches with all of their hosts / You may think they scare me; you\\'re probably right / Black cats...\\nMaybe if you put some time in to your ‚Ä¶\\nShot Down Lyrics: 2 G\\'s Up! {DAMN!} ‚Ä¶\\nBomb First Lyrics: Bomb First Lyrics / ‚Ä¶\\nPlay House Lyrics: If you new weather, ‚Ä¶\\nHow to Format Lyrics: Type out all lyrics, ‚Ä¶\\nChorus: (He know...) I got a stack! (He ‚Ä¶\\n[Intro: Lloyd Banks (DJ Whoo Kid)] ‚Ä¶\\nApr 3, 2013\\xa0¬∑ Official Audio for \"You May Be Right\" by Billy Joel Listen to Billy Joel: https://billyjoel.lnk.to/listenYD...more\\nBilly Joel \"You May Be Right\": Friday night, I crashed your party Saturday, I said I\\'m sorry Sunday came and trashed me out again I...\\nLyric Finder - Search the world\\'s best lyric sites and find lyrics for any song.\\nYou May Be Right Lyrics & Meanings: Friday night I crashed your party / Saturday I said I\\'m sorry / Sunday came and trashed me out again / I was only having fun / Wasn\\'t hurting anyone / And we all enjoyed the weekend for a change / / I\\'ve ‚Ä¶\\nMay 19, 2014\\xa0¬∑ Friday night I crashed your party Saturday I said I‚Äôm sorry Sunday came and trashed me out again I was only having fun Wasn‚Äôt hurting anyone And we all enjoyed the weekend for a change I‚Äôve been stranded in the combat ‚Ä¶\\n\\n### Lloyd Banks ‚Äì Halloween Intro Lyrics | Genius Lyrics\\nFollow @genius\\n\\n### This statement was made by an \\nSpeakers should offer definitions of all technical or little-known terms in their presentation. A citation from a work of fiction or nonfiction is an example of a literary quotation. If Gwen knows ‚Ä¶\\nQuestions 1-5 Choose the correct letter, A, B or C 1. The speaker says that the conference includes issues which A. were requested by participants. B. are seldom discussed. C. cause ‚Ä¶\\nSelect the example in which cultural differences between the speaker and the audience may affect communication. The music that Andrew used in his ‚Ä¶\\nA speaker who, during a speech of acceptance, says, \"I am so caught off guard\" but then reads from a prepared script fails to honor which guideline for effective special occasion speaking?\\n\"To inform my audience about what happened at the Battle oGettysburg\" is a specific purpose statement for an informative speech about an event.\\nA good speaker tries very hard to eliminate all fear and nervousness. It is more important for a listener to remember the main points of a speech than to remember support materials. ‚Ä¶\\nIn a crowded arena, you notice that when others laugh, clap, or cheer on the speaker, you are more likely to follow along with their actions. This is an example of _____ theory\\nTo help us think through how to be effective in delivering special occasion speeches, let‚Äôs look at four key ingredients: preparation, adaptation to the occasion, adaptation to the audience, and mindfulness about the time.\\nPublic speaking, as its name implies, is a way of making your ideas public‚Äî of sharing them with other people and of influencing other people. Importance for civic engagement II. Public Speaking vs Conversation.\\n\\n### Ch11 Quiz - SPCH 1311 Flashcards | Quizlet\\n¬© 2025 Quizlet, Inc.'}\n",
      "üßê Fact-checking: MUSIC You may think this can't be probably right Luck gets in the woods on Hallo...\n",
      "‚úÖ All statements are supported or unverified.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\580.mp4\n",
      "Deepfake label: REAL, Fact-check label: True\n",
      "üíæ Saved checkpoint after 581 videos\n",
      "üìº Processing video 582: ../data/dfw_youtube_release\\581.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\581.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n",
      "üìù Transcribing...\n",
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Clint Eastwood\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-4.52] Unknown: Random headphone Wait\n",
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 4.52, 'speaker': 'Unknown', 'text': 'Random headphone Wait', 'reason': 'No factual claim or political statement to verify; this is not checkworthy.', 'context': 'Unknown setting, likely an introduction or technical issue, with no political or factual discussion to assess.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\581\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\581.mp4, 2764800 bytes wanted but 0 bytes read,at frame 4977/4978, at time 207.38/207.38 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['012dc16e98cb489e98f75b0ca29010a1_clip_1.mp4'], 'pred': [0.43744027614593506], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 4.52, 'speaker': 'Unknown', 'text': 'Random headphone Wait', 'reason': 'No factual claim or political statement to verify; this is not checkworthy.', 'context': 'Unknown setting, likely an introduction or technical issue, with no political or factual discussion to assess.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.43744027614593506}]\n",
      "üì∞ Enriching statements with articles...\n",
      "https://www.bing.com/search?q=Random headphone Wait\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"e56476b1d1fa83e1de2a5239ab2b35bb\", element=\"f.34865F416D62F1AB6E9DD7A3770431C5.d.7492CB8F33A0C39C11EC8BA308C5E782.e.17\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e56476b1d1fa83e1de2a5239ab2b35bb\", element=\"f.34865F416D62F1AB6E9DD7A3770431C5.d.7492CB8F33A0C39C11EC8BA308C5E782.e.18\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e56476b1d1fa83e1de2a5239ab2b35bb\", element=\"f.34865F416D62F1AB6E9DD7A3770431C5.d.7492CB8F33A0C39C11EC8BA308C5E782.e.19\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e56476b1d1fa83e1de2a5239ab2b35bb\", element=\"f.34865F416D62F1AB6E9DD7A3770431C5.d.7492CB8F33A0C39C11EC8BA308C5E782.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e56476b1d1fa83e1de2a5239ab2b35bb\", element=\"f.34865F416D62F1AB6E9DD7A3770431C5.d.7492CB8F33A0C39C11EC8BA308C5E782.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e56476b1d1fa83e1de2a5239ab2b35bb\", element=\"f.34865F416D62F1AB6E9DD7A3770431C5.d.7492CB8F33A0C39C11EC8BA308C5E782.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e56476b1d1fa83e1de2a5239ab2b35bb\", element=\"f.34865F416D62F1AB6E9DD7A3770431C5.d.7492CB8F33A0C39C11EC8BA308C5E782.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e56476b1d1fa83e1de2a5239ab2b35bb\", element=\"f.34865F416D62F1AB6E9DD7A3770431C5.d.7492CB8F33A0C39C11EC8BA308C5E782.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e56476b1d1fa83e1de2a5239ab2b35bb\", element=\"f.34865F416D62F1AB6E9DD7A3770431C5.d.7492CB8F33A0C39C11EC8BA308C5E782.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e56476b1d1fa83e1de2a5239ab2b35bb\", element=\"f.34865F416D62F1AB6E9DD7A3770431C5.d.7492CB8F33A0C39C11EC8BA308C5E782.e.26\")>]\n",
      "Headphone Challenge - Guess the Lines ‚Äç‚ÜïÔ∏è| #shorts | Wait For It\n",
      "https://www.youtube.com/shorts/y6CmeH3M8lo\n",
      "Monkey: Free Random Video Chat Like Omegle with Strangers\n",
      "https://www.monkey.app/?pa_channel=google-1&gad_source=1\n",
      "Found 3 relevant links:\n",
      "[{'title': 'Random headphone Wait', 'link': 'https://www.bing.com/search?q=Random headphone Wait'}, {'title': 'Headphone Challenge - Guess the Lines \\u200d‚ÜïÔ∏è| #shorts | Wait For It', 'link': 'https://www.youtube.com/shorts/y6CmeH3M8lo'}, {'title': 'Monkey: Free Random Video Chat Like Omegle with Strangers', 'link': 'https://www.monkey.app/?pa_channel=google-1&gad_source=1'}]\n",
      "‚è≥ Attempt 1: Crawling https://www.youtube.com/shorts/y6CmeH3M8lo with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=Random headphone Wait with wait_time=10s\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=Random headphone Wait:\n",
      "use headphones please wait random pleyer üòÇüòÇDalpat Meena\n",
      "Alternative to Omegle & OmeTV Monkey brings the thrill of random video chat, enabling you to meet new people from around the world in real-time. It serves as an excellent alternative to Omegle or OmeTV for those seeking exciting ‚Ä¶\n",
      "It stops randomly as well, sometimes you can wait for it to stop or pausing music or stopping sounds can occasionaly stop this. it happens on random games with or without music. The battery is currently high and i...\n",
      "‚úÖ Crawled content from https://www.youtube.com/shorts/y6CmeH3M8lo:\n",
      "...\n",
      "https://www.bing.com/search?q=Unknown setting, likely an introduction or technical issue, with no political or factual discussion to assess.\n",
      "Found 10 relevant links:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"e6ac693c63fe91eb7357e0a1cff8d8eb\", element=\"f.C982342FCDDD91F3B89AE9838F61C12B.d.B2CC2C0FF0762EBFE5CFC78EC0BBE184.e.19\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e6ac693c63fe91eb7357e0a1cff8d8eb\", element=\"f.C982342FCDDD91F3B89AE9838F61C12B.d.B2CC2C0FF0762EBFE5CFC78EC0BBE184.e.20\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e6ac693c63fe91eb7357e0a1cff8d8eb\", element=\"f.C982342FCDDD91F3B89AE9838F61C12B.d.B2CC2C0FF0762EBFE5CFC78EC0BBE184.e.21\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e6ac693c63fe91eb7357e0a1cff8d8eb\", element=\"f.C982342FCDDD91F3B89AE9838F61C12B.d.B2CC2C0FF0762EBFE5CFC78EC0BBE184.e.22\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e6ac693c63fe91eb7357e0a1cff8d8eb\", element=\"f.C982342FCDDD91F3B89AE9838F61C12B.d.B2CC2C0FF0762EBFE5CFC78EC0BBE184.e.23\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e6ac693c63fe91eb7357e0a1cff8d8eb\", element=\"f.C982342FCDDD91F3B89AE9838F61C12B.d.B2CC2C0FF0762EBFE5CFC78EC0BBE184.e.24\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e6ac693c63fe91eb7357e0a1cff8d8eb\", element=\"f.C982342FCDDD91F3B89AE9838F61C12B.d.B2CC2C0FF0762EBFE5CFC78EC0BBE184.e.25\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e6ac693c63fe91eb7357e0a1cff8d8eb\", element=\"f.C982342FCDDD91F3B89AE9838F61C12B.d.B2CC2C0FF0762EBFE5CFC78EC0BBE184.e.26\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e6ac693c63fe91eb7357e0a1cff8d8eb\", element=\"f.C982342FCDDD91F3B89AE9838F61C12B.d.B2CC2C0FF0762EBFE5CFC78EC0BBE184.e.27\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"e6ac693c63fe91eb7357e0a1cff8d8eb\", element=\"f.C982342FCDDD91F3B89AE9838F61C12B.d.B2CC2C0FF0762EBFE5CFC78EC0BBE184.e.28\")>]\n",
      "\"Unknown Configuration Setting\" VSCode greyed Out\n",
      "https://stackoverflow.com/questions/65311289/unknown-configuration-setting-vscode-greyed-out\n",
      "Computer Basics: Basic Troubleshooting Techniques\n",
      "https://edu.gcfglobal.org/en/computerbasics/basic-troubleshooting-techniques/1/\n",
      "Found 3 relevant links:\n",
      "[{'title': 'Unknown setting, likely an int', 'link': 'https://www.bing.com/search?q=Unknown setting, likely an introduction or technical issue, with no political or factual discussion to assess.'}, {'title': '\"Unknown Configuration Setting\" VSCode greyed Out', 'link': 'https://stackoverflow.com/questions/65311289/unknown-configuration-setting-vscode-greyed-out'}, {'title': 'Computer Basics: Basic Troubleshooting Techniques', 'link': 'https://edu.gcfglobal.org/en/computerbasics/basic-troubleshooting-techniques/1/'}]\n",
      "‚è≥ Attempt 1: Crawling https://www.bing.com/search?q=Unknown setting, likely an introduction or technical issue, with no political or factual discussion to assess. with wait_time=10s\n",
      "‚è≥ Attempt 1: Crawling https://stackoverflow.com/questions/65311289/unknown-configuration-setting-vscode-greyed-out with wait_time=10s\n",
      "‚úÖ Crawled content from https://www.bing.com/search?q=Unknown setting, likely an introduction or technical issue, with no political or factual discussion to assess.:\n",
      "Dec 15, 2020¬†¬∑ On hover, the warning I get is Unknown Configuration Setting No quick fixes available. How do I activate these settings again? Ok, I've found the reason: the right Python ‚Ä¶\n",
      "2 days ago¬†¬∑ Technical Level : Intermediate Summary Windows 10 has been available in preview since October 2014. Since then, early adopters have developed a better understanding of the ‚Ä¶\n",
      "Dec 5, 2018¬†¬∑ After opening the settings.json file (from the preferences menu, not directly) I get a couple of warnings stati...\n",
      "‚úÖ Crawled content from https://stackoverflow.com/questions/65311289/unknown-configuration-setting-vscode-greyed-out:\n",
      "Verify you are human by completing the action below....\n",
      "‚úÖ Finished enriching statements with articles.\n",
      "üß™ Running fact-checks on statements...\n",
      "{'start': 0.0, 'end': 4.52, 'speaker': 'Unknown', 'text': 'Random headphone Wait', 'reason': 'No factual claim or political statement to verify; this is not checkworthy.', 'context': 'Unknown setting, likely an introduction or technical issue, with no political or factual discussion to assess.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.43744027614593506, 'article_texts': '### Random headphone Wait\\nuse headphones please wait random pleyer üòÇüòÇDalpat Meena\\nAlternative to Omegle & OmeTV Monkey brings the thrill of random video chat, enabling you to meet new people from around the world in real-time. It serves as an excellent alternative to Omegle or OmeTV for those seeking exciting ‚Ä¶\\nIt stops randomly as well, sometimes you can wait for it to stop or pausing music or stopping sounds can occasionaly stop this. it happens on random games with or without music. The battery is currently high and it will happen regardless of ‚Ä¶\\nJan 20, 2021\\xa0¬∑ To soft reset your headset: Make sure your headset is currently unplugged. Make sure your headset is powered on. Hold the Mute button on the headset down for about 15 seconds. Hold down the power button until the ‚Ä¶\\n\\n### Unknown setting, likely an int\\nDec 15, 2020\\xa0¬∑ On hover, the warning I get is Unknown Configuration Setting No quick fixes available. How do I activate these settings again? Ok, I\\'ve found the reason: the right Python ‚Ä¶\\n2 days ago\\xa0¬∑ Technical Level : Intermediate Summary Windows 10 has been available in preview since October 2014. Since then, early adopters have developed a better understanding of the ‚Ä¶\\nDec 5, 2018\\xa0¬∑ After opening the settings.json file (from the preferences menu, not directly) I get a couple of warnings stating: Unknown configuration setting. Removing the changes in the settings file, doesn\\'t clear the warning.\\nNo matter what\\'s causing the issue, troubleshooting will always be a process of trial and error ‚Äîin some cases, you may need to use several different approaches before you can find a solution; ‚Ä¶\\nStruggling with technical issues? A troubleshooting methodology can help. Understand the step-by-step process to diagnose, test, and resolve problems efficiently. Troubleshooting starts by accurately identifying the problem using ‚Ä¶\\nSep 2, 2024\\xa0¬∑ In the Edge Settings window, select Cookies and site permissions > Cookies and data stored > Manage and delete cookies and site data. Turn on Allow sites to save and read cookie data (recommended), and make sure that ‚Ä¶\\n\\n### \"Unknown Configuration Setting\" VSCode greyed Out\\nVerify you are human by completing the action below.'}\n",
      "üßê Fact-checking: Random headphone Wait...\n",
      "‚úÖ All statements are supported or unverified.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\581.mp4\n",
      "Deepfake label: REAL, Fact-check label: True\n",
      "üíæ Saved checkpoint after 582 videos\n",
      "üìº Processing video 583: ../data/dfw_youtube_release\\582.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\582.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Harry Callahan\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Harry Callahan\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-14.00] Unknown: This is about a movie about a couple of killers. Harry Callahan. Now homicidal maniac.\n",
      "[18.00-20.00] Harry Callahan: The one with a badge is Harry.\n",
      "[21.00-56.00] Unknown: Hold! Oh! There were a lot of reasons they called him dirty Harry. And he kept inventing new ones. Don't pass it on yet. I'm putting somebody with you. You knew what happens if the guys did have work with?\n",
      "[56.00-67.00] Harry Callahan: Dietrich still in the hospital with a bullet in his gun and then Duchy's dead. Now you're working with Gonzalez or you're not working. Now that's straight from the fifth floor. You got it? I know what you're thinking.\n",
      "[68.00-70.00] Unknown: Did you buy a six shots or only five?\n",
      "[71.00-85.00] Harry Callahan: Would you tell it the truth in all of this excitement that Daniel has dragged myself? The big, this is a 44 magnum, the most powerful handgun in the world that would blow your head clean off. If you could ask yourself one question, do I feel lucky?\n",
      "[86.00-87.00] Unknown: We'll do your punk.\n",
      "[89.00-102.00] Harry Callahan: Did you see the man that did this to you? Can you identify him? Yes, I'll have him. He's a big cop. Worst homicide. Call a hammer. What about it, Harry? You want the star? I want an answer.\n",
      "[102.00-104.00] Unknown: Have you been following that man?\n",
      "[106.00-112.00] Harry Callahan: Yeah, I've been following him and me on time. And then anyone can tell I did to do that to him. Oh.\n",
      "[112.00-114.00] Unknown: Because he looks too damn good.\n",
      "[114.00-115.00] Harry Callahan: That's how.\n",
      "[115.00-123.00] Unknown: Now, if you got the guts to play this game by the rules, the kids will have a nice little plane ride. I guarantee you, you will not be molested anyway.\n",
      "[123.00-134.00] Harry Callahan: I'll give you my word of honor on it. Will you people gonna stop messing around with this guy? He's gonna be stopped now. I gave my word of honor on it. And he will not be molested. And that's a direct order, Calla Herr!\n",
      "[137.00-139.00] Unknown: Detective Harry Calla Herr.\n",
      "[139.00-141.00] Harry Callahan: You don't assign him.\n",
      "[141.00-142.00] Unknown: Stop!\n",
      "[142.00-143.00] Harry Callahan: To murder cases.\n",
      "[144.00-147.00] Unknown: You're just... ...turn em loose.\n",
      "[151.00-153.00] Harry Callahan: Now, what the hell did you do to your damn?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 checkworthy statements.\n",
      "[{'start': 56.0, 'end': 67.0, 'speaker': 'Harry Callahan', 'text': \"Dietrich still in the hospital with a bullet in his gun and then Duchy's dead. Now you're working with Gonzalez or you're not working. Now that's straight from the fifth floor. You got it? I know what you're thinking.\", 'reason': 'Claims about hospital status of a person, a death, and work assignments from a specified authority level.', 'context': 'Dialogue from a movie scene featuring police characters, roughly between 56 and 67 seconds, discussing ongoing police work and casualties.', 'frame_path': 'statement_frames\\\\Harry Callahan_005600.jpg'}, {'start': 71.0, 'end': 85.0, 'speaker': 'Harry Callahan', 'text': 'Would you tell it the truth in all of this excitement that Daniel has dragged myself? The big, this is a 44 magnum, the most powerful handgun in the world that would blow your head clean off. If you could ask yourself one question, do I feel lucky?', 'reason': 'Claims about the .44 Magnum being the most powerful handgun in the world and describing its lethality.', 'context': 'Scene from the movie dialogue around 71 to 85 seconds, wherein a character is asserting firearm power and challenging another person.', 'frame_path': 'statement_frames\\\\Harry Callahan_007100.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\582\\clip_1.mp4 from 56.00s to 67.00s\n",
      "‚úÇÔ∏è Cutting statement_clips\\582\\clip_2.mp4 from 71.00s to 85.00s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\582\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['902f91b39fbb4487b537d50101208947_clip_1.mp4'], 'pred': [0.5963679552078247], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['6b46495f8be54ef9ac8ea586166e4824_clip_2.mp4'], 'pred': [0.4248514771461487], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 56.0, 'end': 67.0, 'speaker': 'Harry Callahan', 'text': \"Dietrich still in the hospital with a bullet in his gun and then Duchy's dead. Now you're working with Gonzalez or you're not working. Now that's straight from the fifth floor. You got it? I know what you're thinking.\", 'reason': 'Claims about hospital status of a person, a death, and work assignments from a specified authority level.', 'context': 'Dialogue from a movie scene featuring police characters, roughly between 56 and 67 seconds, discussing ongoing police work and casualties.', 'frame_path': 'statement_frames\\\\Harry Callahan_005600.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5963679552078247}, {'start': 71.0, 'end': 85.0, 'speaker': 'Harry Callahan', 'text': 'Would you tell it the truth in all of this excitement that Daniel has dragged myself? The big, this is a 44 magnum, the most powerful handgun in the world that would blow your head clean off. If you could ask yourself one question, do I feel lucky?', 'reason': 'Claims about the .44 Magnum being the most powerful handgun in the world and describing its lethality.', 'context': 'Scene from the movie dialogue around 71 to 85 seconds, wherein a character is asserting firearm power and challenging another person.', 'frame_path': 'statement_frames\\\\Harry Callahan_007100.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.4248514771461487}]\n",
      "‚ö†Ô∏è Statement Dietrich still in the hospital with a bullet in his gun and then Duchy's dead. Now you're working with Gonzalez or you're not working. Now that's straight from the fifth floor. You got it? I know what you're thinking. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\582.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 583 videos\n",
      "üìº Processing video 584: ../data/dfw_youtube_release\\583.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\583.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-42.00] Unknown: Happy Valentine's Day Every day of the 14th I don't think you'll hurt me, I just want to say happy Valentine's Day Every day of the 14th Can you dig up? Don't, when you're dead What is that, that's that? What is that, that's that? What's that, that's that? What is that, that's that? What's that, that's but that'sÁßÅ What's that, that's that? What's that, that's that? Santa Claus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 42.0, 'speaker': 'Unknown', 'text': \"Happy Valentine's Day Every day of the 14th I don't think you'll hurt me, I just want to say happy Valentine's Day Every day of the 14th Can you dig up? Don't, when you're dead What is that, that's that? What is that, that's that? What's that, that's that? What is that, that's that? What's that, that's but that'sÁßÅ What's that, that's that? What's that, that's that? Santa Claus\", 'reason': \"The speaker makes a claim about Valentine's Day and repeats phrases that are unclear but potentially metaphorical or cultural references, which may require verification for interpretation or origin.\", 'context': 'Unknown speaker speaking in an unclear or informal setting; likely a spontaneous or casual speech without a formal political or factual context. The content is ambiguous and does not clearly fit usual political or factual debates, and there is no specified date or event.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\583\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\583.mp4, 1555200 bytes wanted but 0 bytes read,at frame 1000/1001, at time 41.67/41.68 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['f2f4e6f15e6e4d639cb24a7f07d2bd3b_clip_1.mp4'], 'pred': [0.6100987792015076], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 42.0, 'speaker': 'Unknown', 'text': \"Happy Valentine's Day Every day of the 14th I don't think you'll hurt me, I just want to say happy Valentine's Day Every day of the 14th Can you dig up? Don't, when you're dead What is that, that's that? What is that, that's that? What's that, that's that? What is that, that's that? What's that, that's but that'sÁßÅ What's that, that's that? What's that, that's that? Santa Claus\", 'reason': \"The speaker makes a claim about Valentine's Day and repeats phrases that are unclear but potentially metaphorical or cultural references, which may require verification for interpretation or origin.\", 'context': 'Unknown speaker speaking in an unclear or informal setting; likely a spontaneous or casual speech without a formal political or factual context. The content is ambiguous and does not clearly fit usual political or factual debates, and there is no specified date or event.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.6100987792015076}]\n",
      "‚ö†Ô∏è Statement Happy Valentine's Day Every day of the 14th I don't think you'll hurt me, I just want to say happy Valentine's Day Every day of the 14th Can you dig up? Don't, when you're dead What is that, that's that? What is that, that's that? What's that, that's that? What is that, that's that? What's that, that's but that'sÁßÅ What's that, that's that? What's that, that's that? Santa Claus is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\583.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 584 videos\n",
      "üìº Processing video 585: ../data/dfw_youtube_release\\584.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\584.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[30.00-38.00] Unknown: I think I better quit talking that bitch.\n",
      "[38.00-40.00] SPEAKER_00: So come and get it.\n",
      "‚úÖ Found 1 checkworthy statements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 30.0, 'end': 38.0, 'speaker': 'Unknown', 'text': 'I think I better quit talking that bitch.', 'reason': 'Contains a controversial and potentially inflammatory statement by the speaker.', 'context': 'Likely a heated exchange or confrontation during a political debate or interview around 30 to 40 seconds into the video; no specific topic or question known.', 'frame_path': 'statement_frames\\\\Unknown_003000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\584\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\584.mp4, 2764800 bytes wanted but 0 bytes read,at frame 1000/1001, at time 41.67/41.68 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['9c22894e8f504adeba05d99610e9b967_clip_1.mp4'], 'pred': [0.6065438985824585], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 30.0, 'end': 38.0, 'speaker': 'Unknown', 'text': 'I think I better quit talking that bitch.', 'reason': 'Contains a controversial and potentially inflammatory statement by the speaker.', 'context': 'Likely a heated exchange or confrontation during a political debate or interview around 30 to 40 seconds into the video; no specific topic or question known.', 'frame_path': 'statement_frames\\\\Unknown_003000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.6065438985824585}]\n",
      "‚ö†Ô∏è Statement I think I better quit talking that bitch. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\584.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 585 videos\n",
      "üìº Processing video 586: ../data/dfw_youtube_release\\585.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\585.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Jim Hopper\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_02...\n",
      "‚úÖ SPEAKER_02 ‚Üí Jim Hopper\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-40.00] Unknown: Hi. Hi. I've been coming around the circles in my mind. Getting all the sins that I've filed over you But you take me to the places that I'm not never fine. What I wanted to say to you? Uh-oh. I think we're in trouble. Nobody's in trouble.\n",
      "[40.00-41.00] Jim Hopper: Okay.\n",
      "[41.00-44.00] Unknown: I just...\n",
      "[44.00-55.00] Jim Hopper: You know what? Your mom called. What? She needs your home right away.\n",
      "[55.00-56.00] Unknown: Is everything okay?\n",
      "[56.00-58.00] Jim Hopper: No, I don't think so.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 44.0, 'end': 55.0, 'speaker': 'Jim Hopper', 'text': 'You know what? Your mom called. What? She needs your home right away.', 'reason': 'Implying an urgent situation involving a family member, which may be a significant claim about an emergency or important event.', 'context': 'From a dialogue scene likely in a TV show or film, occurring at 44 to 55 seconds. The context suggests a sudden notice of urgency regarding a family situation, possibly in a dramatic or suspenseful setting.', 'frame_path': 'statement_frames\\\\Jim Hopper_004400.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\585\\clip_1.mp4\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['a80004d13767404bbea87c216bc763d2_clip_1.mp4'], 'pred': [0.5464106798171997], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 44.0, 'end': 55.0, 'speaker': 'Jim Hopper', 'text': 'You know what? Your mom called. What? She needs your home right away.', 'reason': 'Implying an urgent situation involving a family member, which may be a significant claim about an emergency or important event.', 'context': 'From a dialogue scene likely in a TV show or film, occurring at 44 to 55 seconds. The context suggests a sudden notice of urgency regarding a family situation, possibly in a dramatic or suspenseful setting.', 'frame_path': 'statement_frames\\\\Jim Hopper_004400.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5464106798171997}]\n",
      "‚ö†Ô∏è Statement You know what? Your mom called. What? She needs your home right away. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\585.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 586 videos\n",
      "üìº Processing video 587: ../data/dfw_youtube_release\\586.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\586.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Mike Wheeler\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-10.80] Unknown: 2\n",
      "[10.80-27.12] Mike Wheeler: 8 You're on your own. Mine! You can never surrender! No! You don't like it? No!\n",
      "[27.12-30.12] Unknown: Those are the same things.\n",
      "[30.12-43.12] Mike Wheeler: Sanko, face a flourish. Go for it, but he out in the same heart. Move them and destroy. On the hall, New York. Now they're looking to see. Can't name them all. Now it's your small self-body. Everybody! Everybody! To get the fuck off!\n",
      "[43.12-47.12] Unknown: Hey! The ancient number mom.\n",
      "[47.12-52.12] SPEAKER_00: Leave the door open and go! What's wrong?\n",
      "[54.12-56.12] Unknown: Hey ladies!\n",
      "[58.12-59.12] Mike Wheeler: Who's that?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 checkworthy statements.\n",
      "[{'start': 10.8, 'end': 27.12, 'speaker': 'Mike Wheeler', 'text': \"You're on your own. Mine! You can never surrender! No! You don't like it? No!\", 'reason': 'Asserts a strong stance about never surrendering, a bold and controversial claim that can be fact-checked for context or accuracy.', 'context': 'Unknown setting, possibly a heated discussion or argument during an informal event in 2024; Mike Wheeler is expressing a defiant viewpoint, possibly replying to opposition or criticism.', 'frame_path': 'statement_frames\\\\Mike Wheeler_001080.jpg'}, {'start': 30.12, 'end': 43.12, 'speaker': 'Mike Wheeler', 'text': \"Sanko, face a flourish. Go for it, but he out in the same heart. Move them and destroy. On the hall, New York. Now they're looking to see. Can't name them all. Now it's your small self-body. Everybody! Everybody! To get the fuck off!\", 'reason': 'Contains various claims about movements and actions possibly referencing a historical or political situation including place names such as New York, which can be checked for accuracy or context.', 'context': 'Likely during a dramatic or intense speech in a public or semi-public event in 2024; Mike Wheeler appears to be motivating or commanding a group, discussing some form of action or conflict.', 'frame_path': 'statement_frames\\\\Mike Wheeler_003012.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\586\\clip_1.mp4 from 10.80s to 27.12s\n",
      "‚úÇÔ∏è Cutting statement_clips\\586\\clip_2.mp4 from 30.12s to 43.12s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\586\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['bae03bac55c74c4c8ecdc21db973c383_clip_1.mp4'], 'pred': [0.3503580689430237], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['719948577e86409aae6a03b7b8ee4a76_clip_2.mp4'], 'pred': [0.16857069730758667], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 10.8, 'end': 27.12, 'speaker': 'Mike Wheeler', 'text': \"You're on your own. Mine! You can never surrender! No! You don't like it? No!\", 'reason': 'Asserts a strong stance about never surrendering, a bold and controversial claim that can be fact-checked for context or accuracy.', 'context': 'Unknown setting, possibly a heated discussion or argument during an informal event in 2024; Mike Wheeler is expressing a defiant viewpoint, possibly replying to opposition or criticism.', 'frame_path': 'statement_frames\\\\Mike Wheeler_001080.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.3503580689430237}, {'start': 30.12, 'end': 43.12, 'speaker': 'Mike Wheeler', 'text': \"Sanko, face a flourish. Go for it, but he out in the same heart. Move them and destroy. On the hall, New York. Now they're looking to see. Can't name them all. Now it's your small self-body. Everybody! Everybody! To get the fuck off!\", 'reason': 'Contains various claims about movements and actions possibly referencing a historical or political situation including place names such as New York, which can be checked for accuracy or context.', 'context': 'Likely during a dramatic or intense speech in a public or semi-public event in 2024; Mike Wheeler appears to be motivating or commanding a group, discussing some form of action or conflict.', 'frame_path': 'statement_frames\\\\Mike Wheeler_003012.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.16857069730758667}]\n",
      "üì∞ Enriching statements with articles...\n",
      "https://www.bing.com/search?q=You're on your own. Mine! You can never surrender! No! You don't like it? No!https://www.bing.com/search?q=Sanko, face a flourish. Go for it, but he out in the same heart. Move them and destroy. On the hall, New York. Now they're looking to see. Can't name them all. Now it's your small self-body. Everybody! Everybody! To get the fuck off!\n",
      "\n",
      "‚ùå Error processing statement You're on your own. Mine! You can never surrender! No! You don't like it? No!: Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n",
      "  (Session info: chrome=138.0.7204.158)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xa51a33+62339]\n",
      "\tGetHandleVerifier [0x0xa51a74+62404]\n",
      "\t(No symbol) [0x0x892123]\n",
      "\t(No symbol) [0x0x88f85b]\n",
      "\t(No symbol) [0x0x8830d2]\n",
      "\t(No symbol) [0x0x884b05]\n",
      "\t(No symbol) [0x0x883368]\n",
      "\t(No symbol) [0x0x882ea3]\n",
      "\t(No symbol) [0x0x882bb1]\n",
      "\t(No symbol) [0x0x880b54]\n",
      "\t(No symbol) [0x0x8814fb]\n",
      "\t(No symbol) [0x0x895b4e]\n",
      "\t(No symbol) [0x0x921367]\n",
      "\t(No symbol) [0x0x8ff3bc]\n",
      "\t(No symbol) [0x0x9207a3]\n",
      "\t(No symbol) [0x0x8ff1b6]\n",
      "\t(No symbol) [0x0x8ce7a2]\n",
      "\t(No symbol) [0x0x8cf644]\n",
      "\tGetHandleVerifier [0x0xcc65c3+2637587]\n",
      "\tGetHandleVerifier [0x0xcc19ca+2618138]\n",
      "\tGetHandleVerifier [0x0xa784aa+220666]\n",
      "\tGetHandleVerifier [0x0xa688d8+156200]\n",
      "\tGetHandleVerifier [0x0xa6f06d+182717]\n",
      "\tGetHandleVerifier [0x0xa59978+94920]\n",
      "\tGetHandleVerifier [0x0xa59b02+95314]\n",
      "\tGetHandleVerifier [0x0xa44c4a+9626]\n",
      "\tBaseThreadInitThunk [0x0x758e7ba9+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7733c3ab+107]\n",
      "\tRtlClearBits [0x0x7733c32f+191]\n",
      "‚ùå Error processing statement Sanko, face a flourish. Go for it, but he out in the same heart. Move them and destroy. On the hall, New York. Now they're looking to see. Can't name them all. Now it's your small self-body. Everybody! Everybody! To get the fuck off!: Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n",
      "  (Session info: chrome=138.0.7204.158)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xa51a33+62339]\n",
      "\tGetHandleVerifier [0x0xa51a74+62404]\n",
      "\t(No symbol) [0x0x892123]\n",
      "\t(No symbol) [0x0x88f85b]\n",
      "\t(No symbol) [0x0x8830d2]\n",
      "\t(No symbol) [0x0x884b05]\n",
      "\t(No symbol) [0x0x883368]\n",
      "\t(No symbol) [0x0x882ea3]\n",
      "\t(No symbol) [0x0x882bb1]\n",
      "\t(No symbol) [0x0x880b54]\n",
      "\t(No symbol) [0x0x8814fb]\n",
      "\t(No symbol) [0x0x895b4e]\n",
      "\t(No symbol) [0x0x921367]\n",
      "\t(No symbol) [0x0x8ff3bc]\n",
      "\t(No symbol) [0x0x9207a3]\n",
      "\t(No symbol) [0x0x8ff1b6]\n",
      "\t(No symbol) [0x0x8ce7a2]\n",
      "\t(No symbol) [0x0x8cf644]\n",
      "\tGetHandleVerifier [0x0xcc65c3+2637587]\n",
      "\tGetHandleVerifier [0x0xcc19ca+2618138]\n",
      "\tGetHandleVerifier [0x0xa784aa+220666]\n",
      "\tGetHandleVerifier [0x0xa688d8+156200]\n",
      "\tGetHandleVerifier [0x0xa6f06d+182717]\n",
      "\tGetHandleVerifier [0x0xa59978+94920]\n",
      "\tGetHandleVerifier [0x0xa59b02+95314]\n",
      "\tGetHandleVerifier [0x0xa44c4a+9626]\n",
      "\tBaseThreadInitThunk [0x0x758e7ba9+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7733c3ab+107]\n",
      "\tRtlClearBits [0x0x7733c32f+191]\n",
      "\n",
      "\n",
      "‚úÖ Finished enriching statements with articles.\n",
      "üß™ Running fact-checks on statements...\n",
      "{'start': 10.8, 'end': 27.12, 'speaker': 'Mike Wheeler', 'text': \"You're on your own. Mine! You can never surrender! No! You don't like it? No!\", 'reason': 'Asserts a strong stance about never surrendering, a bold and controversial claim that can be fact-checked for context or accuracy.', 'context': 'Unknown setting, possibly a heated discussion or argument during an informal event in 2024; Mike Wheeler is expressing a defiant viewpoint, possibly replying to opposition or criticism.', 'frame_path': 'statement_frames\\\\Mike Wheeler_001080.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.3503580689430237, 'article_texts': ''}\n",
      "üßê Fact-checking: You're on your own. Mine! You can never surrender! No! You don't like it? No!...\n",
      "{'start': 30.12, 'end': 43.12, 'speaker': 'Mike Wheeler', 'text': \"Sanko, face a flourish. Go for it, but he out in the same heart. Move them and destroy. On the hall, New York. Now they're looking to see. Can't name them all. Now it's your small self-body. Everybody! Everybody! To get the fuck off!\", 'reason': 'Contains various claims about movements and actions possibly referencing a historical or political situation including place names such as New York, which can be checked for accuracy or context.', 'context': 'Likely during a dramatic or intense speech in a public or semi-public event in 2024; Mike Wheeler appears to be motivating or commanding a group, discussing some form of action or conflict.', 'frame_path': 'statement_frames\\\\Mike Wheeler_003012.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.16857069730758667, 'article_texts': ''}\n",
      "üßê Fact-checking: Sanko, face a flourish. Go for it, but he out in the same heart. Move them and d...\n",
      "‚úÖ All statements are supported or unverified.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\586.mp4\n",
      "Deepfake label: REAL, Fact-check label: True\n",
      "üíæ Saved checkpoint after 587 videos\n",
      "üìº Processing video 588: ../data/dfw_youtube_release\\587.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\587.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Unnamed\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-128.24] Unknown: Tisztet, hoffit√°s, sajim, a√Ω magyarok. Az √°nk, √©s magy vir√°g. Ezen nyiprom l√©v√°lt√≥ szemvet. Megr≈ël, r√≠tkar mesz√©l√ºnk. T√∂bbem kopat√≠t√°ltak, ebben az esztend≈ëben, a sz√≥laajat meg a c√©lmiat. Ika szben, senkinek nem t≈±nt fel. √âs a p√°zza hant mad√°rk√°k afrikai tegel√©se. Jaxzt√≥ m√©rt√©ben elhozodott. Vikor, marulod√≥ hoffit√°sa ink. A korrupci√≥ m√©rt√©k√©ve j√∂nnek. √âs szid√°rdantitartok. Orvid h√°t√≥, tar√°nk√©rizek. A duppra zs√°gos, h√°rom, vedr√∂s, eldor√°dobbogarak. √âs a h√°zartos, sz√∫nyak canca vir√°gok, n√ºgyem ellett. Amigr√°ci√≥, cs√∫nyos k√©rd√©s. √âs a kerint√© is miatt f≈ëdik√∫cs a csal√°dok sz√°zai ker√ºlten vesz√©be. Egy 8-gyermekes tisza t√°jt csal√°lt√≥kaptam nevert. ≈êk, ami ad b√°nk√≥dnak, hogy a szennyezetterme ishetes √©des viz. Meg√∂ltek edvenc, egy h√°tai tuj√©r√≥ k√°jukat. Nefi, kis mok. Et most szullok. T√°rcs√°s hely≈ë, p√©ld√°ul a hark√°juk, daradatok√°juk, r√°kord√≥bogarak, p√°rdutsz voltos, hangyolesz≈ëk, √©s ti? L√°mi pozok. Szeretek elpadben edetz√©ben. A k√©t ezek tizenj√≥z√°sztend≈ëben is sz√°vid hatok r√°la. Aholy, de √°tverenztan√≠csenek√ºnk. Nem minden dol√°ny. Ila dol√°ny. Nem minden rovar. Vicik. K√∂rnyezet bar√°taj. Ide v√©n. Fagyunk √∂ssze a rozt√°st√≥l,\n",
      "[128.24-129.84] SPEAKER_00: koguvatf√∫ria k√∂rtv√©kre.\n",
      "[129.84-140.72] Unknown: Ilyos a hazap. F√©nyed err≈ël. Vodog√≥ √©vet. N≈ëj√©ges, √°llatkil√°g. Vodog√≥ √©vet, annyorokkor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 128.24, 'speaker': 'Unknown', 'text': 'Tisztet, hoffit√°s, sajim, a√Ω magyarok. Az √°nk, √©s magy vir√°g. Ezen nyiprom l√©v√°lt√≥ szemvet. Megr≈ël, r√≠tkar mesz√©l√ºnk. T√∂bbem kopat√≠t√°ltak, ebben az esztend≈ëben, a sz√≥laajat meg a c√©lmiat. Ika szben, senkinek nem t≈±nt fel. √âs a p√°zza hant mad√°rk√°k afrikai tegel√©se. Jaxzt√≥ m√©rt√©ben elhozodott. Vikor, marulod√≥ hoffit√°sa ink. A korrupci√≥ m√©rt√©k√©ve j√∂nnek. √âs szid√°rdantitartok. Orvid h√°t√≥, tar√°nk√©rizek. A duppra zs√°gos, h√°rom, vedr√∂s, eldor√°dobbogarak. √âs a h√°zartos, sz√∫nyak canca vir√°gok, n√ºgyem ellett. Amigr√°ci√≥, cs√∫nyos k√©rd√©s. √âs a kerint√© is miatt f≈ëdik√∫cs a csal√°dok sz√°zai ker√ºlten vesz√©be. Egy 8-gyermekes tisza t√°jt csal√°lt√≥kaptam nevert. ≈êk, ami ad b√°nk√≥dnak, hogy a szennyezetterme ishetes √©des viz. Meg√∂ltek edvenc, egy h√°tai tuj√©r√≥ k√°jukat. Nefi, kis mok. Et most szullok. T√°rcs√°s hely≈ë, p√©ld√°ul a hark√°juk, daradatok√°juk, r√°kord√≥bogarak, p√°rdutsz voltos, hangyolesz≈ëk, √©s ti? L√°mi pozok. Szeretek elpadben edetz√©ben. A k√©t ezek tizenj√≥z√°sztend≈ëben is sz√°vid hatok r√°la. Aholy, de √°tverenztan√≠csenek√ºnk. Nem minden dol√°ny. Ila dol√°ny. Nem minden rovar. Vicik. K√∂rnyezet bar√°taj. Ide v√©n. Fagyunk √∂ssze a rozt√°st√≥l,', 'reason': 'The speaker makes multiple factual claims regarding issues such as corruption levels, migration problems affecting families, environmental contamination (polluted sweet water), and social challenges affecting families with many children, all of which are concrete claims worthy of verification.', 'context': 'The quote was made by an unknown speaker in a Hungarian-language speech or presentation, possibly discussing social and environmental issues affecting Hungarian communities, addressing topics such as corruption, migration, pollution, and family hardship. The exact event or date is not provided but appears to be a formal discussion or address.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}, {'start': 129.84, 'end': 140.72, 'speaker': 'Unknown', 'text': 'Ilyos a hazap. F√©nyed err≈ël. Vodog√≥ √©vet. N≈ëj√©ges, √°llatkil√°g. Vodog√≥ √©vet, annyorokkor.', 'reason': 'Contains claims about the natural environment and possibly ecological or societal conditions, which could be explored for details and accuracy based on the unclear but factual context implied.', 'context': \"Continuation of the same unknown speaker's address related to environmental and societal topics, presumably discussing the state of the homeland and its natural life, in an event or speech of undetermined origin or date but likely tied to community or environmental concerns.\", 'frame_path': 'statement_frames\\\\Unknown_012984.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\587\\clip_1.mp4 from 0.00s to 128.24s\n",
      "‚úÇÔ∏è Cutting statement_clips\\587\\clip_2.mp4 from 129.84s to 140.72s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\587\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['08831eea45f44583b3f00ae61ac8acb0_clip_1.mp4'], 'pred': [0.7602418065071106], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['94da726cb6e940d1b6d22c9f209287eb_clip_2.mp4'], 'pred': [0.8906147480010986], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 128.24, 'speaker': 'Unknown', 'text': 'Tisztet, hoffit√°s, sajim, a√Ω magyarok. Az √°nk, √©s magy vir√°g. Ezen nyiprom l√©v√°lt√≥ szemvet. Megr≈ël, r√≠tkar mesz√©l√ºnk. T√∂bbem kopat√≠t√°ltak, ebben az esztend≈ëben, a sz√≥laajat meg a c√©lmiat. Ika szben, senkinek nem t≈±nt fel. √âs a p√°zza hant mad√°rk√°k afrikai tegel√©se. Jaxzt√≥ m√©rt√©ben elhozodott. Vikor, marulod√≥ hoffit√°sa ink. A korrupci√≥ m√©rt√©k√©ve j√∂nnek. √âs szid√°rdantitartok. Orvid h√°t√≥, tar√°nk√©rizek. A duppra zs√°gos, h√°rom, vedr√∂s, eldor√°dobbogarak. √âs a h√°zartos, sz√∫nyak canca vir√°gok, n√ºgyem ellett. Amigr√°ci√≥, cs√∫nyos k√©rd√©s. √âs a kerint√© is miatt f≈ëdik√∫cs a csal√°dok sz√°zai ker√ºlten vesz√©be. Egy 8-gyermekes tisza t√°jt csal√°lt√≥kaptam nevert. ≈êk, ami ad b√°nk√≥dnak, hogy a szennyezetterme ishetes √©des viz. Meg√∂ltek edvenc, egy h√°tai tuj√©r√≥ k√°jukat. Nefi, kis mok. Et most szullok. T√°rcs√°s hely≈ë, p√©ld√°ul a hark√°juk, daradatok√°juk, r√°kord√≥bogarak, p√°rdutsz voltos, hangyolesz≈ëk, √©s ti? L√°mi pozok. Szeretek elpadben edetz√©ben. A k√©t ezek tizenj√≥z√°sztend≈ëben is sz√°vid hatok r√°la. Aholy, de √°tverenztan√≠csenek√ºnk. Nem minden dol√°ny. Ila dol√°ny. Nem minden rovar. Vicik. K√∂rnyezet bar√°taj. Ide v√©n. Fagyunk √∂ssze a rozt√°st√≥l,', 'reason': 'The speaker makes multiple factual claims regarding issues such as corruption levels, migration problems affecting families, environmental contamination (polluted sweet water), and social challenges affecting families with many children, all of which are concrete claims worthy of verification.', 'context': 'The quote was made by an unknown speaker in a Hungarian-language speech or presentation, possibly discussing social and environmental issues affecting Hungarian communities, addressing topics such as corruption, migration, pollution, and family hardship. The exact event or date is not provided but appears to be a formal discussion or address.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.7602418065071106}, {'start': 129.84, 'end': 140.72, 'speaker': 'Unknown', 'text': 'Ilyos a hazap. F√©nyed err≈ël. Vodog√≥ √©vet. N≈ëj√©ges, √°llatkil√°g. Vodog√≥ √©vet, annyorokkor.', 'reason': 'Contains claims about the natural environment and possibly ecological or societal conditions, which could be explored for details and accuracy based on the unclear but factual context implied.', 'context': \"Continuation of the same unknown speaker's address related to environmental and societal topics, presumably discussing the state of the homeland and its natural life, in an event or speech of undetermined origin or date but likely tied to community or environmental concerns.\", 'frame_path': 'statement_frames\\\\Unknown_012984.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.8906147480010986}]\n",
      "‚ö†Ô∏è Statement Tisztet, hoffit√°s, sajim, a√Ω magyarok. Az √°nk, √©s magy vir√°g. Ezen nyiprom l√©v√°lt√≥ szemvet. Megr≈ël, r√≠tkar mesz√©l√ºnk. T√∂bbem kopat√≠t√°ltak, ebben az esztend≈ëben, a sz√≥laajat meg a c√©lmiat. Ika szben, senkinek nem t≈±nt fel. √âs a p√°zza hant mad√°rk√°k afrikai tegel√©se. Jaxzt√≥ m√©rt√©ben elhozodott. Vikor, marulod√≥ hoffit√°sa ink. A korrupci√≥ m√©rt√©k√©ve j√∂nnek. √âs szid√°rdantitartok. Orvid h√°t√≥, tar√°nk√©rizek. A duppra zs√°gos, h√°rom, vedr√∂s, eldor√°dobbogarak. √âs a h√°zartos, sz√∫nyak canca vir√°gok, n√ºgyem ellett. Amigr√°ci√≥, cs√∫nyos k√©rd√©s. √âs a kerint√© is miatt f≈ëdik√∫cs a csal√°dok sz√°zai ker√ºlten vesz√©be. Egy 8-gyermekes tisza t√°jt csal√°lt√≥kaptam nevert. ≈êk, ami ad b√°nk√≥dnak, hogy a szennyezetterme ishetes √©des viz. Meg√∂ltek edvenc, egy h√°tai tuj√©r√≥ k√°jukat. Nefi, kis mok. Et most szullok. T√°rcs√°s hely≈ë, p√©ld√°ul a hark√°juk, daradatok√°juk, r√°kord√≥bogarak, p√°rdutsz voltos, hangyolesz≈ëk, √©s ti? L√°mi pozok. Szeretek elpadben edetz√©ben. A k√©t ezek tizenj√≥z√°sztend≈ëben is sz√°vid hatok r√°la. Aholy, de √°tverenztan√≠csenek√ºnk. Nem minden dol√°ny. Ila dol√°ny. Nem minden rovar. Vicik. K√∂rnyezet bar√°taj. Ide v√©n. Fagyunk √∂ssze a rozt√°st√≥l, is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\587.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 588 videos\n",
      "üìº Processing video 589: ../data/dfw_youtube_release\\588.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\588.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_00...\n",
      "‚úÖ SPEAKER_00 ‚Üí Harry Potter\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_05...\n",
      "‚úÖ SPEAKER_05 ‚Üí Severus Snape\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_01...\n",
      "‚úÖ SPEAKER_01 ‚Üí Unnamed\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_02...\n",
      "‚úÖ SPEAKER_02 ‚Üí Severus Snape\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_03...\n",
      "‚úÖ SPEAKER_03 ‚Üí Severus Snape\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω SPEAKER_04...\n",
      "‚úÖ SPEAKER_04 ‚Üí Severus Snape\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-3.00] Unknown: Father, what a squab... What a prick!\n",
      "[3.00-4.00] Harry Potter: Pretend you're...\n",
      "[4.00-8.00] Unknown: Pretend you're... Pretend you're... Spillian!\n",
      "[8.00-11.00] Harry Potter: Nice one, James! No, stay! Stay!\n",
      "[11.00-12.00] Unknown: Right!\n",
      "[12.00-19.00] Harry Potter: Who was the seamy takeoff, Snivitties Trout? Stay! Stay! Stay! No, no, no!\n",
      "[22.00-25.00] Unknown: Your lesson is about to end.\n",
      "[25.00-29.00] Severus Snape: I need to... Good... ...out...\n",
      "[30.00-40.00] Unknown: ...offer their compliments to Professor Snape... ...and... ...go on.\n",
      "[40.00-45.00] SPEAKER_01: ...and request that he keep his abnormally large nose out of other people's business. Well, you...\n",
      "[45.00-84.00] Unknown: ...insolently little professor! There you are, potent! It's just empty words... ...you'll give it his best effort... ...but when it matters most... ...he'll just slip that back into the hole. Coward! You did hex that bell, girl!\n",
      "[84.00-87.00] Harry Potter: And you didn't... ...look at the U!\n",
      "[87.00-126.00] Unknown: I swore to protect you! I made the unbreakable vow! Valnera Sinento... Valnera Sinento... ...Math! Severus... Please... ...I've had a cutover!\n",
      "[131.00-134.00] Harry Potter: Fight back! You coward! Fight back!\n",
      "[141.00-143.00] Unknown: And wizardry...\n",
      "[143.00-153.00] Severus Snape: ...her speciality... ...Severus... ...Severus, please! With friends...\n",
      "[180.00-185.00] Unknown: ...how dare you stand where he stood? Tell them how it happened that night!\n",
      "[185.00-188.00] Harry Potter: Tell them how you looked him in the eye!\n",
      "[188.00-190.00] Unknown: A man who trusted you!\n",
      "[190.00-191.00] Harry Potter: And killed him!\n",
      "[191.00-222.00] Unknown: Tell them! Sever! Where does it's true loyalty lie? With you... ...of course...\n",
      "[222.00-227.00] Severus Snape: ...Malon. While you live the elder one cannot truly be mine.\n",
      "[229.00-292.00] Unknown: You've been a good and faithful servant, Severus. Malon... ...Nagini... ...Kill! Take them! Take them! Please... ...you have your mother's eyes. Just like your father. Don't kill me!\n",
      "[292.00-304.00] Severus Snape: The prophecy did not refer to a woman. It spoke of a boy born at the end of July. Yes, but he thinks it's her son. Hide her. Hide them all. I beg you.\n",
      "[304.00-311.00] Unknown: What will you give me in exchange, Severus? Anything.\n",
      "[311.00-313.00] Severus Snape: Rather I give you...\n",
      "[316.00-317.00] Unknown: ...the boy survives.\n",
      "[317.00-322.00] Severus Snape: This is a need to protect the Dark Lord is gone. He has her eyes.\n",
      "[323.00-334.00] Unknown: If you truly loved her... ...no one... ...can...\n",
      "[334.00-338.00] Severus Snape: ...on the night Lord Voldemort went to Godric's Hollow to kill Harry.\n",
      "[341.00-343.00] Unknown: So when the time comes...\n",
      "[343.00-345.00] Severus Snape: ...the boy must die.\n",
      "[348.00-357.00] Unknown: You've kept him alive so he can die at the proper moment. You've been raising him like a pig for slaughter. Don't tell me now that you've grown to cow for the boy.\n",
      "[357.00-359.00] Severus Snape: Except for cow.\n",
      "[374.00-386.00] Unknown: Lily... ...after all this time... ...all the ways.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 checkworthy statements.\n",
      "[{'start': 292.0, 'end': 304.0, 'speaker': 'Severus Snape', 'text': \"The prophecy did not refer to a woman. It spoke of a boy born at the end of July. Yes, but he thinks it's her son. Hide her. Hide them all. I beg you.\", 'reason': 'States a specific prophecy about a boy born at the end of July and clarifies a misconception about it referring to a woman; includes a request to protect certain people based on that information.', 'context': 'A dramatic and revealing conversation about a prophecy in a fantasy-themed dialogue, presumably around the Harry Potter series lore, focusing on prophecy and protection decisions made by Severus Snape during the storyline.', 'frame_path': 'statement_frames\\\\Severus Snape_029200.jpg'}, {'start': 348.0, 'end': 357.0, 'speaker': 'Unknown', 'text': \"You've kept him alive so he can die at the proper moment. You've been raising him like a pig for slaughter. Don't tell me now that you've grown to cow for the boy.\", 'reason': 'Makes a strong claim about secret intentions behind the care and raising of a character, implying a premeditated plan for the character to die at a certain time.', 'context': \"This is part of a heated dialogue about the fate of a key character (Harry Potter) and Severus Snape's alleged motives and loyalties; it reflects on themes of sacrifice and betrayal within the story's context, likely from a fan script or dramatization inspired by the Harry Potter series.\", 'frame_path': 'statement_frames\\\\Unknown_034800.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting statement_clips\\588\\clip_1.mp4 from 292.00s to 304.00s\n",
      "‚úÇÔ∏è Cutting statement_clips\\588\\clip_2.mp4 from 348.00s to 357.00s\n",
      "‚úÖ Finished cutting video into clips. Saved to statement_clips\\588\n",
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['2cbcb911a78c4d67a0d5645eaeed9356_clip_1.mp4'], 'pred': [0.26181334257125854], 'klass': ['uncategorized'], 'pred_label': ['REAL'], 'correct_label': ['unknown']}\n",
      "clip_2.mp4: {'name': ['65b54680a0004551944b165fc16aa385_clip_2.mp4'], 'pred': [0.5337880253791809], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 292.0, 'end': 304.0, 'speaker': 'Severus Snape', 'text': \"The prophecy did not refer to a woman. It spoke of a boy born at the end of July. Yes, but he thinks it's her son. Hide her. Hide them all. I beg you.\", 'reason': 'States a specific prophecy about a boy born at the end of July and clarifies a misconception about it referring to a woman; includes a request to protect certain people based on that information.', 'context': 'A dramatic and revealing conversation about a prophecy in a fantasy-themed dialogue, presumably around the Harry Potter series lore, focusing on prophecy and protection decisions made by Severus Snape during the storyline.', 'frame_path': 'statement_frames\\\\Severus Snape_029200.jpg', 'deepfake_label': 'REAL', 'deepfake_score': 0.26181334257125854}, {'start': 348.0, 'end': 357.0, 'speaker': 'Unknown', 'text': \"You've kept him alive so he can die at the proper moment. You've been raising him like a pig for slaughter. Don't tell me now that you've grown to cow for the boy.\", 'reason': 'Makes a strong claim about secret intentions behind the care and raising of a character, implying a premeditated plan for the character to die at a certain time.', 'context': \"This is part of a heated dialogue about the fate of a key character (Harry Potter) and Severus Snape's alleged motives and loyalties; it reflects on themes of sacrifice and betrayal within the story's context, likely from a fan script or dramatization inspired by the Harry Potter series.\", 'frame_path': 'statement_frames\\\\Unknown_034800.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5337880253791809}]\n",
      "‚ö†Ô∏è Statement You've kept him alive so he can die at the proper moment. You've been raising him like a pig for slaughter. Don't tell me now that you've grown to cow for the boy. is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\588.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 589 videos\n",
      "üìº Processing video 590: ../data/dfw_youtube_release\\589.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\589.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "üñºÔ∏è Extracting frames for unknown speakers...\n",
      "ü§ñ Identifying unknown speakers with GPT...\n",
      "\n",
      "üß† ƒêang x·ª≠ l√Ω unknown...\n",
      "‚úÖ unknown ‚Üí Doc Brown\n",
      "üìú Generating final transcript...\n",
      "üîç Finding checkworthy statements...\n",
      "üîç ƒêang x·ª≠ l√Ω ph·∫ßn 1/1...\n",
      "[0.00-32.00] Unknown: When this baby hits 88 miles per hour, you're gonna see some serious shit. What's this? What's this? What's this?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:C:\\Users\\Nghia\\AppData\\Local\\Temp\\ipykernel_25680\\144884604.py:43: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  statement_dict = s.dict()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 checkworthy statements.\n",
      "[{'start': 0.0, 'end': 32.0, 'speaker': 'Unknown', 'text': \"When this baby hits 88 miles per hour, you're gonna see some serious shit. What's this? What's this? What's this?\", 'reason': 'The statement claims a specific speed, 88 miles per hour, implying a significant event or effect occurring at that speed, which is a verifiable claim about speed and its impact in the given context.', 'context': 'The quote is from an unknown speaker in a short video segment, presumably referencing a famous line from a movie scene involving a time-traveling car. This context is likely entertainment-related rather than political, during an unspecified moment.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg'}]\n",
      "üîç Detecting deepfake...\n",
      "üé• Cutting video into clips...\n",
      "‚úÇÔ∏è Cutting full video to statement_clips\\589\\clip_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file ../data/dfw_youtube_release\\589.mp4, 2764800 bytes wanted but 0 bytes read,at frame 1198/1199, at time 49.97/49.97 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting deepfake in clips...\n",
      "üì§ Sending batch videos to deepfake API...\n",
      "‚úÖ Detection results:\n",
      "clip_1.mp4: {'name': ['3cf3ae09986d422191b37f5e68c2ea7e_clip_1.mp4'], 'pred': [0.5614382028579712], 'klass': ['uncategorized'], 'pred_label': ['FAKE'], 'correct_label': ['unknown']}\n",
      "‚úÖ Finished detecting deepfake.\n",
      "‚úÖ Finished detecting deepfake.\n",
      "[{'start': 0.0, 'end': 32.0, 'speaker': 'Unknown', 'text': \"When this baby hits 88 miles per hour, you're gonna see some serious shit. What's this? What's this? What's this?\", 'reason': 'The statement claims a specific speed, 88 miles per hour, implying a significant event or effect occurring at that speed, which is a verifiable claim about speed and its impact in the given context.', 'context': 'The quote is from an unknown speaker in a short video segment, presumably referencing a famous line from a movie scene involving a time-traveling car. This context is likely entertainment-related rather than political, during an unspecified moment.', 'frame_path': 'statement_frames\\\\Unknown_000000.jpg', 'deepfake_label': 'FAKE', 'deepfake_score': 0.5614382028579712}]\n",
      "‚ö†Ô∏è Statement When this baby hits 88 miles per hour, you're gonna see some serious shit. What's this? What's this? What's this? is marked as deepfake. Skipping fact-check.\n",
      "‚úÖ Finished processing video ../data/dfw_youtube_release\\589.mp4\n",
      "Deepfake label: FAKE, Fact-check label: False\n",
      "üíæ Saved checkpoint after 590 videos\n",
      "üìº Processing video 591: ../data/dfw_youtube_release\\590.mp4\n",
      "üé• Extracting statements from video...\n",
      "üé¨ Extracting audio...\n",
      "MoviePy - Writing audio in audios\\590.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "üîä Diarizing speakers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:d:\\LopHoc\\Thesis\\Ver3\\code\\KLTN-Ver3\\research\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Assigning speakers...\n",
      "üß† Inferring speaker names from transcript...\n",
      "‚ö†Ô∏è Error processing video ../data/dfw_youtube_release\\590.mp4: Connection error.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚ö†Ô∏è Error processing video \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     44\u001b[39m results.append({\n\u001b[32m     45\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mvideo_path\u001b[39m\u001b[33m\"\u001b[39m: video_path,\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdeepfake_label\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdeepfake_label\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m     47\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m: result[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     48\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstatements\u001b[39m\u001b[33m\"\u001b[39m: result[\u001b[33m\"\u001b[39m\u001b[33mstatements\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     49\u001b[39m })\n\u001b[32m     51\u001b[39m batch_counter += \u001b[32m1\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Sau m·ªói 10 video th√¨ l∆∞u l·∫°i file\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "VIDEO_DIR = \"../data/dfw_youtube_release\"\n",
    "SAVE_FILE = \"fact_check_results_reverified.json\"\n",
    "BATCH_SIZE = 1  # M·ªói l·∫ßn l∆∞u k·∫øt qu·∫£ sau 10 video\n",
    "START_INDEX = 549  # C√≥ th·ªÉ thay ƒë·ªïi th√†nh 100, 200,...\n",
    "NUM_VIDEOS = 50  # S·ªë l∆∞·ª£ng video b·∫°n mu·ªën x·ª≠ l√Ω l·∫ßn n√†y\n",
    "\n",
    "# L·∫•y danh s√°ch video theo th·ª© t·ª± s·ªë\n",
    "all_files = sorted([\n",
    "    f for f in os.listdir(VIDEO_DIR)\n",
    "    if f.endswith((\".mp4\", \".avi\", \".mov\"))\n",
    "], key=lambda x: int(x.split(\".\")[0]))  # ƒë·∫£m b·∫£o th·ª© t·ª± ƒë√∫ng theo s·ªë\n",
    "\n",
    "# Ch·ªçn m·ªôt t·∫≠p con video c·∫ßn x·ª≠ l√Ω\n",
    "video_files = [\n",
    "    os.path.join(VIDEO_DIR, f)\n",
    "    for f in all_files[START_INDEX: START_INDEX + NUM_VIDEOS]\n",
    "]\n",
    "\n",
    "# N·∫øu c√≥ file c≈© th√¨ load ti·∫øp, kh√¥ng th√¨ t·∫°o danh s√°ch tr·ªëng\n",
    "if os.path.exists(SAVE_FILE):\n",
    "    with open(SAVE_FILE, \"r\", encoding=\"utf-8\") as f:  # üëà th√™m encoding\n",
    "        results = json.load(f)\n",
    "else:\n",
    "    results = []\n",
    "\n",
    "# Tr√°nh x·ª≠ l√Ω l·∫°i c√°c video ƒë√£ c√≥ k·∫øt qu·∫£\n",
    "processed_videos = {r[\"video_path\"] for r in results}\n",
    "pending_videos = [vp for vp in video_files if vp not in processed_videos]\n",
    "\n",
    "batch_counter = 0\n",
    "\n",
    "for idx, video_path in enumerate(pending_videos, 1):\n",
    "    print(f\"üìº Processing video {idx + START_INDEX}: {video_path}\")\n",
    "    try:\n",
    "        result = fact_check_video(video_path)\n",
    "        print(f\"‚úÖ Finished processing video {video_path}\")\n",
    "        print(f\"Deepfake label: {result['deepfake_label']}, Fact-check label: {result['label']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing video {video_path}: {e}\")\n",
    "        result = None\n",
    "\n",
    "    results.append({\n",
    "        \"video_path\": video_path,\n",
    "        \"deepfake_label\": result[\"deepfake_label\"],\n",
    "        \"label\": result[\"label\"],\n",
    "        \"statements\": result[\"statements\"],\n",
    "    })\n",
    "\n",
    "    batch_counter += 1\n",
    "\n",
    "    # Sau m·ªói 10 video th√¨ l∆∞u l·∫°i file\n",
    "    if batch_counter >= BATCH_SIZE:\n",
    "        with open(SAVE_FILE, \"w\") as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "        print(f\"üíæ Saved checkpoint after {idx + START_INDEX} videos\")\n",
    "        batch_counter = 0\n",
    "\n",
    "# Sau v√≤ng l·∫∑p, n·∫øu c√≤n batch ch∆∞a l∆∞u th√¨ l∆∞u n·ªët\n",
    "if batch_counter > 0:\n",
    "    with open(SAVE_FILE, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"üíæ Final checkpoint saved after {len(results)} videos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "927fbd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos processed: 487\n",
      "Precision: 1.0000\n",
      "Recall:    0.8049\n",
      "F1-score:  0.8919\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ file\n",
    "with open(\"fact_check_results_reverified.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "def extract_index(video_path):\n",
    "    filename = video_path.split(\"\\\\\")[-1]  # l·∫•y ph·∫ßn 236.mp4\n",
    "    index = int(filename.split(\".\")[0])\n",
    "    return index\n",
    "\n",
    "# L·ªçc b·ªè c√°c video t·ª´ 236 ƒë·∫øn 334\n",
    "filtered_data = [\n",
    "    item for item in data\n",
    "    if not (236 <= extract_index(item[\"video_path\"]) <= 334)\n",
    "]\n",
    "\n",
    "print(f\"Total videos processed: {len(filtered_data)}\")\n",
    "\n",
    "# L·∫•y danh s√°ch nh√£n d·ª± ƒëo√°n\n",
    "y_pred = [item[\"label\"] for item in filtered_data]\n",
    "\n",
    "# T·∫°o nh√£n ƒë√∫ng (ground truth): to√†n b·ªô l√† False\n",
    "y_true = [False] * len(y_pred)\n",
    "\n",
    "# T√≠nh metrics\n",
    "report = classification_report(\n",
    "    y_true, y_pred,\n",
    "    target_names=[\"False\"],\n",
    "    labels=[False],\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "# In chi ti·∫øt\n",
    "\n",
    "print(f\"Precision: {report['False']['precision']:.4f}\")\n",
    "print(f\"Recall:    {report['False']['recall']:.4f}\")\n",
    "print(f\"F1-score:  {report['False']['f1-score']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
