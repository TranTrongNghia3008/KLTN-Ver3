{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9adbf56",
   "metadata": {},
   "source": [
    "# Part 1: Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd2845",
   "metadata": {},
   "source": [
    "## 1.1 Install Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a46a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22027d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install pyannote.audio\n",
    "!pip install moviepy opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca86f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub[hf_xet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33261970",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromedriver-autoinstaller\n",
    "!apt-get update\n",
    "!apt-get install -y chromium-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce3c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for running selenium in Google Colab\n",
    "## You don't need to run this code if you do it in Jupyter notebook, or other local Python setting\n",
    "%%shell\n",
    "sudo apt -y update\n",
    "sudo apt install -y wget curl unzip\n",
    "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
    "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
    "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
    "dpkg -i google-chrome-stable_current_amd64.deb\n",
    "CHROME_DRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`\n",
    "wget -N https://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip -P /tmp/\n",
    "unzip -o /tmp/chromedriver_linux64.zip -d /tmp/\n",
    "chmod +x /tmp/chromedriver\n",
    "mv /tmp/chromedriver /usr/local/bin/chromedriver\n",
    "pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c97dc1",
   "metadata": {},
   "source": [
    "## 1.2 Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9327cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1411688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "from pyannote.audio import Pipeline\n",
    "from typing import List, Dict\n",
    "import yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b13240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df685bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b6dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For crawling data\n",
    "import chromedriver_autoinstaller\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import concurrent.futures\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException, NoSuchElementException, ElementClickInterceptedException\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b59196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8569af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c0161",
   "metadata": {},
   "source": [
    "## 1.3 Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a81aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf38943",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"http://localhost:8000/deepfake/detect/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Chromedriver\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')  # Run in headless mode\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--window-size=1920x1080')  # Ensure the window size is large enough\n",
    "\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "chrome_options.add_argument(\"accept-language=en-US,en;q=0.9\")\n",
    "chrome_options.add_argument(\"referer=https://www.google.com/\")\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "chrome_options.add_argument(\n",
    "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.6478.57 Safari/537.36\"\n",
    ")\n",
    "chrome_options.binary_location = '/usr/bin/chromium-browser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd41f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIMUM_K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9645c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key = OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0699a806",
   "metadata": {},
   "source": [
    "# Part 2: Extract statements that need fact-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825bb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 1: Extract audio from video ---\n",
    "def extract_audio(video_path: str, audio_dir: str = \"audios\") -> str:\n",
    "    if not os.path.exists(audio_dir):\n",
    "        os.makedirs(audio_dir)\n",
    "    video = VideoFileClip(video_path)\n",
    "    audio_path = os.path.basename(video_path).replace('.mp4', '.wav')\n",
    "    audio_path = os.path.join(audio_dir, audio_path)\n",
    "    if os.path.exists(audio_path):\n",
    "        os.remove(audio_path)\n",
    "    video.audio.write_audiofile(audio_path)\n",
    "    return audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc2022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 2: Diarize audio (identify speakers) ---\n",
    "def diarize_audio(audio_path: str) -> List[Dict]:\n",
    "    pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\", use_auth_token=HUGGINGFACE_TOKEN)\n",
    "    diarization = pipeline(audio_path)\n",
    "    speakers = []\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        speakers.append({\n",
    "            \"start\": turn.start,\n",
    "            \"end\": turn.end,\n",
    "            \"speaker\": speaker\n",
    "        })\n",
    "    return speakers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc41532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 3: Transcribe audio ---\n",
    "def transcribe_audio(audio_path: str) -> List[Dict]:\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"segments\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35273564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 4: Assign speakers to transcript segments ---\n",
    "def assign_speakers(segments: List[Dict], speakers: List[Dict]) -> List[Dict]:\n",
    "    output = []\n",
    "    for seg in segments:\n",
    "        speaker_label = \"unknown\"\n",
    "        for sp in speakers:\n",
    "            if sp[\"start\"] <= seg[\"start\"] <= sp[\"end\"]:\n",
    "                speaker_label = sp[\"speaker\"]\n",
    "                break\n",
    "        output.append({\n",
    "            \"start\": seg[\"start\"],\n",
    "            \"end\": seg[\"end\"],\n",
    "            \"speaker\": speaker_label,\n",
    "            \"text\": seg[\"text\"].strip()\n",
    "        })\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e23243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 5: Identify speaker names via text cues (OpenAI) ---\n",
    "class Speaker(BaseModel):\n",
    "    id: str\n",
    "    name: str\n",
    "\n",
    "class ListSpeakers(BaseModel):\n",
    "    listSpeakers: list[Speaker]\n",
    "\n",
    "\n",
    "def identify_speaker_names_via_text(transcript: List[Dict]) -> Dict:\n",
    "    transcript_text = \"\\n\".join(\n",
    "        [f\"{seg['speaker']}: {seg['text']}\" for seg in transcript]\n",
    "    )\n",
    "    prompt = f\"\"\"\n",
    "    Below is the full transcript of a video, each line contains the speaker (SPEAKER_XX) and the dialogue.\n",
    "\n",
    "    Analyze to determine if there is any part where the speaker introduces himself or is introduced by someone else.\n",
    "\n",
    "    Returns a JSON result with the following structure:\n",
    "    {{\n",
    "      {{\n",
    "        id: \"SPEAKER_00\",\n",
    "        name: \"Name if available\",\n",
    "      }},\n",
    "      ...\n",
    "    }}\n",
    "\n",
    "    If not identified, returns the name field as \"Unnamed\".\n",
    "\n",
    "    Transcript:\n",
    "    {transcript_text}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.responses.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        text_format=ListSpeakers,\n",
    "    )\n",
    "\n",
    "    return response.output_parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9993052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_for_unknown_speakers(\n",
    "    video_path: str,\n",
    "    speaker_segments: List[Dict],\n",
    "    speaker_name_map,  # kiểu: ListSpeakers (đã chứa list[Speaker(id, name)])\n",
    "    output_dir: str = \"frames\",\n",
    "    max_frames_per_speaker: int = 5\n",
    "):\n",
    "    import os\n",
    "    import cv2\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Tạo dict lookup tên từ speaker_name_map\n",
    "    speaker_id_to_name = {s.id: s.name for s in speaker_name_map.listSpeakers}\n",
    "    speaker_frames = {}\n",
    "\n",
    "    for seg in speaker_segments:\n",
    "        spk = seg['speaker']\n",
    "        name = speaker_id_to_name.get(spk, \"\")\n",
    "        if name.startswith(\"Unnamed\"):\n",
    "            # Nếu đã đủ 5 frame thì bỏ qua\n",
    "            if spk in speaker_frames and len(speaker_frames[spk]) >= max_frames_per_speaker:\n",
    "                continue\n",
    "\n",
    "            mid_time = (seg['start'] + seg['end']) / 2\n",
    "            frame_num = int(mid_time * fps)\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                frame_path = os.path.join(output_dir, f\"{spk}_{int(seg['start'])}.jpg\")\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "                if spk not in speaker_frames:\n",
    "                    speaker_frames[spk] = []\n",
    "                speaker_frames[spk].append({\n",
    "                    \"time\": mid_time,\n",
    "                    \"frame_path\": frame_path,\n",
    "                    \"text\": seg[\"text\"]\n",
    "                })\n",
    "\n",
    "    cap.release()\n",
    "    return speaker_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f7b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def identify_unknown_speakers_with_gpt(speaker_frames: dict) -> dict:\n",
    "    \"\"\"\n",
    "    speaker_frames: {\n",
    "        \"SPEAKER_01\": [\n",
    "            {\"time\": ..., \"frame_path\": ..., \"text\": ...},\n",
    "            ...\n",
    "        ],\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    speaker_id_to_name = {}\n",
    "\n",
    "    for speaker_id, frames in speaker_frames.items():\n",
    "        print(f\"\\n🧠 Đang xử lý {speaker_id}...\")\n",
    "\n",
    "        # Chuẩn bị prompt chính\n",
    "        texts = [f'“{f[\"text\"]}”' for f in frames if f.get(\"text\")]\n",
    "        combined_text = \"\\n\".join(texts)  # Dùng tối đa 3 đoạn transcript\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "This is a collection of frames extracted from a video showing one speaker. Based on their appearance and the following quotes, can you identify who they are or make an educated guess?\n",
    "\n",
    "Quotes:\n",
    "{combined_text}\n",
    "\n",
    "Returns only the speaker's name (no further explanation needed).\n",
    "\n",
    "If you can't tell, reply with \"Unnamed\".\n",
    "\"\"\"\n",
    "\n",
    "        # Chuẩn bị ảnh\n",
    "        content_items = [{\"type\": \"input_text\", \"text\": prompt}]\n",
    "        for f in frames:\n",
    "            image_path = f[\"frame_path\"]  # đảm bảo đúng path\n",
    "            try:\n",
    "                base64_image = encode_image(image_path)\n",
    "                content_items.append({\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Không thể đọc ảnh {image_path}: {e}\")\n",
    "\n",
    "        # Gửi yêu cầu lên GPT\n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                input=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": content_items\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            name = response.output_text\n",
    "            speaker_id_to_name[speaker_id] = name\n",
    "            print(f\"✅ {speaker_id} → {name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error for {speaker_id}: {e}\")\n",
    "            speaker_id_to_name[speaker_id] = \"Unnamed\"\n",
    "\n",
    "    return speaker_id_to_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cae5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_named_transcript(transcript, speaker_name_map, new_names):\n",
    "    # Bước 1: Gộp tên từ speaker_name_map và new_names\n",
    "    speaker_lookup = {}\n",
    "    for speaker in speaker_name_map.listSpeakers:\n",
    "        speaker_id = speaker.id\n",
    "        # Ưu tiên tên từ new_names nếu có\n",
    "        name = new_names.get(speaker_id, speaker.name)\n",
    "        speaker_lookup[speaker_id] = name\n",
    "\n",
    "    # Bước 2: Tạo transcript cuối cùng\n",
    "    final_transcript = []\n",
    "    for seg in transcript:\n",
    "        spk = seg['speaker']\n",
    "        if spk == \"unknown\":\n",
    "            display_name = \"Unknown\"\n",
    "        else:\n",
    "            name = speaker_lookup.get(spk, spk)\n",
    "            display_name = name if name != \"Unnamed\" else spk\n",
    "\n",
    "        final_transcript.append({\n",
    "            \"start\": seg[\"start\"],\n",
    "            \"end\": seg[\"end\"],\n",
    "            \"speaker\": display_name,\n",
    "            \"text\": seg[\"text\"]\n",
    "        })\n",
    "\n",
    "    return final_transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4313bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Statement(BaseModel):\n",
    "    start: float\n",
    "    end: float\n",
    "    speaker: str\n",
    "    text: str\n",
    "    reason: str  # Tại sao cần kiểm chứng\n",
    "    context: str\n",
    "\n",
    "class ListStatement(BaseModel):\n",
    "    listStatment: List[Statement]\n",
    "\n",
    "\n",
    "def split_transcript(transcript, chunk_size=100):\n",
    "    \"\"\"Chia transcript thành các đoạn nhỏ để tránh quá dài\"\"\"\n",
    "    return [transcript[i:i+chunk_size] for i in range(0, len(transcript), chunk_size)]\n",
    "\n",
    "\n",
    "def find_checkworthy_statements(final_transcript, model=\"gpt-4o\"):\n",
    "    parts = split_transcript(final_transcript, chunk_size=300)\n",
    "    all_statements = []\n",
    "\n",
    "    for idx, part in enumerate(parts):\n",
    "        print(f\"🔍 Đang xử lý phần {idx+1}/{len(parts)}...\")\n",
    "\n",
    "        # Tạo văn bản nhập\n",
    "        lines = [f\"[{r['start']:.2f}-{r['end']:.2f}] {r['speaker']}: {r['text']}\" for r in part]\n",
    "        input_text = \"\\n\".join(lines)\n",
    "        print(input_text)\n",
    "\n",
    "        prompt = \"\"\"You are a professional fact-checking assistant.\n",
    "          Your job is to extract verbatim **checkworthy statements** from political transcripts, debates, interviews, or speeches.\n",
    "          Ignore statements from unknown speakers (e.g. \"Unknown:\", \"SPEAKER_XX:\")\n",
    "\n",
    "          A **checkworthy statement** typically:\n",
    "          - Contains a factual claim or statistic.\n",
    "          - Mentions historical events, conflicts, or political actions.\n",
    "          - Suggests a cause-effect relationship (e.g. \"if I were president, this would never happen\").\n",
    "          - Blames or credits someone for an outcome (e.g. immigration, war, economy).\n",
    "          - Makes bold or potentially controversial assertions.\n",
    "\n",
    "          Avoid:\n",
    "          - Statements from unknown speakers (e.g. \"Unknown:\", \"SPEAKER_XX:\")\n",
    "          - Opinions or vague generalities (e.g. \"I love America\").\n",
    "          - Greetings, filler speech, or rhetorical questions with no factual basis.\n",
    "\n",
    "          ### Output Format\n",
    "          Return a list of structured statements in this format:\n",
    "          - `start`: float → start time in seconds\n",
    "          - `end`: float → end time in seconds\n",
    "          - `speaker`: str → name of the speaker\n",
    "          - `text`: str → the exact quote **verbatim** that is checkworthy\n",
    "          - `reason`: str → short explanation why this should be fact-checked\n",
    "          - `context`: str → describing the **context** of the statement. This must include:\n",
    "            + Where the quote was made (e.g., in a presidential debate, TV interview, campaign rally, etc.) — infer this if possible\n",
    "            + When it occurred (date or relative time, e.g., \"during the 2024 campaign\", or \"in June 2025\") — infer from available information\n",
    "            + What topic was being discussed immediately before and after the statement (e.g., foreign policy, immigration, etc.)\n",
    "            + If the speaker was responding to a question or another speaker, note that as well\n",
    "          \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.responses.parse(\n",
    "                model=model,\n",
    "                input=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": prompt,\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": input_text,\n",
    "                    },\n",
    "                ],\n",
    "                text_format=ListStatement,\n",
    "            )\n",
    "            statements = response.output_parsed.listStatment\n",
    "            all_statements.extend(statements)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Lỗi ở phần {idx+1}: {e}\")\n",
    "\n",
    "    return all_statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535eb539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frame_for_statement(video_path: str, statement, output_dir=\"statement_frames\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    mid_time = (statement.start + statement.end) / 2\n",
    "    frame_num = int(mid_time * fps)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        filename = f\"{statement.speaker}_{int(statement.start*100):06d}.jpg\"\n",
    "        frame_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        return frame_path\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_statements_from_video(video_path: str):\n",
    "    \"\"\"\n",
    "    Extracts the transcript from a video file.\n",
    "    \"\"\"\n",
    "    print(\"🎬 Extracting audio...\")\n",
    "    audio_path = extract_audio(video_path)\n",
    "    \n",
    "    print(\"🔊 Diarizing speakers...\")\n",
    "    speakers = diarize_audio(audio_path)\n",
    "    \n",
    "    print(\"📝 Transcribing...\")\n",
    "    segments = transcribe_audio(audio_path)\n",
    "    \n",
    "    print(\"👥 Assigning speakers...\")\n",
    "    transcript = assign_speakers(segments, speakers)\n",
    "\n",
    "    print(\"🧠 Inferring speaker names from transcript...\")\n",
    "    speaker_name_map = identify_speaker_names_via_text(transcript)\n",
    "    \n",
    "    print(\"🖼️ Extracting frames for unknown speakers...\")\n",
    "    speaker_frames = extract_frames_for_unknown_speakers(video_path, transcript, speaker_name_map)\n",
    "    \n",
    "    print(\"🤖 Identifying unknown speakers with GPT...\")\n",
    "    new_names = identify_unknown_speakers_with_gpt(speaker_frames)\n",
    "\n",
    "    print(\"📜 Generating final transcript...\")\n",
    "    final = generate_named_transcript(transcript, speaker_name_map, new_names)\n",
    "    \n",
    "    print(\"🔍 Finding checkworthy statements...\")\n",
    "    final_statements = find_checkworthy_statements(final)\n",
    "    \n",
    "    print(f\"✅ Found {len(final_statements)} checkworthy statements.\")\n",
    "    \n",
    "    final_statements_json = []\n",
    "\n",
    "    for s in final_statements:\n",
    "        frame_path = extract_frame_for_statement(video_path, s)\n",
    "\n",
    "        statement_dict = s.dict()\n",
    "        statement_dict[\"frame_path\"] = frame_path or \"N/A\"\n",
    "\n",
    "        final_statements_json.append(statement_dict)\n",
    "    \n",
    "    return final_statements_json\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb3c65",
   "metadata": {},
   "source": [
    "# Part 3: Deepfake prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_video_into_clips(final_statements_json, video_path: str):\n",
    "    \"\"\"\n",
    "    Cuts the video into clips based on the provided statements.\n",
    "    \"\"\"\n",
    "    clip_dir = os.path.join(\"statement_clips\", os.path.splitext(os.path.basename(video_path))[0])\n",
    "    os.makedirs(clip_dir, exist_ok=True)\n",
    "\n",
    "    for i, s in enumerate(final_statements_json):\n",
    "        start, end = s['start'], s['end']\n",
    "        clip_path = os.path.join(clip_dir, f\"clip_{i+1}.mp4\")\n",
    "\n",
    "        print(f\"✂️ Cutting {clip_path} from {start}s to {end}s\")\n",
    "        clip = VideoFileClip(video_path).subclip(start, end)\n",
    "        clip.write_videofile(clip_path, codec=\"libx264\", audio_codec=\"aac\", verbose=False, logger=None)\n",
    "    \n",
    "    print(f\"✅ Finished cutting video into clips. Saved to {clip_dir}\")\n",
    "    return clip_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_api_detect_deepfake(clip_dir: str):\n",
    "    \"\"\"\n",
    "    Detects deepfake in the video clips.\n",
    "    \"\"\"\n",
    "    # Tạo danh sách file để gửi\n",
    "    video_files = []\n",
    "    for filename in os.listdir(CLIP_DIR):\n",
    "        if filename.endswith(\".mp4\"):\n",
    "            file_path = os.path.join(CLIP_DIR, filename)\n",
    "            video_files.append((\"videos\", (filename, open(file_path, \"rb\"), \"video/mp4\")))\n",
    "\n",
    "    # Gửi yêu cầu POST\n",
    "    print(\"📤 Sending batch videos to deepfake API...\")\n",
    "    response = requests.post(API_URL, files=video_files)\n",
    "\n",
    "    # Kết quả\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(\"✅ Detection results:\")\n",
    "        for fname, r in result.items():\n",
    "            print(f\"{fname}: {r}\")\n",
    "        return result\n",
    "    else:\n",
    "        print(f\"❌ Error {response.status_code}: {response.text}\")\n",
    "        \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1987dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_deepfake(final_statements_json, video_path: str):\n",
    "    \"\"\"\n",
    "    Main function to detect deepfake in the video.\n",
    "    \"\"\"\n",
    "    print(\"🎥 Cutting video into clips...\")\n",
    "    clip_dir = cut_video_into_clips(final_statements_json, video_path)\n",
    "\n",
    "    print(\"🔍 Detecting deepfake in clips...\")\n",
    "    results = call_api_detect_deepfake(clip_dir)\n",
    "\n",
    "    for idx, statement in enumerate(final_statements_json):\n",
    "        clip_name = f\"clip_{idx+1}.mp4\"\n",
    "        result = results.get(clip_name, {})\n",
    "        \n",
    "        # Lấy nhãn deepfake nếu có\n",
    "        label = result.get(\"pred_label\", [\"unknown\"])[0]\n",
    "        \n",
    "        # Gắn vào statement\n",
    "        statement[\"deepfake_label\"] = label\n",
    "    \n",
    "    print(\"✅ Finished detecting deepfake.\")\n",
    "    return final_statements_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58286fb",
   "metadata": {},
   "source": [
    "# Part 4: Crawl related articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4cd42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_relevant_links(query):\n",
    "  driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "  prompt = f'https://www.bing.com/search?q={query}'\n",
    "  print(prompt)\n",
    "  driver.get(prompt)\n",
    "  time.sleep(random.uniform(1, 10))\n",
    "  # print(driver.page_source)\n",
    "\n",
    "  articles = driver.find_elements(By.CSS_SELECTOR, \"#b_results li.b_algo\")\n",
    "  link_articles = []\n",
    "  link_articles.append({\n",
    "      'title': query[:30],\n",
    "      'link': prompt,\n",
    "      # 'summary': summary\n",
    "  })\n",
    "  print(f\"Found {len(articles)} relevant links:\\n{articles}\")\n",
    "  for article in articles[:MINIMUM_K]:  # Giới hạn lấy 5 kết quả đầu tiên\n",
    "    try:\n",
    "      title_element = article.find_element(By.TAG_NAME, \"h2\").find_element(By.TAG_NAME, \"a\")\n",
    "      title = title_element.text\n",
    "      link = title_element.get_attribute('href')\n",
    "      # summary = article.find_element(By.CLASS_NAME, 'css-16nhkrn').text\n",
    "      # local = local_query(link)\n",
    "      link_articles.append({\n",
    "          'title': title,\n",
    "          'link': link,\n",
    "          # 'summary': summary\n",
    "      })\n",
    "      print(title)\n",
    "      print(link)\n",
    "    except Exception as e:\n",
    "        print(\"Lỗi khi trích xuất bài viết:\", e)\n",
    "  driver.quit()\n",
    "\n",
    "  print(f\"Found {len(link_articles)} relevant links:\\n{link_articles}\")\n",
    "\n",
    "  return link_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376faf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_dismiss_popups(driver):\n",
    "    try:\n",
    "        # Các nút phổ biến cần nhấn\n",
    "        popup_texts = [\n",
    "            \"Accept Cookies\", \"Accept All Cookies\", \"I Accept\",\n",
    "            \"Agree\", \"Press & Hold\", \"Continue\"\n",
    "        ]\n",
    "        for text in popup_texts:\n",
    "            try:\n",
    "                btn = driver.find_element(\n",
    "                    By.XPATH,\n",
    "                    f\"//button[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{text.lower()}')]\"\n",
    "                )\n",
    "                btn.click()\n",
    "                print(f\"✅ Clicked popup button: '{text}'\")\n",
    "                break\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "            except ElementClickInterceptedException:\n",
    "                continue\n",
    "\n",
    "        # Tìm các nút có class name chứa 'close'\n",
    "        close_candidates = driver.find_elements(By.XPATH, \"//button[contains(@class, 'close') or contains(translate(@aria-label, 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'close')]\")\n",
    "\n",
    "        for btn in close_candidates:\n",
    "            try:\n",
    "                btn.click()\n",
    "                print(\"✅ Clicked a close button\")\n",
    "                break\n",
    "            except (ElementClickInterceptedException, Exception):\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error while dismissing popup: {e}\")\n",
    "\n",
    "def process_article_link(article, max_retries=5):\n",
    "    \"\"\"Hàm xử lý một liên kết riêng lẻ và trả về nội dung gộp các thẻ <p>\"\"\"\n",
    "    article_crawl = {\n",
    "        \"title\": article['title'],\n",
    "        \"src\": article['link'],\n",
    "        \"contents\": \"\"  # gộp tất cả <p> vào 1 chuỗi\n",
    "    }\n",
    "\n",
    "    success = False\n",
    "    wait_time = 10  # thời gian chờ ban đầu (giây)\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        try:\n",
    "            print(f\"⏳ Attempt {attempt}: Crawling {article['link']} with wait_time={wait_time}s\")\n",
    "            driver.get(article['link'])\n",
    "            time.sleep(wait_time)\n",
    "            try_dismiss_popups(driver)\n",
    "\n",
    "            all_elements = driver.find_elements(By.XPATH, \".//p\")\n",
    "            contents = []\n",
    "\n",
    "            for element in all_elements:\n",
    "                if element.tag_name == \"p\":\n",
    "                    text_content = element.get_attribute(\"innerText\").strip()\n",
    "                    if text_content:\n",
    "                        contents.append(text_content)\n",
    "\n",
    "            article_crawl[\"contents\"] = \"\\n\".join(contents)\n",
    "            print(f'✅ Crawled content from {article[\"link\"]}:\\n{article_crawl[\"contents\"][:500]}...')  # in 500 ký tự đầu tiên\n",
    "            success = True\n",
    "            break  # thành công thì thoát\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Attempt {attempt} failed for {article['link']}: {e}\")\n",
    "            wait_time += 300  # tăng thời gian chờ thêm 10s cho mỗi lần thử lại\n",
    "\n",
    "        finally:\n",
    "            driver.quit()\n",
    "\n",
    "    if not success:\n",
    "        print(f\"❌ Failed to crawl article from {article['link']} after {max_retries} attempts.\")\n",
    "\n",
    "    return article_crawl\n",
    "\n",
    "\n",
    "\n",
    "def crawl_articles(query, crawl_json):\n",
    "    \"\"\"Hàm chính để crawl các trang khác\"\"\"\n",
    "    url_articles = search_relevant_links(query)\n",
    "\n",
    "    # Giới hạn số lượng link cần crawl\n",
    "    url_articles = url_articles[:MINIMUM_K]\n",
    "\n",
    "    # Sử dụng Multi-threading để chạy nhiều request song song\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        result = list(executor.map(process_article_link, url_articles))\n",
    "\n",
    "    # Gộp kết quả vào crawl_json\n",
    "    crawl_json.extend(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_statement(statement):\n",
    "    query = statement[\"text\"].strip('\"')\n",
    "    crawl_json = []\n",
    "\n",
    "    # Crawl theo statement\n",
    "    crawl_articles(query, crawl_json=crawl_json)\n",
    "\n",
    "    # Crawl thêm theo context\n",
    "    context = statement[\"context\"]\n",
    "    crawl_articles(query=context, crawl_json=crawl_json)\n",
    "\n",
    "    # Loại bỏ các kết quả None\n",
    "    crawl_json = [item for item in crawl_json if item is not None]\n",
    "\n",
    "    # Nối lại toàn bộ nội dung: thêm title và content mỗi bài\n",
    "    article_texts = \"\\n\\n\".join(\n",
    "        f\"### {item.get('title', 'No Title')}\\n{item.get('contents', '').strip()}\"\n",
    "        for item in crawl_json\n",
    "        if item.get(\"contents\")\n",
    "    )\n",
    "\n",
    "    # Trả lại enriched statement\n",
    "    enriched_statement = statement.copy()\n",
    "    enriched_statement[\"article_texts\"] = article_texts.strip()\n",
    "\n",
    "    return enriched_statement\n",
    "\n",
    "\n",
    "def enrich_statements_with_articles(final_statements_json):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        return list(executor.map(process_single_statement, final_statements_json))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577ea3f",
   "metadata": {},
   "source": [
    "# Part 5: Fact-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactCheck(BaseModel):\n",
    "    sentence: str\n",
    "    label: bool  # True = SUPPORTED, False = REFUTED\n",
    "    explanation: str\n",
    "    revised_sentence: str\n",
    "\n",
    "def fact_check(statement, article_texts=\"\"):\n",
    "    article_texts = statement['article_texts']\n",
    "    prompt = f\"\"\"\n",
    "You are a professional fact-checking assistant. Your task is to verify whether a given statement made by a public figure is factually accurate, using the reference documents provided.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "Follow this two-step fact-checking process:\n",
    "\n",
    "1. **Verify if the speaker actually made this statement**:\n",
    "   - Search the reference documents to determine whether the speaker is directly or credibly quoted as having said this, or something semantically equivalent.\n",
    "   - If such a quote or statement from the speaker is found, then:\n",
    "     - **Label = true**\n",
    "     - Provide an explanation saying the speaker did make this statement.\n",
    "     - Return the original sentence as `revised_sentence`.\n",
    "     - Do not evaluate the factual accuracy of the content — if the quote is confirmed, assume it is real.\n",
    "\n",
    "2. **If there is no evidence that the speaker made this statement**, proceed to assess the **factual accuracy** of the statement based on the reference documents:\n",
    "   - If it is supported by evidence, label as **true**, provide reasoning, and return the original sentence.\n",
    "   - If it is misleading or incorrect, label as **false**, explain why, and rewrite it correctly using only facts from the documents.\n",
    "\n",
    "Use only the information in the documents. Do not speculate or assume intent. Be concise and precise.\n",
    "\n",
    "### Context:\n",
    "{statement['context']}\n",
    "\n",
    "### Speaker:\n",
    "{statement['speaker']}\n",
    "\n",
    "### Statement:\n",
    "\"{statement['text']}\"\n",
    "\n",
    "### Documents:\n",
    "{article_texts}\n",
    "\n",
    "### Output format:\n",
    "- sentence: original statement\n",
    "- label: true (supported) or false (refuted)\n",
    "- explanation: why the statement is supported/refuted\n",
    "- revised_sentence: corrected version if refuted, or original statement if supported\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.responses.parse(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a medical fact-checking expert.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            text_format=FactCheck\n",
    "        )\n",
    "        result = response.output_parsed\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Problem with API: {e}\")\n",
    "        result = \"Unverified\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9219172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_check_single_statement(statement):\n",
    "    print(statement)\n",
    "    text = statement[\"text\"]\n",
    "    article_texts = statement.get(\"article_texts\", \"\")\n",
    "\n",
    "    print(f\"🧐 Fact-checking: {text[:80]}...\")\n",
    "\n",
    "    result = fact_check(statement)\n",
    "\n",
    "    if result == \"Unverified\":\n",
    "        statement[\"label\"] = None\n",
    "        statement[\"explanation\"] = \"Unverified due to API error.\"\n",
    "        statement[\"revised_statement\"] = text\n",
    "    else:\n",
    "        statement[\"label\"] = result.label\n",
    "        statement[\"explanation\"] = result.explanation\n",
    "        statement[\"revised_statement\"] = result.revised_sentence\n",
    "\n",
    "    return statement\n",
    "\n",
    "\n",
    "def run_fact_checks_parallel(enriched_statements, max_workers=4):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(fact_check_single_statement, enriched_statements))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd2a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_check_video(video_path: str):\n",
    "    \"\"\"\n",
    "    Main function to fact-check the video.\n",
    "    \"\"\"\n",
    "    print(\"🎥 Extracting statements from video...\")\n",
    "    final_statements_json = extract_statements_from_video(video_path)\n",
    "\n",
    "    print(\"🔍 Detecting deepfake...\")\n",
    "    final_statements_json = detect_deepfake(final_statements_json, video_path)\n",
    "    \n",
    "    for statement in final_statements_json:\n",
    "        if statement.get(\"pred_label\") == \"FAKE\":\n",
    "            print(f\"⚠️ Statement {statement['text']} is marked as deepfake. Skipping fact-check.\")\n",
    "            return False\n",
    "\n",
    "\n",
    "    print(\"📰 Enriching statements with articles...\")\n",
    "    enriched_statements = enrich_statements_with_articles(final_statements_json)\n",
    "\n",
    "    print(\"✅ Finished enriching statements with articles.\")\n",
    "\n",
    "    print(\"🧪 Running fact-checks on statements...\")\n",
    "    fact_checked_results = run_fact_checks_parallel(enriched_statements)\n",
    "\n",
    "    for result in enumerate(fact_checked_results):\n",
    "        if result.label == \"False\":\n",
    "            print(f\"❌ Statement '{result.sentence}' is refuted: {result.explanation}\")\n",
    "            return False\n",
    "    \n",
    "    print(\"✅ All statements are supported or unverified.\")\n",
    "    return True\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e615209e",
   "metadata": {},
   "source": [
    "# Part 6: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3336f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = \"../data/dfw_youtube_release\"\n",
    "\n",
    "video_files = [\n",
    "    os.path.join(VIDEO_DIR, f) for f in os.listdir(VIDEO_DIR)\n",
    "    if f.endswith((\".mp4\", \".avi\", \".mov\"))\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for video_path in video_files:\n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    try:\n",
    "        result = fact_check_video(video_path)\n",
    "        if result:\n",
    "            print(f\"✅ Video {video_path} passed the fact-check.\")\n",
    "        else:\n",
    "            print(f\"❌ Video {video_path} failed the fact-check.\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing video {video_path}: {e}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"video_path\": video_path,   \n",
    "        \"result\": result\n",
    "    })\n",
    "\n",
    "# Save results to a file\n",
    "import json\n",
    "with open(\"fact_check_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
