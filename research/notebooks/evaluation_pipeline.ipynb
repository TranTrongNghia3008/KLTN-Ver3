{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9adbf56",
   "metadata": {},
   "source": [
    "# Part 1: Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd2845",
   "metadata": {},
   "source": [
    "## 1.1 Install Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a46a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22027d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install pyannote.audio\n",
    "!pip install moviepy opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca86f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub[hf_xet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33261970",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromedriver-autoinstaller\n",
    "!apt-get update\n",
    "!apt-get install -y chromium-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce3c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for running selenium in Google Colab\n",
    "## You don't need to run this code if you do it in Jupyter notebook, or other local Python setting\n",
    "%%shell\n",
    "sudo apt -y update\n",
    "sudo apt install -y wget curl unzip\n",
    "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
    "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
    "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
    "dpkg -i google-chrome-stable_current_amd64.deb\n",
    "CHROME_DRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`\n",
    "wget -N https://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip -P /tmp/\n",
    "unzip -o /tmp/chromedriver_linux64.zip -d /tmp/\n",
    "chmod +x /tmp/chromedriver\n",
    "mv /tmp/chromedriver /usr/local/bin/chromedriver\n",
    "pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c97dc1",
   "metadata": {},
   "source": [
    "## 1.2 Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9327cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1411688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "from pyannote.audio import Pipeline\n",
    "from typing import List, Dict\n",
    "import yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b13240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df685bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b6dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For crawling data\n",
    "import chromedriver_autoinstaller\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import concurrent.futures\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException, NoSuchElementException, ElementClickInterceptedException\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b59196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8569af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c0161",
   "metadata": {},
   "source": [
    "## 1.3 Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a81aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf38943",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"http://localhost:8000/deepfake/detect/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Chromedriver\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')  # Run in headless mode\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--window-size=1920x1080')  # Ensure the window size is large enough\n",
    "\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "chrome_options.add_argument(\"accept-language=en-US,en;q=0.9\")\n",
    "chrome_options.add_argument(\"referer=https://www.google.com/\")\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "chrome_options.add_argument(\n",
    "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.6478.57 Safari/537.36\"\n",
    ")\n",
    "chrome_options.binary_location = '/usr/bin/chromium-browser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd41f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIMUM_K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9645c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key = OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0699a806",
   "metadata": {},
   "source": [
    "# Part 2: Extract statements that need fact-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825bb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 1: Extract audio from video ---\n",
    "def extract_audio(video_path: str, audio_dir: str = \"audios\") -> str:\n",
    "    if not os.path.exists(audio_dir):\n",
    "        os.makedirs(audio_dir)\n",
    "    video = VideoFileClip(video_path)\n",
    "    audio_path = os.path.basename(video_path).replace('.mp4', '.wav')\n",
    "    audio_path = os.path.join(audio_dir, audio_path)\n",
    "    if os.path.exists(audio_path):\n",
    "        os.remove(audio_path)\n",
    "    video.audio.write_audiofile(audio_path)\n",
    "    return audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc2022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 2: Diarize audio (identify speakers) ---\n",
    "def diarize_audio(audio_path: str) -> List[Dict]:\n",
    "    pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\", use_auth_token=HUGGINGFACE_TOKEN)\n",
    "    diarization = pipeline(audio_path)\n",
    "    speakers = []\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        speakers.append({\n",
    "            \"start\": turn.start,\n",
    "            \"end\": turn.end,\n",
    "            \"speaker\": speaker\n",
    "        })\n",
    "    return speakers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc41532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 3: Transcribe audio ---\n",
    "def transcribe_audio(audio_path: str) -> List[Dict]:\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"segments\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35273564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 4: Assign speakers to transcript segments ---\n",
    "def assign_speakers(segments: List[Dict], speakers: List[Dict]) -> List[Dict]:\n",
    "    output = []\n",
    "    for seg in segments:\n",
    "        speaker_label = \"unknown\"\n",
    "        for sp in speakers:\n",
    "            if sp[\"start\"] <= seg[\"start\"] <= sp[\"end\"]:\n",
    "                speaker_label = sp[\"speaker\"]\n",
    "                break\n",
    "        output.append({\n",
    "            \"start\": seg[\"start\"],\n",
    "            \"end\": seg[\"end\"],\n",
    "            \"speaker\": speaker_label,\n",
    "            \"text\": seg[\"text\"].strip()\n",
    "        })\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e23243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 5: Identify speaker names via text cues (OpenAI) ---\n",
    "class Speaker(BaseModel):\n",
    "    id: str\n",
    "    name: str\n",
    "\n",
    "class ListSpeakers(BaseModel):\n",
    "    listSpeakers: list[Speaker]\n",
    "\n",
    "\n",
    "def identify_speaker_names_via_text(transcript: List[Dict]) -> Dict:\n",
    "    transcript_text = \"\\n\".join(\n",
    "        [f\"{seg['speaker']}: {seg['text']}\" for seg in transcript]\n",
    "    )\n",
    "    prompt = f\"\"\"\n",
    "    Below is the full transcript of a video, each line contains the speaker (SPEAKER_XX) and the dialogue.\n",
    "\n",
    "    Analyze to determine if there is any part where the speaker introduces himself or is introduced by someone else.\n",
    "\n",
    "    Returns a JSON result with the following structure:\n",
    "    {{\n",
    "      {{\n",
    "        id: \"SPEAKER_00\",\n",
    "        name: \"Name if available\",\n",
    "      }},\n",
    "      ...\n",
    "    }}\n",
    "\n",
    "    If not identified, returns the name field as \"Unnamed\".\n",
    "\n",
    "    Transcript:\n",
    "    {transcript_text}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.responses.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        text_format=ListSpeakers,\n",
    "    )\n",
    "\n",
    "    return response.output_parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9993052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_for_unknown_speakers(\n",
    "    video_path: str,\n",
    "    speaker_segments: List[Dict],\n",
    "    speaker_name_map,  # ki·ªÉu: ListSpeakers (ƒë√£ ch·ª©a list[Speaker(id, name)])\n",
    "    output_dir: str = \"frames\",\n",
    "    max_frames_per_speaker: int = 5\n",
    "):\n",
    "    import os\n",
    "    import cv2\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # T·∫°o dict lookup t√™n t·ª´ speaker_name_map\n",
    "    speaker_id_to_name = {s.id: s.name for s in speaker_name_map.listSpeakers}\n",
    "    speaker_frames = {}\n",
    "\n",
    "    for seg in speaker_segments:\n",
    "        spk = seg['speaker']\n",
    "        name = speaker_id_to_name.get(spk, \"\")\n",
    "        if name.startswith(\"Unnamed\"):\n",
    "            # N·∫øu ƒë√£ ƒë·ªß 5 frame th√¨ b·ªè qua\n",
    "            if spk in speaker_frames and len(speaker_frames[spk]) >= max_frames_per_speaker:\n",
    "                continue\n",
    "\n",
    "            mid_time = (seg['start'] + seg['end']) / 2\n",
    "            frame_num = int(mid_time * fps)\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                frame_path = os.path.join(output_dir, f\"{spk}_{int(seg['start'])}.jpg\")\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "                if spk not in speaker_frames:\n",
    "                    speaker_frames[spk] = []\n",
    "                speaker_frames[spk].append({\n",
    "                    \"time\": mid_time,\n",
    "                    \"frame_path\": frame_path,\n",
    "                    \"text\": seg[\"text\"]\n",
    "                })\n",
    "\n",
    "    cap.release()\n",
    "    return speaker_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f7b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def identify_unknown_speakers_with_gpt(speaker_frames: dict) -> dict:\n",
    "    \"\"\"\n",
    "    speaker_frames: {\n",
    "        \"SPEAKER_01\": [\n",
    "            {\"time\": ..., \"frame_path\": ..., \"text\": ...},\n",
    "            ...\n",
    "        ],\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    speaker_id_to_name = {}\n",
    "\n",
    "    for speaker_id, frames in speaker_frames.items():\n",
    "        print(f\"\\nüß† ƒêang x·ª≠ l√Ω {speaker_id}...\")\n",
    "\n",
    "        # Chu·∫©n b·ªã prompt ch√≠nh\n",
    "        texts = [f'‚Äú{f[\"text\"]}‚Äù' for f in frames if f.get(\"text\")]\n",
    "        combined_text = \"\\n\".join(texts)  # D√πng t·ªëi ƒëa 3 ƒëo·∫°n transcript\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "This is a collection of frames extracted from a video showing one speaker. Based on their appearance and the following quotes, can you identify who they are or make an educated guess?\n",
    "\n",
    "Quotes:\n",
    "{combined_text}\n",
    "\n",
    "Returns only the speaker's name (no further explanation needed).\n",
    "\n",
    "If you can't tell, reply with \"Unnamed\".\n",
    "\"\"\"\n",
    "\n",
    "        # Chu·∫©n b·ªã ·∫£nh\n",
    "        content_items = [{\"type\": \"input_text\", \"text\": prompt}]\n",
    "        for f in frames:\n",
    "            image_path = f[\"frame_path\"]  # ƒë·∫£m b·∫£o ƒë√∫ng path\n",
    "            try:\n",
    "                base64_image = encode_image(image_path)\n",
    "                content_items.append({\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh {image_path}: {e}\")\n",
    "\n",
    "        # G·ª≠i y√™u c·∫ßu l√™n GPT\n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                input=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": content_items\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            name = response.output_text\n",
    "            speaker_id_to_name[speaker_id] = name\n",
    "            print(f\"‚úÖ {speaker_id} ‚Üí {name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error for {speaker_id}: {e}\")\n",
    "            speaker_id_to_name[speaker_id] = \"Unnamed\"\n",
    "\n",
    "    return speaker_id_to_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cae5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_named_transcript(transcript, speaker_name_map, new_names):\n",
    "    # B∆∞·ªõc 1: G·ªôp t√™n t·ª´ speaker_name_map v√† new_names\n",
    "    speaker_lookup = {}\n",
    "    for speaker in speaker_name_map.listSpeakers:\n",
    "        speaker_id = speaker.id\n",
    "        # ∆Øu ti√™n t√™n t·ª´ new_names n·∫øu c√≥\n",
    "        name = new_names.get(speaker_id, speaker.name)\n",
    "        speaker_lookup[speaker_id] = name\n",
    "\n",
    "    # B∆∞·ªõc 2: T·∫°o transcript cu·ªëi c√πng\n",
    "    final_transcript = []\n",
    "    for seg in transcript:\n",
    "        spk = seg['speaker']\n",
    "        if spk == \"unknown\":\n",
    "            display_name = \"Unknown\"\n",
    "        else:\n",
    "            name = speaker_lookup.get(spk, spk)\n",
    "            display_name = name if name != \"Unnamed\" else spk\n",
    "\n",
    "        final_transcript.append({\n",
    "            \"start\": seg[\"start\"],\n",
    "            \"end\": seg[\"end\"],\n",
    "            \"speaker\": display_name,\n",
    "            \"text\": seg[\"text\"]\n",
    "        })\n",
    "\n",
    "    return final_transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4313bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Statement(BaseModel):\n",
    "    start: float\n",
    "    end: float\n",
    "    speaker: str\n",
    "    text: str\n",
    "    reason: str  # T·∫°i sao c·∫ßn ki·ªÉm ch·ª©ng\n",
    "    context: str\n",
    "\n",
    "class ListStatement(BaseModel):\n",
    "    listStatment: List[Statement]\n",
    "\n",
    "\n",
    "def split_transcript(transcript, chunk_size=100):\n",
    "    \"\"\"Chia transcript th√†nh c√°c ƒëo·∫°n nh·ªè ƒë·ªÉ tr√°nh qu√° d√†i\"\"\"\n",
    "    return [transcript[i:i+chunk_size] for i in range(0, len(transcript), chunk_size)]\n",
    "\n",
    "\n",
    "def find_checkworthy_statements(final_transcript, model=\"gpt-4o\"):\n",
    "    parts = split_transcript(final_transcript, chunk_size=300)\n",
    "    all_statements = []\n",
    "\n",
    "    for idx, part in enumerate(parts):\n",
    "        print(f\"üîç ƒêang x·ª≠ l√Ω ph·∫ßn {idx+1}/{len(parts)}...\")\n",
    "\n",
    "        # T·∫°o vƒÉn b·∫£n nh·∫≠p\n",
    "        lines = [f\"[{r['start']:.2f}-{r['end']:.2f}] {r['speaker']}: {r['text']}\" for r in part]\n",
    "        input_text = \"\\n\".join(lines)\n",
    "        print(input_text)\n",
    "\n",
    "        prompt = \"\"\"You are a professional fact-checking assistant.\n",
    "          Your job is to extract verbatim **checkworthy statements** from political transcripts, debates, interviews, or speeches.\n",
    "          Ignore statements from unknown speakers (e.g. \"Unknown:\", \"SPEAKER_XX:\")\n",
    "\n",
    "          A **checkworthy statement** typically:\n",
    "          - Contains a factual claim or statistic.\n",
    "          - Mentions historical events, conflicts, or political actions.\n",
    "          - Suggests a cause-effect relationship (e.g. \"if I were president, this would never happen\").\n",
    "          - Blames or credits someone for an outcome (e.g. immigration, war, economy).\n",
    "          - Makes bold or potentially controversial assertions.\n",
    "\n",
    "          Avoid:\n",
    "          - Statements from unknown speakers (e.g. \"Unknown:\", \"SPEAKER_XX:\")\n",
    "          - Opinions or vague generalities (e.g. \"I love America\").\n",
    "          - Greetings, filler speech, or rhetorical questions with no factual basis.\n",
    "\n",
    "          ### Output Format\n",
    "          Return a list of structured statements in this format:\n",
    "          - `start`: float ‚Üí start time in seconds\n",
    "          - `end`: float ‚Üí end time in seconds\n",
    "          - `speaker`: str ‚Üí name of the speaker\n",
    "          - `text`: str ‚Üí the exact quote **verbatim** that is checkworthy\n",
    "          - `reason`: str ‚Üí short explanation why this should be fact-checked\n",
    "          - `context`: str ‚Üí describing the **context** of the statement. This must include:\n",
    "            + Where the quote was made (e.g., in a presidential debate, TV interview, campaign rally, etc.) ‚Äî infer this if possible\n",
    "            + When it occurred (date or relative time, e.g., \"during the 2024 campaign\", or \"in June 2025\") ‚Äî infer from available information\n",
    "            + What topic was being discussed immediately before and after the statement (e.g., foreign policy, immigration, etc.)\n",
    "            + If the speaker was responding to a question or another speaker, note that as well\n",
    "          \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.responses.parse(\n",
    "                model=model,\n",
    "                input=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": prompt,\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": input_text,\n",
    "                    },\n",
    "                ],\n",
    "                text_format=ListStatement,\n",
    "            )\n",
    "            statements = response.output_parsed.listStatment\n",
    "            all_statements.extend(statements)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå L·ªói ·ªü ph·∫ßn {idx+1}: {e}\")\n",
    "\n",
    "    return all_statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535eb539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frame_for_statement(video_path: str, statement, output_dir=\"statement_frames\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    mid_time = (statement.start + statement.end) / 2\n",
    "    frame_num = int(mid_time * fps)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        filename = f\"{statement.speaker}_{int(statement.start*100):06d}.jpg\"\n",
    "        frame_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        return frame_path\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_statements_from_video(video_path: str):\n",
    "    \"\"\"\n",
    "    Extracts the transcript from a video file.\n",
    "    \"\"\"\n",
    "    print(\"üé¨ Extracting audio...\")\n",
    "    audio_path = extract_audio(video_path)\n",
    "    \n",
    "    print(\"üîä Diarizing speakers...\")\n",
    "    speakers = diarize_audio(audio_path)\n",
    "    \n",
    "    print(\"üìù Transcribing...\")\n",
    "    segments = transcribe_audio(audio_path)\n",
    "    \n",
    "    print(\"üë• Assigning speakers...\")\n",
    "    transcript = assign_speakers(segments, speakers)\n",
    "\n",
    "    print(\"üß† Inferring speaker names from transcript...\")\n",
    "    speaker_name_map = identify_speaker_names_via_text(transcript)\n",
    "    \n",
    "    print(\"üñºÔ∏è Extracting frames for unknown speakers...\")\n",
    "    speaker_frames = extract_frames_for_unknown_speakers(video_path, transcript, speaker_name_map)\n",
    "    \n",
    "    print(\"ü§ñ Identifying unknown speakers with GPT...\")\n",
    "    new_names = identify_unknown_speakers_with_gpt(speaker_frames)\n",
    "\n",
    "    print(\"üìú Generating final transcript...\")\n",
    "    final = generate_named_transcript(transcript, speaker_name_map, new_names)\n",
    "    \n",
    "    print(\"üîç Finding checkworthy statements...\")\n",
    "    final_statements = find_checkworthy_statements(final)\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(final_statements)} checkworthy statements.\")\n",
    "    \n",
    "    final_statements_json = []\n",
    "\n",
    "    for s in final_statements:\n",
    "        frame_path = extract_frame_for_statement(video_path, s)\n",
    "\n",
    "        statement_dict = s.dict()\n",
    "        statement_dict[\"frame_path\"] = frame_path or \"N/A\"\n",
    "\n",
    "        final_statements_json.append(statement_dict)\n",
    "    \n",
    "    return final_statements_json\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb3c65",
   "metadata": {},
   "source": [
    "# Part 3: Deepfake prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_video_into_clips(final_statements_json, video_path: str):\n",
    "    \"\"\"\n",
    "    Cuts the video into clips based on the provided statements.\n",
    "    \"\"\"\n",
    "    clip_dir = os.path.join(\"statement_clips\", os.path.splitext(os.path.basename(video_path))[0])\n",
    "    os.makedirs(clip_dir, exist_ok=True)\n",
    "\n",
    "    for i, s in enumerate(final_statements_json):\n",
    "        start, end = s['start'], s['end']\n",
    "        clip_path = os.path.join(clip_dir, f\"clip_{i+1}.mp4\")\n",
    "\n",
    "        print(f\"‚úÇÔ∏è Cutting {clip_path} from {start}s to {end}s\")\n",
    "        clip = VideoFileClip(video_path).subclip(start, end)\n",
    "        clip.write_videofile(clip_path, codec=\"libx264\", audio_codec=\"aac\", verbose=False, logger=None)\n",
    "    \n",
    "    print(f\"‚úÖ Finished cutting video into clips. Saved to {clip_dir}\")\n",
    "    return clip_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_api_detect_deepfake(clip_dir: str):\n",
    "    \"\"\"\n",
    "    Detects deepfake in the video clips.\n",
    "    \"\"\"\n",
    "    # T·∫°o danh s√°ch file ƒë·ªÉ g·ª≠i\n",
    "    video_files = []\n",
    "    for filename in os.listdir(CLIP_DIR):\n",
    "        if filename.endswith(\".mp4\"):\n",
    "            file_path = os.path.join(CLIP_DIR, filename)\n",
    "            video_files.append((\"videos\", (filename, open(file_path, \"rb\"), \"video/mp4\")))\n",
    "\n",
    "    # G·ª≠i y√™u c·∫ßu POST\n",
    "    print(\"üì§ Sending batch videos to deepfake API...\")\n",
    "    response = requests.post(API_URL, files=video_files)\n",
    "\n",
    "    # K·∫øt qu·∫£\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(\"‚úÖ Detection results:\")\n",
    "        for fname, r in result.items():\n",
    "            print(f\"{fname}: {r}\")\n",
    "        return result\n",
    "    else:\n",
    "        print(f\"‚ùå Error {response.status_code}: {response.text}\")\n",
    "        \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1987dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_deepfake(final_statements_json, video_path: str):\n",
    "    \"\"\"\n",
    "    Main function to detect deepfake in the video.\n",
    "    \"\"\"\n",
    "    print(\"üé• Cutting video into clips...\")\n",
    "    clip_dir = cut_video_into_clips(final_statements_json, video_path)\n",
    "\n",
    "    print(\"üîç Detecting deepfake in clips...\")\n",
    "    results = call_api_detect_deepfake(clip_dir)\n",
    "\n",
    "    for idx, statement in enumerate(final_statements_json):\n",
    "        clip_name = f\"clip_{idx+1}.mp4\"\n",
    "        result = results.get(clip_name, {})\n",
    "        \n",
    "        # L·∫•y nh√£n deepfake n·∫øu c√≥\n",
    "        label = result.get(\"pred_label\", [\"unknown\"])[0]\n",
    "        \n",
    "        # G·∫Øn v√†o statement\n",
    "        statement[\"deepfake_label\"] = label\n",
    "    \n",
    "    print(\"‚úÖ Finished detecting deepfake.\")\n",
    "    return final_statements_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58286fb",
   "metadata": {},
   "source": [
    "# Part 4: Crawl related articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4cd42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_relevant_links(query):\n",
    "  driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "  prompt = f'https://www.bing.com/search?q={query}'\n",
    "  print(prompt)\n",
    "  driver.get(prompt)\n",
    "  time.sleep(random.uniform(1, 10))\n",
    "  # print(driver.page_source)\n",
    "\n",
    "  articles = driver.find_elements(By.CSS_SELECTOR, \"#b_results li.b_algo\")\n",
    "  link_articles = []\n",
    "  link_articles.append({\n",
    "      'title': query[:30],\n",
    "      'link': prompt,\n",
    "      # 'summary': summary\n",
    "  })\n",
    "  print(f\"Found {len(articles)} relevant links:\\n{articles}\")\n",
    "  for article in articles[:MINIMUM_K]:  # Gi·ªõi h·∫°n l·∫•y 5 k·∫øt qu·∫£ ƒë·∫ßu ti√™n\n",
    "    try:\n",
    "      title_element = article.find_element(By.TAG_NAME, \"h2\").find_element(By.TAG_NAME, \"a\")\n",
    "      title = title_element.text\n",
    "      link = title_element.get_attribute('href')\n",
    "      # summary = article.find_element(By.CLASS_NAME, 'css-16nhkrn').text\n",
    "      # local = local_query(link)\n",
    "      link_articles.append({\n",
    "          'title': title,\n",
    "          'link': link,\n",
    "          # 'summary': summary\n",
    "      })\n",
    "      print(title)\n",
    "      print(link)\n",
    "    except Exception as e:\n",
    "        print(\"L·ªói khi tr√≠ch xu·∫•t b√†i vi·∫øt:\", e)\n",
    "  driver.quit()\n",
    "\n",
    "  print(f\"Found {len(link_articles)} relevant links:\\n{link_articles}\")\n",
    "\n",
    "  return link_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376faf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_dismiss_popups(driver):\n",
    "    try:\n",
    "        # C√°c n√∫t ph·ªï bi·∫øn c·∫ßn nh·∫•n\n",
    "        popup_texts = [\n",
    "            \"Accept Cookies\", \"Accept All Cookies\", \"I Accept\",\n",
    "            \"Agree\", \"Press & Hold\", \"Continue\"\n",
    "        ]\n",
    "        for text in popup_texts:\n",
    "            try:\n",
    "                btn = driver.find_element(\n",
    "                    By.XPATH,\n",
    "                    f\"//button[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{text.lower()}')]\"\n",
    "                )\n",
    "                btn.click()\n",
    "                print(f\"‚úÖ Clicked popup button: '{text}'\")\n",
    "                break\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "            except ElementClickInterceptedException:\n",
    "                continue\n",
    "\n",
    "        # T√¨m c√°c n√∫t c√≥ class name ch·ª©a 'close'\n",
    "        close_candidates = driver.find_elements(By.XPATH, \"//button[contains(@class, 'close') or contains(translate(@aria-label, 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'close')]\")\n",
    "\n",
    "        for btn in close_candidates:\n",
    "            try:\n",
    "                btn.click()\n",
    "                print(\"‚úÖ Clicked a close button\")\n",
    "                break\n",
    "            except (ElementClickInterceptedException, Exception):\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error while dismissing popup: {e}\")\n",
    "\n",
    "def process_article_link(article, max_retries=5):\n",
    "    \"\"\"H√†m x·ª≠ l√Ω m·ªôt li√™n k·∫øt ri√™ng l·∫ª v√† tr·∫£ v·ªÅ n·ªôi dung g·ªôp c√°c th·∫ª <p>\"\"\"\n",
    "    article_crawl = {\n",
    "        \"title\": article['title'],\n",
    "        \"src\": article['link'],\n",
    "        \"contents\": \"\"  # g·ªôp t·∫•t c·∫£ <p> v√†o 1 chu·ªói\n",
    "    }\n",
    "\n",
    "    success = False\n",
    "    wait_time = 10  # th·ªùi gian ch·ªù ban ƒë·∫ßu (gi√¢y)\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        try:\n",
    "            print(f\"‚è≥ Attempt {attempt}: Crawling {article['link']} with wait_time={wait_time}s\")\n",
    "            driver.get(article['link'])\n",
    "            time.sleep(wait_time)\n",
    "            try_dismiss_popups(driver)\n",
    "\n",
    "            all_elements = driver.find_elements(By.XPATH, \".//p\")\n",
    "            contents = []\n",
    "\n",
    "            for element in all_elements:\n",
    "                if element.tag_name == \"p\":\n",
    "                    text_content = element.get_attribute(\"innerText\").strip()\n",
    "                    if text_content:\n",
    "                        contents.append(text_content)\n",
    "\n",
    "            article_crawl[\"contents\"] = \"\\n\".join(contents)\n",
    "            print(f'‚úÖ Crawled content from {article[\"link\"]}:\\n{article_crawl[\"contents\"][:500]}...')  # in 500 k√Ω t·ª± ƒë·∫ßu ti√™n\n",
    "            success = True\n",
    "            break  # th√†nh c√¥ng th√¨ tho√°t\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Attempt {attempt} failed for {article['link']}: {e}\")\n",
    "            wait_time += 300  # tƒÉng th·ªùi gian ch·ªù th√™m 10s cho m·ªói l·∫ßn th·ª≠ l·∫°i\n",
    "\n",
    "        finally:\n",
    "            driver.quit()\n",
    "\n",
    "    if not success:\n",
    "        print(f\"‚ùå Failed to crawl article from {article['link']} after {max_retries} attempts.\")\n",
    "\n",
    "    return article_crawl\n",
    "\n",
    "\n",
    "\n",
    "def crawl_articles(query, crawl_json):\n",
    "    \"\"\"H√†m ch√≠nh ƒë·ªÉ crawl c√°c trang kh√°c\"\"\"\n",
    "    url_articles = search_relevant_links(query)\n",
    "\n",
    "    # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng link c·∫ßn crawl\n",
    "    url_articles = url_articles[:MINIMUM_K]\n",
    "\n",
    "    # S·ª≠ d·ª•ng Multi-threading ƒë·ªÉ ch·∫°y nhi·ªÅu request song song\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        result = list(executor.map(process_article_link, url_articles))\n",
    "\n",
    "    # G·ªôp k·∫øt qu·∫£ v√†o crawl_json\n",
    "    crawl_json.extend(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_statement(statement):\n",
    "    query = statement[\"text\"].strip('\"')\n",
    "    crawl_json = []\n",
    "\n",
    "    # Crawl theo statement\n",
    "    crawl_articles(query, crawl_json=crawl_json)\n",
    "\n",
    "    # Crawl th√™m theo context\n",
    "    context = statement[\"context\"]\n",
    "    crawl_articles(query=context, crawl_json=crawl_json)\n",
    "\n",
    "    # Lo·∫°i b·ªè c√°c k·∫øt qu·∫£ None\n",
    "    crawl_json = [item for item in crawl_json if item is not None]\n",
    "\n",
    "    # N·ªëi l·∫°i to√†n b·ªô n·ªôi dung: th√™m title v√† content m·ªói b√†i\n",
    "    article_texts = \"\\n\\n\".join(\n",
    "        f\"### {item.get('title', 'No Title')}\\n{item.get('contents', '').strip()}\"\n",
    "        for item in crawl_json\n",
    "        if item.get(\"contents\")\n",
    "    )\n",
    "\n",
    "    # Tr·∫£ l·∫°i enriched statement\n",
    "    enriched_statement = statement.copy()\n",
    "    enriched_statement[\"article_texts\"] = article_texts.strip()\n",
    "\n",
    "    return enriched_statement\n",
    "\n",
    "\n",
    "def enrich_statements_with_articles(final_statements_json):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        return list(executor.map(process_single_statement, final_statements_json))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577ea3f",
   "metadata": {},
   "source": [
    "# Part 5: Fact-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactCheck(BaseModel):\n",
    "    sentence: str\n",
    "    label: bool  # True = SUPPORTED, False = REFUTED\n",
    "    explanation: str\n",
    "    revised_sentence: str\n",
    "\n",
    "def fact_check(statement, article_texts=\"\"):\n",
    "    article_texts = statement['article_texts']\n",
    "    prompt = f\"\"\"\n",
    "You are a professional fact-checking assistant. Your task is to verify whether a given statement made by a public figure is factually accurate, using the reference documents provided.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "Follow this two-step fact-checking process:\n",
    "\n",
    "1. **Verify if the speaker actually made this statement**:\n",
    "   - Search the reference documents to determine whether the speaker is directly or credibly quoted as having said this, or something semantically equivalent.\n",
    "   - If such a quote or statement from the speaker is found, then:\n",
    "     - **Label = true**\n",
    "     - Provide an explanation saying the speaker did make this statement.\n",
    "     - Return the original sentence as `revised_sentence`.\n",
    "     - Do not evaluate the factual accuracy of the content ‚Äî if the quote is confirmed, assume it is real.\n",
    "\n",
    "2. **If there is no evidence that the speaker made this statement**, proceed to assess the **factual accuracy** of the statement based on the reference documents:\n",
    "   - If it is supported by evidence, label as **true**, provide reasoning, and return the original sentence.\n",
    "   - If it is misleading or incorrect, label as **false**, explain why, and rewrite it correctly using only facts from the documents.\n",
    "\n",
    "Use only the information in the documents. Do not speculate or assume intent. Be concise and precise.\n",
    "\n",
    "### Context:\n",
    "{statement['context']}\n",
    "\n",
    "### Speaker:\n",
    "{statement['speaker']}\n",
    "\n",
    "### Statement:\n",
    "\"{statement['text']}\"\n",
    "\n",
    "### Documents:\n",
    "{article_texts}\n",
    "\n",
    "### Output format:\n",
    "- sentence: original statement\n",
    "- label: true (supported) or false (refuted)\n",
    "- explanation: why the statement is supported/refuted\n",
    "- revised_sentence: corrected version if refuted, or original statement if supported\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.responses.parse(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a medical fact-checking expert.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            text_format=FactCheck\n",
    "        )\n",
    "        result = response.output_parsed\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Problem with API: {e}\")\n",
    "        result = \"Unverified\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9219172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_check_single_statement(statement):\n",
    "    print(statement)\n",
    "    text = statement[\"text\"]\n",
    "    article_texts = statement.get(\"article_texts\", \"\")\n",
    "\n",
    "    print(f\"üßê Fact-checking: {text[:80]}...\")\n",
    "\n",
    "    result = fact_check(statement)\n",
    "\n",
    "    if result == \"Unverified\":\n",
    "        statement[\"label\"] = None\n",
    "        statement[\"explanation\"] = \"Unverified due to API error.\"\n",
    "        statement[\"revised_statement\"] = text\n",
    "    else:\n",
    "        statement[\"label\"] = result.label\n",
    "        statement[\"explanation\"] = result.explanation\n",
    "        statement[\"revised_statement\"] = result.revised_sentence\n",
    "\n",
    "    return statement\n",
    "\n",
    "\n",
    "def run_fact_checks_parallel(enriched_statements, max_workers=4):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(fact_check_single_statement, enriched_statements))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd2a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_check_video(video_path: str):\n",
    "    \"\"\"\n",
    "    Main function to fact-check the video.\n",
    "    \"\"\"\n",
    "    print(\"üé• Extracting statements from video...\")\n",
    "    final_statements_json = extract_statements_from_video(video_path)\n",
    "\n",
    "    print(\"üîç Detecting deepfake...\")\n",
    "    final_statements_json = detect_deepfake(final_statements_json, video_path)\n",
    "    \n",
    "    for statement in final_statements_json:\n",
    "        if statement.get(\"pred_label\") == \"FAKE\":\n",
    "            print(f\"‚ö†Ô∏è Statement {statement['text']} is marked as deepfake. Skipping fact-check.\")\n",
    "            return False\n",
    "\n",
    "\n",
    "    print(\"üì∞ Enriching statements with articles...\")\n",
    "    enriched_statements = enrich_statements_with_articles(final_statements_json)\n",
    "\n",
    "    print(\"‚úÖ Finished enriching statements with articles.\")\n",
    "\n",
    "    print(\"üß™ Running fact-checks on statements...\")\n",
    "    fact_checked_results = run_fact_checks_parallel(enriched_statements)\n",
    "\n",
    "    for result in enumerate(fact_checked_results):\n",
    "        if result.label == \"False\":\n",
    "            print(f\"‚ùå Statement '{result.sentence}' is refuted: {result.explanation}\")\n",
    "            return False\n",
    "    \n",
    "    print(\"‚úÖ All statements are supported or unverified.\")\n",
    "    return True\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e615209e",
   "metadata": {},
   "source": [
    "# Part 6: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3336f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = \"../data/dfw_youtube_release\"\n",
    "\n",
    "video_files = [\n",
    "    os.path.join(VIDEO_DIR, f) for f in os.listdir(VIDEO_DIR)\n",
    "    if f.endswith((\".mp4\", \".avi\", \".mov\"))\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for video_path in video_files:\n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    try:\n",
    "        result = fact_check_video(video_path)\n",
    "        if result:\n",
    "            print(f\"‚úÖ Video {video_path} passed the fact-check.\")\n",
    "        else:\n",
    "            print(f\"‚ùå Video {video_path} failed the fact-check.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing video {video_path}: {e}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"video_path\": video_path,   \n",
    "        \"result\": result\n",
    "    })\n",
    "\n",
    "# Save results to a file\n",
    "import json\n",
    "with open(\"fact_check_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
